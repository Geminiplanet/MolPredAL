>> Train vae and task model
epoch 0: train loss is  1.58401
epoch 10: train loss is  1.48782
epoch 20: train loss is  1.46406
epoch 30: train loss is  1.48833
epoch 40: train loss is  1.50838
epoch 50: train loss is  1.40774
epoch 60: train loss is  1.31016
epoch 70: train loss is  1.22266
epoch 80: train loss is  1.25594
epoch 90: train loss is  1.14501
epoch 100: train loss is  1.15061
epoch 110: train loss is  1.19266
epoch 120: train loss is  1.21210
 >> Test Model
Cycle 1/10 || labeled data size 200, test loss(MAE) =  0.84000
TA-VAAL iteration: 0 vae_loss: 1.6091654300689697 dsc_loss: 1.4147613048553467
TA-VAAL iteration: 10 vae_loss: 1.6630549430847168 dsc_loss: 1.3957816362380981
TA-VAAL iteration: 20 vae_loss: 1.7194371223449707 dsc_loss: 1.3653239011764526
TA-VAAL iteration: 30 vae_loss: 1.7440831661224365 dsc_loss: 1.397682547569275
TA-VAAL iteration: 40 vae_loss: 1.6224802732467651 dsc_loss: 1.3799229860305786
TA-VAAL iteration: 50 vae_loss: 2.0006015300750732 dsc_loss: 1.3934557437896729
TA-VAAL iteration: 60 vae_loss: 1.9454429149627686 dsc_loss: 1.376546859741211
TA-VAAL iteration: 70 vae_loss: 1.7334671020507812 dsc_loss: 1.3976482152938843
TA-VAAL iteration: 80 vae_loss: 1.6843106746673584 dsc_loss: 1.3860087394714355
TA-VAAL iteration: 90 vae_loss: 1.760730266571045 dsc_loss: 1.392904281616211
TA-VAAL iteration: 100 vae_loss: 1.5776134729385376 dsc_loss: 1.3805019855499268
TA-VAAL iteration: 200 vae_loss: 1.6942397356033325 dsc_loss: 1.3664014339447021
TA-VAAL iteration: 300 vae_loss: 1.6957321166992188 dsc_loss: 1.3801182508468628
TA-VAAL iteration: 400 vae_loss: 1.5894732475280762 dsc_loss: 1.3818907737731934
TA-VAAL iteration: 500 vae_loss: 1.7213104963302612 dsc_loss: 1.3642010688781738
TA-VAAL iteration: 600 vae_loss: 1.6297955513000488 dsc_loss: 1.3725944757461548
TA-VAAL iteration: 700 vae_loss: 1.936476230621338 dsc_loss: 1.380274772644043
TA-VAAL iteration: 800 vae_loss: 1.7435312271118164 dsc_loss: 1.3787646293640137
TA-VAAL iteration: 900 vae_loss: 1.8344004154205322 dsc_loss: 1.3674060106277466
TA-VAAL iteration: 1000 vae_loss: 1.763181209564209 dsc_loss: 1.3845715522766113
TA-VAAL iteration: 1100 vae_loss: 1.9206410646438599 dsc_loss: 1.3652029037475586
TA-VAAL iteration: 1200 vae_loss: 2.009521484375 dsc_loss: 1.3716309070587158
TA-VAAL iteration: 1300 vae_loss: 1.9560840129852295 dsc_loss: 1.366180419921875
TA-VAAL iteration: 1400 vae_loss: 1.9427965879440308 dsc_loss: 1.3693678379058838
TA-VAAL iteration: 1500 vae_loss: 1.909449577331543 dsc_loss: 1.4029746055603027
TA-VAAL iteration: 1600 vae_loss: 1.906050205230713 dsc_loss: 1.3652522563934326
TA-VAAL iteration: 1700 vae_loss: 1.9949378967285156 dsc_loss: 1.3650763034820557
TA-VAAL iteration: 1800 vae_loss: 1.8974580764770508 dsc_loss: 1.3693010807037354
TA-VAAL iteration: 1900 vae_loss: 1.8183777332305908 dsc_loss: 1.3842965364456177
TA-VAAL iteration: 2000 vae_loss: 1.9728220701217651 dsc_loss: 1.3771350383758545
TA-VAAL iteration: 2100 vae_loss: 1.8538181781768799 dsc_loss: 1.3775588274002075
TA-VAAL iteration: 2200 vae_loss: 2.0467369556427 dsc_loss: 1.3684848546981812
TA-VAAL iteration: 2300 vae_loss: 2.1309916973114014 dsc_loss: 1.3751637935638428
TA-VAAL iteration: 2400 vae_loss: 1.946333408355713 dsc_loss: 1.3789901733398438
TA-VAAL iteration: 2500 vae_loss: 1.9494457244873047 dsc_loss: 1.3751804828643799
TA-VAAL iteration: 2600 vae_loss: 1.970313310623169 dsc_loss: 1.371105432510376
TA-VAAL iteration: 2700 vae_loss: 1.9766935110092163 dsc_loss: 1.3788220882415771
TA-VAAL iteration: 2800 vae_loss: 2.204948902130127 dsc_loss: 1.3749301433563232
TA-VAAL iteration: 2900 vae_loss: 2.1562628746032715 dsc_loss: 1.3635523319244385
TA-VAAL iteration: 3000 vae_loss: 1.9922115802764893 dsc_loss: 1.3488245010375977
TA-VAAL iteration: 3100 vae_loss: 2.185229778289795 dsc_loss: 1.2923468351364136
TA-VAAL iteration: 3200 vae_loss: 1.9167234897613525 dsc_loss: 1.3282554149627686
TA-VAAL iteration: 3300 vae_loss: 1.9875379800796509 dsc_loss: 1.2367020845413208
TA-VAAL iteration: 3400 vae_loss: 1.8444033861160278 dsc_loss: 1.3266832828521729
TA-VAAL iteration: 3500 vae_loss: 1.8311474323272705 dsc_loss: 1.2958781719207764
TA-VAAL iteration: 3600 vae_loss: 2.2760870456695557 dsc_loss: 1.2877594232559204
TA-VAAL iteration: 3700 vae_loss: 2.315690040588379 dsc_loss: 1.2701183557510376
TA-VAAL iteration: 3800 vae_loss: 1.9894335269927979 dsc_loss: 1.2828329801559448
TA-VAAL iteration: 3900 vae_loss: 2.0307981967926025 dsc_loss: 1.2593200206756592
TA-VAAL iteration: 4000 vae_loss: 2.086143970489502 dsc_loss: 1.246231198310852
TA-VAAL iteration: 4100 vae_loss: 2.2046825885772705 dsc_loss: 1.2935645580291748
TA-VAAL iteration: 4200 vae_loss: 2.134986162185669 dsc_loss: 1.312105655670166
TA-VAAL iteration: 4300 vae_loss: 1.9918875694274902 dsc_loss: 1.2647058963775635
TA-VAAL iteration: 4400 vae_loss: 2.177870035171509 dsc_loss: 1.246617078781128
TA-VAAL iteration: 4500 vae_loss: 2.282954692840576 dsc_loss: 1.2917214632034302
TA-VAAL iteration: 4600 vae_loss: 2.294772148132324 dsc_loss: 1.3101894855499268
TA-VAAL iteration: 4700 vae_loss: 1.9700984954833984 dsc_loss: 1.3473635911941528
TA-VAAL iteration: 4800 vae_loss: 2.3790485858917236 dsc_loss: 1.2102506160736084
TA-VAAL iteration: 4900 vae_loss: 2.6249308586120605 dsc_loss: 1.2878426313400269
TA-VAAL iteration: 5000 vae_loss: 2.433878183364868 dsc_loss: 1.3459486961364746
TA-VAAL iteration: 5100 vae_loss: 2.465660572052002 dsc_loss: 1.336975336074829
TA-VAAL iteration: 5200 vae_loss: 2.07802677154541 dsc_loss: 1.353947639465332
TA-VAAL iteration: 5300 vae_loss: 1.9952880144119263 dsc_loss: 1.3108365535736084
TA-VAAL iteration: 5400 vae_loss: 2.0067460536956787 dsc_loss: 1.2294752597808838
TA-VAAL iteration: 5500 vae_loss: 2.0869174003601074 dsc_loss: 1.2965654134750366
TA-VAAL iteration: 5600 vae_loss: 2.1035706996917725 dsc_loss: 1.2836244106292725
TA-VAAL iteration: 5700 vae_loss: 2.4607224464416504 dsc_loss: 1.2558003664016724
TA-VAAL iteration: 5800 vae_loss: 2.2604317665100098 dsc_loss: 1.222585678100586
TA-VAAL iteration: 5900 vae_loss: 2.562840461730957 dsc_loss: 1.2575523853302002
TA-VAAL iteration: 6000 vae_loss: 2.47357439994812 dsc_loss: 1.1403791904449463
TA-VAAL iteration: 6100 vae_loss: 2.0553903579711914 dsc_loss: 1.202606201171875
TA-VAAL iteration: 6200 vae_loss: 3.0219569206237793 dsc_loss: 1.550574541091919
400 106708 27 107099
>> Train vae and task model
epoch 0: train loss is  1.56852
epoch 10: train loss is  1.47231
epoch 20: train loss is  1.39783
epoch 30: train loss is  1.34730
epoch 40: train loss is  1.34569
epoch 50: train loss is  1.29283
epoch 60: train loss is  1.26058
epoch 70: train loss is  1.19076
epoch 80: train loss is  1.10666
epoch 90: train loss is  1.11580
epoch 100: train loss is  1.07439
epoch 110: train loss is  1.18176
epoch 120: train loss is  1.01272
 >> Test Model
Cycle 2/10 || labeled data size 400, test loss(MAE) =  0.83161
TA-VAAL iteration: 0 vae_loss: 1.742394208908081 dsc_loss: 1.4016261100769043
TA-VAAL iteration: 10 vae_loss: 1.5502468347549438 dsc_loss: 1.384746789932251
TA-VAAL iteration: 20 vae_loss: 1.6005585193634033 dsc_loss: 1.3839285373687744
TA-VAAL iteration: 30 vae_loss: 1.713102102279663 dsc_loss: 1.3811190128326416
TA-VAAL iteration: 40 vae_loss: 1.7091761827468872 dsc_loss: 1.3790409564971924
TA-VAAL iteration: 50 vae_loss: 1.7267464399337769 dsc_loss: 1.3835341930389404
TA-VAAL iteration: 60 vae_loss: 1.6936516761779785 dsc_loss: 1.3687167167663574
TA-VAAL iteration: 70 vae_loss: 1.5922094583511353 dsc_loss: 1.3808457851409912
TA-VAAL iteration: 80 vae_loss: 1.5831595659255981 dsc_loss: 1.374248743057251
TA-VAAL iteration: 90 vae_loss: 1.634787917137146 dsc_loss: 1.3586305379867554
TA-VAAL iteration: 100 vae_loss: 1.6127994060516357 dsc_loss: 1.3795779943466187
TA-VAAL iteration: 200 vae_loss: 1.6148546934127808 dsc_loss: 1.358277678489685
TA-VAAL iteration: 300 vae_loss: 1.7532856464385986 dsc_loss: 1.3853555917739868
TA-VAAL iteration: 400 vae_loss: 1.9225118160247803 dsc_loss: 1.3890407085418701
TA-VAAL iteration: 500 vae_loss: 1.763087511062622 dsc_loss: 1.3691210746765137
TA-VAAL iteration: 600 vae_loss: 2.058932304382324 dsc_loss: 1.3677120208740234
TA-VAAL iteration: 700 vae_loss: 1.6577380895614624 dsc_loss: 1.3771328926086426
TA-VAAL iteration: 800 vae_loss: 2.121393918991089 dsc_loss: 1.4146091938018799
TA-VAAL iteration: 900 vae_loss: 2.2728049755096436 dsc_loss: 1.352290153503418
TA-VAAL iteration: 1000 vae_loss: 2.231705665588379 dsc_loss: 1.34230637550354
TA-VAAL iteration: 1100 vae_loss: 2.3004517555236816 dsc_loss: 1.3921741247177124
TA-VAAL iteration: 1200 vae_loss: 2.331183433532715 dsc_loss: 1.3703476190567017
TA-VAAL iteration: 1300 vae_loss: 2.1497879028320312 dsc_loss: 1.3563735485076904
TA-VAAL iteration: 1400 vae_loss: 2.0246689319610596 dsc_loss: 1.3511855602264404
TA-VAAL iteration: 1500 vae_loss: 2.5694329738616943 dsc_loss: 1.5247639417648315
TA-VAAL iteration: 1600 vae_loss: 2.5092525482177734 dsc_loss: 1.3038897514343262
TA-VAAL iteration: 1700 vae_loss: 2.189213275909424 dsc_loss: 1.2732385396957397
TA-VAAL iteration: 1800 vae_loss: 2.684415340423584 dsc_loss: 1.2705721855163574
TA-VAAL iteration: 1900 vae_loss: 2.965636730194092 dsc_loss: 1.2596166133880615
TA-VAAL iteration: 2000 vae_loss: 2.5553793907165527 dsc_loss: 1.277859091758728
TA-VAAL iteration: 2100 vae_loss: 2.8351402282714844 dsc_loss: 1.0394537448883057
TA-VAAL iteration: 2200 vae_loss: 2.8351776599884033 dsc_loss: 0.9985244274139404
TA-VAAL iteration: 2300 vae_loss: 2.5426430702209473 dsc_loss: 1.069434404373169
TA-VAAL iteration: 2400 vae_loss: 2.450237274169922 dsc_loss: 1.0320210456848145
TA-VAAL iteration: 2500 vae_loss: 2.731050968170166 dsc_loss: 1.2345607280731201
TA-VAAL iteration: 2600 vae_loss: 1.992569923400879 dsc_loss: 1.1777093410491943
TA-VAAL iteration: 2700 vae_loss: 2.688051700592041 dsc_loss: 1.2485933303833008
TA-VAAL iteration: 2800 vae_loss: 2.871718645095825 dsc_loss: 1.144626259803772
TA-VAAL iteration: 2900 vae_loss: 3.108226776123047 dsc_loss: 0.9469727873802185
TA-VAAL iteration: 3000 vae_loss: 2.6477091312408447 dsc_loss: 1.2011581659317017
TA-VAAL iteration: 3100 vae_loss: 2.561066150665283 dsc_loss: 1.0565403699874878
TA-VAAL iteration: 3200 vae_loss: 2.7129998207092285 dsc_loss: 1.2154219150543213
TA-VAAL iteration: 3300 vae_loss: 2.6552340984344482 dsc_loss: 1.0536226034164429
TA-VAAL iteration: 3400 vae_loss: 2.6021649837493896 dsc_loss: 1.2252116203308105
TA-VAAL iteration: 3500 vae_loss: 2.9992928504943848 dsc_loss: 1.2300355434417725
TA-VAAL iteration: 3600 vae_loss: 2.9782657623291016 dsc_loss: 1.2019908428192139
TA-VAAL iteration: 3700 vae_loss: 2.371295690536499 dsc_loss: 1.1401206254959106
TA-VAAL iteration: 3800 vae_loss: 1.8221763372421265 dsc_loss: 1.165016770362854
TA-VAAL iteration: 3900 vae_loss: 2.893573045730591 dsc_loss: 1.23288893699646
TA-VAAL iteration: 4000 vae_loss: 2.5227060317993164 dsc_loss: 1.1510536670684814
TA-VAAL iteration: 4100 vae_loss: 2.438798427581787 dsc_loss: 1.244264841079712
TA-VAAL iteration: 4200 vae_loss: 2.782932758331299 dsc_loss: 1.055084228515625
TA-VAAL iteration: 4300 vae_loss: 4.021475315093994 dsc_loss: 1.3349213600158691
TA-VAAL iteration: 4400 vae_loss: 3.119168281555176 dsc_loss: 1.0414159297943115
TA-VAAL iteration: 4500 vae_loss: 2.243154764175415 dsc_loss: 1.0123804807662964
TA-VAAL iteration: 4600 vae_loss: 3.315401554107666 dsc_loss: 1.016090989112854
TA-VAAL iteration: 4700 vae_loss: 2.4734363555908203 dsc_loss: 1.2248815298080444
TA-VAAL iteration: 4800 vae_loss: 3.9051411151885986 dsc_loss: 1.2011834383010864
TA-VAAL iteration: 4900 vae_loss: 2.70584774017334 dsc_loss: 1.1564427614212036
TA-VAAL iteration: 5000 vae_loss: 3.205592155456543 dsc_loss: 0.9637949466705322
TA-VAAL iteration: 5100 vae_loss: 2.5660548210144043 dsc_loss: 1.1460598707199097
TA-VAAL iteration: 5200 vae_loss: 2.832054376602173 dsc_loss: 0.9714375734329224
TA-VAAL iteration: 5300 vae_loss: 2.944425582885742 dsc_loss: 1.1864423751831055
TA-VAAL iteration: 5400 vae_loss: 3.2760117053985596 dsc_loss: 1.049744725227356
TA-VAAL iteration: 5500 vae_loss: 3.281437397003174 dsc_loss: 1.026919960975647
TA-VAAL iteration: 5600 vae_loss: 3.6135170459747314 dsc_loss: 1.0827043056488037
TA-VAAL iteration: 5700 vae_loss: 3.0267858505249023 dsc_loss: 1.103766679763794
TA-VAAL iteration: 5800 vae_loss: 3.446033000946045 dsc_loss: 0.9761887788772583
TA-VAAL iteration: 5900 vae_loss: 2.8071584701538086 dsc_loss: 1.029205322265625
TA-VAAL iteration: 6000 vae_loss: 2.9920172691345215 dsc_loss: 1.179154872894287
TA-VAAL iteration: 6100 vae_loss: 2.8246583938598633 dsc_loss: 1.0435986518859863
TA-VAAL iteration: 6200 vae_loss: 3.976837158203125 dsc_loss: 1.0535203218460083
TA-VAAL iteration: 6300 vae_loss: 2.7705070972442627 dsc_loss: 1.0499038696289062
TA-VAAL iteration: 6400 vae_loss: 2.898092269897461 dsc_loss: 1.118759274482727
600 106508 27 107099
>> Train vae and task model
epoch 0: train loss is  1.57613
epoch 10: train loss is  1.48873
epoch 20: train loss is  1.48303
epoch 30: train loss is  1.41426
epoch 40: train loss is  1.35218
epoch 50: train loss is  1.30685
epoch 60: train loss is  1.21603
epoch 70: train loss is  1.15621
epoch 80: train loss is  1.17840
epoch 90: train loss is  1.18586
epoch 100: train loss is  1.12329
epoch 110: train loss is  1.09257
epoch 120: train loss is  1.06192
 >> Test Model
Cycle 3/10 || labeled data size 600, test loss(MAE) =  0.77791
TA-VAAL iteration: 0 vae_loss: 1.7175931930541992 dsc_loss: 1.4007257223129272
TA-VAAL iteration: 10 vae_loss: 1.4387247562408447 dsc_loss: 1.4695438146591187
TA-VAAL iteration: 20 vae_loss: 1.7367210388183594 dsc_loss: 1.4077204465866089
TA-VAAL iteration: 30 vae_loss: 1.941924810409546 dsc_loss: 1.4063246250152588
TA-VAAL iteration: 40 vae_loss: 2.1476879119873047 dsc_loss: 1.4098305702209473
TA-VAAL iteration: 50 vae_loss: 2.0830821990966797 dsc_loss: 1.39351224899292
TA-VAAL iteration: 60 vae_loss: 2.301121711730957 dsc_loss: 1.429176688194275
TA-VAAL iteration: 70 vae_loss: 2.2513010501861572 dsc_loss: 1.395719289779663
TA-VAAL iteration: 80 vae_loss: 2.1301815509796143 dsc_loss: 1.3897539377212524
TA-VAAL iteration: 90 vae_loss: 2.093475341796875 dsc_loss: 1.4124672412872314
TA-VAAL iteration: 100 vae_loss: 1.8765565156936646 dsc_loss: 1.4189159870147705
TA-VAAL iteration: 200 vae_loss: 1.6953792572021484 dsc_loss: 1.3882312774658203
TA-VAAL iteration: 300 vae_loss: 2.0109097957611084 dsc_loss: 1.4141201972961426
TA-VAAL iteration: 400 vae_loss: 1.9713971614837646 dsc_loss: 1.4035990238189697
TA-VAAL iteration: 500 vae_loss: 1.9240717887878418 dsc_loss: 1.4918720722198486
TA-VAAL iteration: 600 vae_loss: 1.7940630912780762 dsc_loss: 1.4141956567764282
TA-VAAL iteration: 700 vae_loss: 2.064927577972412 dsc_loss: 1.4137508869171143
TA-VAAL iteration: 800 vae_loss: 1.8057515621185303 dsc_loss: 1.3831892013549805
TA-VAAL iteration: 900 vae_loss: 1.7805025577545166 dsc_loss: 1.3744702339172363
TA-VAAL iteration: 1000 vae_loss: 1.8428293466567993 dsc_loss: 1.3945791721343994
TA-VAAL iteration: 1100 vae_loss: 1.7578928470611572 dsc_loss: 1.4085822105407715
TA-VAAL iteration: 1200 vae_loss: 1.8838900327682495 dsc_loss: 1.4049489498138428
TA-VAAL iteration: 1300 vae_loss: 1.8945192098617554 dsc_loss: 1.414452314376831
TA-VAAL iteration: 1400 vae_loss: 1.9895591735839844 dsc_loss: 1.3926475048065186
TA-VAAL iteration: 1500 vae_loss: 1.952775001525879 dsc_loss: 1.399573564529419
TA-VAAL iteration: 1600 vae_loss: 1.863899827003479 dsc_loss: 1.3898574113845825
TA-VAAL iteration: 1700 vae_loss: 1.8298112154006958 dsc_loss: 1.41144597530365
TA-VAAL iteration: 1800 vae_loss: 2.1721856594085693 dsc_loss: 1.426966667175293
TA-VAAL iteration: 1900 vae_loss: 1.8547227382659912 dsc_loss: 1.3885855674743652
TA-VAAL iteration: 2000 vae_loss: 1.9410951137542725 dsc_loss: 1.3963910341262817
TA-VAAL iteration: 2100 vae_loss: 1.890511155128479 dsc_loss: 1.4102504253387451
TA-VAAL iteration: 2200 vae_loss: 1.8726696968078613 dsc_loss: 1.3912317752838135
TA-VAAL iteration: 2300 vae_loss: 1.877256155014038 dsc_loss: 1.3828288316726685
TA-VAAL iteration: 2400 vae_loss: 1.7893023490905762 dsc_loss: 1.3890467882156372
TA-VAAL iteration: 2500 vae_loss: 1.9048292636871338 dsc_loss: 1.3961181640625
TA-VAAL iteration: 2600 vae_loss: 1.9899154901504517 dsc_loss: 1.4469528198242188
TA-VAAL iteration: 2700 vae_loss: 1.9135003089904785 dsc_loss: 1.4303030967712402
TA-VAAL iteration: 2800 vae_loss: 1.829857349395752 dsc_loss: 1.390019416809082
TA-VAAL iteration: 2900 vae_loss: 2.0368688106536865 dsc_loss: 1.390937328338623
TA-VAAL iteration: 3000 vae_loss: 2.0117814540863037 dsc_loss: 1.4056459665298462
TA-VAAL iteration: 3100 vae_loss: 1.8823710680007935 dsc_loss: 1.3782566785812378
TA-VAAL iteration: 3200 vae_loss: 1.9149659872055054 dsc_loss: 1.3840428590774536
TA-VAAL iteration: 3300 vae_loss: 1.9424954652786255 dsc_loss: 1.3923629522323608
TA-VAAL iteration: 3400 vae_loss: 1.8589273691177368 dsc_loss: 1.3853046894073486
TA-VAAL iteration: 3500 vae_loss: 1.931921362876892 dsc_loss: 1.37234628200531
TA-VAAL iteration: 3600 vae_loss: 2.029327392578125 dsc_loss: 1.3922319412231445
TA-VAAL iteration: 3700 vae_loss: 2.1172726154327393 dsc_loss: 1.363933801651001
TA-VAAL iteration: 3800 vae_loss: 2.1731481552124023 dsc_loss: 1.3535504341125488
TA-VAAL iteration: 3900 vae_loss: 2.0283470153808594 dsc_loss: 1.3197803497314453
TA-VAAL iteration: 4000 vae_loss: 2.748558759689331 dsc_loss: 1.3494677543640137
TA-VAAL iteration: 4100 vae_loss: 2.1418535709381104 dsc_loss: 1.3913512229919434
TA-VAAL iteration: 4200 vae_loss: 2.4432578086853027 dsc_loss: 1.4039270877838135
TA-VAAL iteration: 4300 vae_loss: 2.0540523529052734 dsc_loss: 1.366781234741211
TA-VAAL iteration: 4400 vae_loss: 2.378455877304077 dsc_loss: 1.399254322052002
TA-VAAL iteration: 4500 vae_loss: 2.0383715629577637 dsc_loss: 1.336625099182129
TA-VAAL iteration: 4600 vae_loss: 2.103984832763672 dsc_loss: 1.3344025611877441
TA-VAAL iteration: 4700 vae_loss: 2.450888156890869 dsc_loss: 1.351308822631836
TA-VAAL iteration: 4800 vae_loss: 2.1010184288024902 dsc_loss: 1.379385232925415
TA-VAAL iteration: 4900 vae_loss: 2.235323905944824 dsc_loss: 1.320473313331604
TA-VAAL iteration: 5000 vae_loss: 2.120683193206787 dsc_loss: 1.317399263381958
TA-VAAL iteration: 5100 vae_loss: 2.7028446197509766 dsc_loss: 1.4436670541763306
TA-VAAL iteration: 5200 vae_loss: 2.0310637950897217 dsc_loss: 1.3799082040786743
TA-VAAL iteration: 5300 vae_loss: 2.2309975624084473 dsc_loss: 1.371994137763977
TA-VAAL iteration: 5400 vae_loss: 2.1868035793304443 dsc_loss: 1.3784313201904297
TA-VAAL iteration: 5500 vae_loss: 2.2392094135284424 dsc_loss: 1.3488450050354004
TA-VAAL iteration: 5600 vae_loss: 2.270081043243408 dsc_loss: 1.358375072479248
TA-VAAL iteration: 5700 vae_loss: 2.0550289154052734 dsc_loss: 1.3738652467727661
TA-VAAL iteration: 5800 vae_loss: 2.019810438156128 dsc_loss: 1.3541450500488281
TA-VAAL iteration: 5900 vae_loss: 1.9737555980682373 dsc_loss: 1.3248960971832275
TA-VAAL iteration: 6000 vae_loss: 2.4105405807495117 dsc_loss: 1.4027127027511597
TA-VAAL iteration: 6100 vae_loss: 2.0084869861602783 dsc_loss: 1.355806589126587
TA-VAAL iteration: 6200 vae_loss: 2.5489392280578613 dsc_loss: 1.3445018529891968
TA-VAAL iteration: 6300 vae_loss: 2.0980587005615234 dsc_loss: 1.3858811855316162
TA-VAAL iteration: 6400 vae_loss: 2.193998336791992 dsc_loss: 1.3085644245147705
TA-VAAL iteration: 6500 vae_loss: 2.4188365936279297 dsc_loss: 1.2884052991867065
TA-VAAL iteration: 6600 vae_loss: 2.5109376907348633 dsc_loss: 1.3572306632995605
TA-VAAL iteration: 6700 vae_loss: 2.656855821609497 dsc_loss: 1.4038662910461426
800 106308 27 107099
>> Train vae and task model
epoch 0: train loss is  1.56409
epoch 10: train loss is  1.48042
epoch 20: train loss is  1.38488
epoch 30: train loss is  1.33424
epoch 40: train loss is  1.25406
epoch 50: train loss is  1.19518
epoch 60: train loss is  1.16890
epoch 70: train loss is  1.16057
epoch 80: train loss is  1.19093
epoch 90: train loss is  1.17041
epoch 100: train loss is  1.08521
epoch 110: train loss is  1.09479
epoch 120: train loss is  1.08140
 >> Test Model
Cycle 4/10 || labeled data size 800, test loss(MAE) =  0.77791
TA-VAAL iteration: 0 vae_loss: 1.7804855108261108 dsc_loss: 1.3915305137634277
TA-VAAL iteration: 10 vae_loss: 1.4936320781707764 dsc_loss: 1.4243558645248413
TA-VAAL iteration: 20 vae_loss: 1.9714412689208984 dsc_loss: 1.4069302082061768
TA-VAAL iteration: 30 vae_loss: 1.7602535486221313 dsc_loss: 1.3978378772735596
TA-VAAL iteration: 40 vae_loss: 1.9915831089019775 dsc_loss: 1.394680380821228
TA-VAAL iteration: 50 vae_loss: 2.0656795501708984 dsc_loss: 1.3809466361999512
TA-VAAL iteration: 60 vae_loss: 1.854745864868164 dsc_loss: 1.4048349857330322
TA-VAAL iteration: 70 vae_loss: 1.8772037029266357 dsc_loss: 1.3837858438491821
TA-VAAL iteration: 80 vae_loss: 1.6635792255401611 dsc_loss: 1.3921858072280884
TA-VAAL iteration: 90 vae_loss: 1.7416422367095947 dsc_loss: 1.3983336687088013
TA-VAAL iteration: 100 vae_loss: 1.663434386253357 dsc_loss: 1.3841376304626465
TA-VAAL iteration: 200 vae_loss: 1.7367172241210938 dsc_loss: 1.379146695137024
TA-VAAL iteration: 300 vae_loss: 1.7250996828079224 dsc_loss: 1.389208436012268
TA-VAAL iteration: 400 vae_loss: 1.810064673423767 dsc_loss: 1.425686001777649
TA-VAAL iteration: 500 vae_loss: 1.7010409832000732 dsc_loss: 1.3766839504241943
TA-VAAL iteration: 600 vae_loss: 1.758211612701416 dsc_loss: 1.3953055143356323
TA-VAAL iteration: 700 vae_loss: 1.7952296733856201 dsc_loss: 1.3942750692367554
TA-VAAL iteration: 800 vae_loss: 1.6513816118240356 dsc_loss: 1.3729519844055176
TA-VAAL iteration: 900 vae_loss: 1.6726192235946655 dsc_loss: 1.3918416500091553
TA-VAAL iteration: 1000 vae_loss: 1.9295320510864258 dsc_loss: 1.3988063335418701
TA-VAAL iteration: 1100 vae_loss: 1.8729090690612793 dsc_loss: 1.383112907409668
TA-VAAL iteration: 1200 vae_loss: 1.7650327682495117 dsc_loss: 1.3700071573257446
TA-VAAL iteration: 1300 vae_loss: 1.9754164218902588 dsc_loss: 1.3732575178146362
TA-VAAL iteration: 1400 vae_loss: 1.9245452880859375 dsc_loss: 1.3951561450958252
TA-VAAL iteration: 1500 vae_loss: 1.7626596689224243 dsc_loss: 1.3943266868591309
TA-VAAL iteration: 1600 vae_loss: 1.8104901313781738 dsc_loss: 1.3756611347198486
TA-VAAL iteration: 1700 vae_loss: 2.0242185592651367 dsc_loss: 1.3964271545410156
TA-VAAL iteration: 1800 vae_loss: 1.896769404411316 dsc_loss: 1.3634711503982544
TA-VAAL iteration: 1900 vae_loss: 1.8372793197631836 dsc_loss: 1.3886432647705078
TA-VAAL iteration: 2000 vae_loss: 1.9893461465835571 dsc_loss: 1.3930790424346924
TA-VAAL iteration: 2100 vae_loss: 2.014679431915283 dsc_loss: 1.3699336051940918
TA-VAAL iteration: 2200 vae_loss: 1.9208910465240479 dsc_loss: 1.3766682147979736
TA-VAAL iteration: 2300 vae_loss: 1.9161478281021118 dsc_loss: 1.4080002307891846
TA-VAAL iteration: 2400 vae_loss: 2.1019673347473145 dsc_loss: 1.379845142364502
TA-VAAL iteration: 2500 vae_loss: 2.057234287261963 dsc_loss: 1.3421227931976318
TA-VAAL iteration: 2600 vae_loss: 1.9568531513214111 dsc_loss: 1.3809959888458252
TA-VAAL iteration: 2700 vae_loss: 2.0067458152770996 dsc_loss: 1.3985942602157593
TA-VAAL iteration: 2800 vae_loss: 2.200131416320801 dsc_loss: 1.357391119003296
TA-VAAL iteration: 2900 vae_loss: 2.0862181186676025 dsc_loss: 1.3931632041931152
TA-VAAL iteration: 3000 vae_loss: 1.9540948867797852 dsc_loss: 1.3856689929962158
TA-VAAL iteration: 3100 vae_loss: 2.0405049324035645 dsc_loss: 1.3644285202026367
TA-VAAL iteration: 3200 vae_loss: 2.4858083724975586 dsc_loss: 1.3984135389328003
TA-VAAL iteration: 3300 vae_loss: 2.1342251300811768 dsc_loss: 1.406867265701294
TA-VAAL iteration: 3400 vae_loss: 1.9590553045272827 dsc_loss: 1.374410629272461
TA-VAAL iteration: 3500 vae_loss: 1.9147727489471436 dsc_loss: 1.359562873840332
TA-VAAL iteration: 3600 vae_loss: 2.2301087379455566 dsc_loss: 1.4066747426986694
TA-VAAL iteration: 3700 vae_loss: 2.038543939590454 dsc_loss: 1.3832919597625732
TA-VAAL iteration: 3800 vae_loss: 2.0841312408447266 dsc_loss: 1.3530040979385376
TA-VAAL iteration: 3900 vae_loss: 2.2258076667785645 dsc_loss: 1.3937407732009888
TA-VAAL iteration: 4000 vae_loss: 2.259349822998047 dsc_loss: 1.403407335281372
TA-VAAL iteration: 4100 vae_loss: 2.254136323928833 dsc_loss: 1.3670164346694946
TA-VAAL iteration: 4200 vae_loss: 2.155081272125244 dsc_loss: 1.379196047782898
TA-VAAL iteration: 4300 vae_loss: 2.1806249618530273 dsc_loss: 1.4336507320404053
TA-VAAL iteration: 4400 vae_loss: 2.2066330909729004 dsc_loss: 1.3710416555404663
TA-VAAL iteration: 4500 vae_loss: 2.136303424835205 dsc_loss: 1.3895080089569092
TA-VAAL iteration: 4600 vae_loss: 2.1543374061584473 dsc_loss: 1.3871999979019165
TA-VAAL iteration: 4700 vae_loss: 2.2330098152160645 dsc_loss: 1.366696834564209
TA-VAAL iteration: 4800 vae_loss: 2.238621711730957 dsc_loss: 1.3677102327346802
TA-VAAL iteration: 4900 vae_loss: 2.2248101234436035 dsc_loss: 1.408477544784546
TA-VAAL iteration: 5000 vae_loss: 2.297232151031494 dsc_loss: 1.3929574489593506
TA-VAAL iteration: 5100 vae_loss: 2.301551342010498 dsc_loss: 1.361510992050171
TA-VAAL iteration: 5200 vae_loss: 2.3314008712768555 dsc_loss: 1.3803632259368896
TA-VAAL iteration: 5300 vae_loss: 2.3377699851989746 dsc_loss: 1.3959109783172607
TA-VAAL iteration: 5400 vae_loss: 2.622105836868286 dsc_loss: 1.3753752708435059
TA-VAAL iteration: 5500 vae_loss: 2.41694974899292 dsc_loss: 1.3682656288146973
TA-VAAL iteration: 5600 vae_loss: 2.32370924949646 dsc_loss: 1.4138193130493164
TA-VAAL iteration: 5700 vae_loss: 2.2302634716033936 dsc_loss: 1.3789727687835693
TA-VAAL iteration: 5800 vae_loss: 2.4598309993743896 dsc_loss: 1.3810555934906006
TA-VAAL iteration: 5900 vae_loss: 2.3939719200134277 dsc_loss: 1.406080722808838
TA-VAAL iteration: 6000 vae_loss: 2.3052515983581543 dsc_loss: 1.3680363893508911
TA-VAAL iteration: 6100 vae_loss: 2.096538543701172 dsc_loss: 1.3676174879074097
TA-VAAL iteration: 6200 vae_loss: 2.5899481773376465 dsc_loss: 1.393772840499878
TA-VAAL iteration: 6300 vae_loss: 2.3957035541534424 dsc_loss: 1.3632479906082153
TA-VAAL iteration: 6400 vae_loss: 2.4312424659729004 dsc_loss: 1.3427863121032715
TA-VAAL iteration: 6500 vae_loss: 2.329192638397217 dsc_loss: 1.366257905960083
TA-VAAL iteration: 6600 vae_loss: 2.668200969696045 dsc_loss: 1.4039274454116821
TA-VAAL iteration: 6700 vae_loss: 2.324850082397461 dsc_loss: 1.3591969013214111
TA-VAAL iteration: 6800 vae_loss: 2.521482229232788 dsc_loss: 1.3741446733474731
TA-VAAL iteration: 6900 vae_loss: 2.2581288814544678 dsc_loss: 1.3993349075317383
1000 106108 27 107099
>> Train vae and task model
epoch 0: train loss is  1.63346
epoch 10: train loss is  1.53547
epoch 20: train loss is  1.47752
epoch 30: train loss is  1.39245
epoch 40: train loss is  1.32680
epoch 50: train loss is  1.27040
epoch 60: train loss is  1.23347
epoch 70: train loss is  1.17764
epoch 80: train loss is  1.18475
epoch 90: train loss is  1.13260
epoch 100: train loss is  1.09952
epoch 110: train loss is  1.10185
epoch 120: train loss is  1.04588
 >> Test Model
Cycle 5/10 || labeled data size 1000, test loss(MAE) =  0.80909
TA-VAAL iteration: 0 vae_loss: 1.7384679317474365 dsc_loss: 1.3969628810882568
TA-VAAL iteration: 10 vae_loss: 1.6429697275161743 dsc_loss: 1.4216597080230713
TA-VAAL iteration: 20 vae_loss: 1.729701042175293 dsc_loss: 1.470401644706726
TA-VAAL iteration: 30 vae_loss: 1.6778066158294678 dsc_loss: 1.4362109899520874
TA-VAAL iteration: 40 vae_loss: 1.7599011659622192 dsc_loss: 1.4010957479476929
TA-VAAL iteration: 50 vae_loss: 1.8811264038085938 dsc_loss: 1.383875846862793
TA-VAAL iteration: 60 vae_loss: 1.7905573844909668 dsc_loss: 1.4014701843261719
TA-VAAL iteration: 70 vae_loss: 1.8739817142486572 dsc_loss: 1.428680419921875
TA-VAAL iteration: 80 vae_loss: 1.7140700817108154 dsc_loss: 1.38580322265625
TA-VAAL iteration: 90 vae_loss: 1.6498398780822754 dsc_loss: 1.400541067123413
TA-VAAL iteration: 100 vae_loss: 1.692863941192627 dsc_loss: 1.4073578119277954
TA-VAAL iteration: 200 vae_loss: 1.6905959844589233 dsc_loss: 1.3874306678771973
TA-VAAL iteration: 300 vae_loss: 1.8045798540115356 dsc_loss: 1.3918123245239258
TA-VAAL iteration: 400 vae_loss: 1.4030930995941162 dsc_loss: 1.4006133079528809
TA-VAAL iteration: 500 vae_loss: 1.7551333904266357 dsc_loss: 1.4021095037460327
TA-VAAL iteration: 600 vae_loss: 1.8274544477462769 dsc_loss: 1.4028398990631104
TA-VAAL iteration: 700 vae_loss: 1.7491436004638672 dsc_loss: 1.3611721992492676
TA-VAAL iteration: 800 vae_loss: 1.693830966949463 dsc_loss: 1.373462200164795
TA-VAAL iteration: 900 vae_loss: 1.8704383373260498 dsc_loss: 1.3981188535690308
TA-VAAL iteration: 1000 vae_loss: 1.7346221208572388 dsc_loss: 1.4051084518432617
TA-VAAL iteration: 1100 vae_loss: 1.8578979969024658 dsc_loss: 1.3652266263961792
TA-VAAL iteration: 1200 vae_loss: 1.7480928897857666 dsc_loss: 1.3843885660171509
TA-VAAL iteration: 1300 vae_loss: 1.8727941513061523 dsc_loss: 1.4183530807495117
TA-VAAL iteration: 1400 vae_loss: 1.9522056579589844 dsc_loss: 1.4017341136932373
TA-VAAL iteration: 1500 vae_loss: 2.0385963916778564 dsc_loss: 1.3583701848983765
TA-VAAL iteration: 1600 vae_loss: 1.9655779600143433 dsc_loss: 1.3798575401306152
TA-VAAL iteration: 1700 vae_loss: 2.0050208568573 dsc_loss: 1.4114656448364258
TA-VAAL iteration: 1800 vae_loss: 1.982045292854309 dsc_loss: 1.394565463066101
TA-VAAL iteration: 1900 vae_loss: 2.099390983581543 dsc_loss: 1.365665316581726
TA-VAAL iteration: 2000 vae_loss: 1.996344804763794 dsc_loss: 1.3723465204238892
TA-VAAL iteration: 2100 vae_loss: 2.014615535736084 dsc_loss: 1.4090754985809326
TA-VAAL iteration: 2200 vae_loss: 2.0558922290802 dsc_loss: 1.3993127346038818
TA-VAAL iteration: 2300 vae_loss: 2.2131106853485107 dsc_loss: 1.363988995552063
TA-VAAL iteration: 2400 vae_loss: 2.0964179039001465 dsc_loss: 1.3769423961639404
TA-VAAL iteration: 2500 vae_loss: 2.124786853790283 dsc_loss: 1.4031836986541748
TA-VAAL iteration: 2600 vae_loss: 2.1428565979003906 dsc_loss: 1.4002606868743896
TA-VAAL iteration: 2700 vae_loss: 2.1618449687957764 dsc_loss: 1.3559060096740723
TA-VAAL iteration: 2800 vae_loss: 2.2346181869506836 dsc_loss: 1.3773819208145142
TA-VAAL iteration: 2900 vae_loss: 2.1986026763916016 dsc_loss: 1.419546127319336
TA-VAAL iteration: 3000 vae_loss: 2.2610161304473877 dsc_loss: 1.4062440395355225
TA-VAAL iteration: 3100 vae_loss: 2.1732137203216553 dsc_loss: 1.360811471939087
TA-VAAL iteration: 3200 vae_loss: 2.476175308227539 dsc_loss: 1.37825608253479
TA-VAAL iteration: 3300 vae_loss: 2.406424045562744 dsc_loss: 1.3958699703216553
TA-VAAL iteration: 3400 vae_loss: 2.4252660274505615 dsc_loss: 1.4000908136367798
TA-VAAL iteration: 3500 vae_loss: 2.4460954666137695 dsc_loss: 1.3740861415863037
TA-VAAL iteration: 3600 vae_loss: 2.407827377319336 dsc_loss: 1.371077537536621
TA-VAAL iteration: 3700 vae_loss: 2.3085665702819824 dsc_loss: 1.4204678535461426
TA-VAAL iteration: 3800 vae_loss: 2.2836995124816895 dsc_loss: 1.4031035900115967
TA-VAAL iteration: 3900 vae_loss: 2.3097143173217773 dsc_loss: 1.3621315956115723
TA-VAAL iteration: 4000 vae_loss: 2.369840145111084 dsc_loss: 1.3766663074493408
TA-VAAL iteration: 4100 vae_loss: 2.5032081604003906 dsc_loss: 1.4111591577529907
TA-VAAL iteration: 4200 vae_loss: 2.2844533920288086 dsc_loss: 1.392031192779541
TA-VAAL iteration: 4300 vae_loss: 2.515091896057129 dsc_loss: 1.3522758483886719
TA-VAAL iteration: 4400 vae_loss: 2.6010067462921143 dsc_loss: 1.3832345008850098
TA-VAAL iteration: 4500 vae_loss: 2.5253684520721436 dsc_loss: 1.4125573635101318
TA-VAAL iteration: 4600 vae_loss: 2.562039852142334 dsc_loss: 1.3833928108215332
TA-VAAL iteration: 4700 vae_loss: 2.557443141937256 dsc_loss: 1.3619821071624756
TA-VAAL iteration: 4800 vae_loss: 2.579671859741211 dsc_loss: 1.37477445602417
TA-VAAL iteration: 4900 vae_loss: 2.7177224159240723 dsc_loss: 1.4202159643173218
TA-VAAL iteration: 5000 vae_loss: 2.8032872676849365 dsc_loss: 1.4012525081634521
TA-VAAL iteration: 5100 vae_loss: 2.7648353576660156 dsc_loss: 1.3661339282989502
TA-VAAL iteration: 5200 vae_loss: 2.774911880493164 dsc_loss: 1.3750724792480469
TA-VAAL iteration: 5300 vae_loss: 2.7489078044891357 dsc_loss: 1.4231359958648682
TA-VAAL iteration: 5400 vae_loss: 2.727722406387329 dsc_loss: 1.40704345703125
TA-VAAL iteration: 5500 vae_loss: 2.8283181190490723 dsc_loss: 1.3600075244903564
TA-VAAL iteration: 5600 vae_loss: 2.8116893768310547 dsc_loss: 1.3769378662109375
TA-VAAL iteration: 5700 vae_loss: 2.7917940616607666 dsc_loss: 1.410616397857666
TA-VAAL iteration: 5800 vae_loss: 2.5574567317962646 dsc_loss: 1.4024038314819336
TA-VAAL iteration: 5900 vae_loss: 2.670768976211548 dsc_loss: 1.3629755973815918
TA-VAAL iteration: 6000 vae_loss: 2.732487201690674 dsc_loss: 1.381150245666504
TA-VAAL iteration: 6100 vae_loss: 2.802443265914917 dsc_loss: 1.4084855318069458
TA-VAAL iteration: 6200 vae_loss: 2.701596260070801 dsc_loss: 1.402602195739746
TA-VAAL iteration: 6300 vae_loss: 2.8368687629699707 dsc_loss: 1.3478964567184448
TA-VAAL iteration: 6400 vae_loss: 2.884787082672119 dsc_loss: 1.3777424097061157
TA-VAAL iteration: 6500 vae_loss: 2.8346705436706543 dsc_loss: 1.4209706783294678
TA-VAAL iteration: 6600 vae_loss: 2.7630465030670166 dsc_loss: 1.4050872325897217
TA-VAAL iteration: 6700 vae_loss: 2.7029740810394287 dsc_loss: 1.3657368421554565
TA-VAAL iteration: 6800 vae_loss: 2.7535831928253174 dsc_loss: 1.3794714212417603
TA-VAAL iteration: 6900 vae_loss: 2.791893482208252 dsc_loss: 1.4261908531188965
TA-VAAL iteration: 7000 vae_loss: 2.9700770378112793 dsc_loss: 1.4041870832443237
TA-VAAL iteration: 7100 vae_loss: 2.8702752590179443 dsc_loss: 1.3601951599121094
TA-VAAL iteration: 7200 vae_loss: 2.9421794414520264 dsc_loss: 1.380907416343689
1200 105908 27 107099
>> Train vae and task model
epoch 0: train loss is  1.61842
epoch 10: train loss is  1.51281
epoch 20: train loss is  1.46251
epoch 30: train loss is  1.39459
epoch 40: train loss is  1.33394
epoch 50: train loss is  1.31375
epoch 60: train loss is  1.29023
epoch 70: train loss is  1.25270
epoch 80: train loss is  1.25323
epoch 90: train loss is  1.25806
epoch 100: train loss is  1.21912
epoch 110: train loss is  1.23885
epoch 120: train loss is  1.20077
 >> Test Model
Cycle 6/10 || labeled data size 1200, test loss(MAE) =  0.77791
TA-VAAL iteration: 0 vae_loss: 1.6830130815505981 dsc_loss: 1.415946125984192
TA-VAAL iteration: 10 vae_loss: 2.065037965774536 dsc_loss: 1.447890281677246
TA-VAAL iteration: 20 vae_loss: 1.8779478073120117 dsc_loss: 1.3862792253494263
TA-VAAL iteration: 30 vae_loss: 1.8511605262756348 dsc_loss: 1.3923728466033936
TA-VAAL iteration: 40 vae_loss: 1.7776942253112793 dsc_loss: 1.419503927230835
TA-VAAL iteration: 50 vae_loss: 2.2238998413085938 dsc_loss: 1.4181264638900757
TA-VAAL iteration: 60 vae_loss: 2.180368185043335 dsc_loss: 1.393450140953064
TA-VAAL iteration: 70 vae_loss: 2.0673699378967285 dsc_loss: 1.40218186378479
TA-VAAL iteration: 80 vae_loss: 2.2859840393066406 dsc_loss: 1.4257041215896606
TA-VAAL iteration: 90 vae_loss: 1.9462735652923584 dsc_loss: 1.4376274347305298
TA-VAAL iteration: 100 vae_loss: 1.8523800373077393 dsc_loss: 1.3869973421096802
TA-VAAL iteration: 200 vae_loss: 1.7012646198272705 dsc_loss: 1.3916068077087402
TA-VAAL iteration: 300 vae_loss: 1.830878496170044 dsc_loss: 1.3818939924240112
TA-VAAL iteration: 400 vae_loss: 1.7749913930892944 dsc_loss: 1.3918811082839966
TA-VAAL iteration: 500 vae_loss: 1.4946873188018799 dsc_loss: 1.398011565208435
TA-VAAL iteration: 600 vae_loss: 1.6566455364227295 dsc_loss: 1.394433856010437
TA-VAAL iteration: 700 vae_loss: 1.6920872926712036 dsc_loss: 1.3877959251403809
TA-VAAL iteration: 800 vae_loss: 1.5160720348358154 dsc_loss: 1.3784475326538086
TA-VAAL iteration: 900 vae_loss: 1.655083417892456 dsc_loss: 1.4057484865188599
TA-VAAL iteration: 1000 vae_loss: 1.617311954498291 dsc_loss: 1.382210373878479
TA-VAAL iteration: 1100 vae_loss: 1.7865643501281738 dsc_loss: 1.3933234214782715
TA-VAAL iteration: 1200 vae_loss: 1.54098379611969 dsc_loss: 1.3823647499084473
TA-VAAL iteration: 1300 vae_loss: 1.6690398454666138 dsc_loss: 1.382935643196106
TA-VAAL iteration: 1400 vae_loss: 1.7215197086334229 dsc_loss: 1.386897325515747
TA-VAAL iteration: 1500 vae_loss: 1.67170250415802 dsc_loss: 1.3815231323242188
TA-VAAL iteration: 1600 vae_loss: 1.5410377979278564 dsc_loss: 1.3885987997055054
TA-VAAL iteration: 1700 vae_loss: 1.5800633430480957 dsc_loss: 1.37668776512146
TA-VAAL iteration: 1800 vae_loss: 1.6265168190002441 dsc_loss: 1.3579049110412598
TA-VAAL iteration: 1900 vae_loss: 1.6649061441421509 dsc_loss: 1.3927875757217407
TA-VAAL iteration: 2000 vae_loss: 1.5228650569915771 dsc_loss: 1.3913747072219849
TA-VAAL iteration: 2100 vae_loss: 1.5592743158340454 dsc_loss: 1.3997893333435059
TA-VAAL iteration: 2200 vae_loss: 1.6247596740722656 dsc_loss: 1.374725341796875
TA-VAAL iteration: 2300 vae_loss: 1.6602579355239868 dsc_loss: 1.3939467668533325
TA-VAAL iteration: 2400 vae_loss: 1.5402321815490723 dsc_loss: 1.3739155530929565
TA-VAAL iteration: 2500 vae_loss: 1.553566575050354 dsc_loss: 1.3837425708770752
TA-VAAL iteration: 2600 vae_loss: 1.7102766036987305 dsc_loss: 1.3850555419921875
TA-VAAL iteration: 2700 vae_loss: 1.578178882598877 dsc_loss: 1.4009196758270264
TA-VAAL iteration: 2800 vae_loss: 1.6447144746780396 dsc_loss: 1.3849612474441528
TA-VAAL iteration: 2900 vae_loss: 1.6957123279571533 dsc_loss: 1.3863428831100464
TA-VAAL iteration: 3000 vae_loss: 1.7989741563796997 dsc_loss: 1.3935215473175049
TA-VAAL iteration: 3100 vae_loss: 1.6965596675872803 dsc_loss: 1.3812437057495117
TA-VAAL iteration: 3200 vae_loss: 1.5893738269805908 dsc_loss: 1.388413667678833
TA-VAAL iteration: 3300 vae_loss: 1.6313180923461914 dsc_loss: 1.3912811279296875
TA-VAAL iteration: 3400 vae_loss: 1.6839585304260254 dsc_loss: 1.3783459663391113
TA-VAAL iteration: 3500 vae_loss: 1.5043036937713623 dsc_loss: 1.3868589401245117
TA-VAAL iteration: 3600 vae_loss: 1.5329289436340332 dsc_loss: 1.3844696283340454
TA-VAAL iteration: 3700 vae_loss: 1.617173671722412 dsc_loss: 1.3293588161468506
TA-VAAL iteration: 3800 vae_loss: 1.6944810152053833 dsc_loss: 1.3805581331253052
TA-VAAL iteration: 3900 vae_loss: 1.7604799270629883 dsc_loss: 1.4217276573181152
TA-VAAL iteration: 4000 vae_loss: 1.5700277090072632 dsc_loss: 1.3943495750427246
TA-VAAL iteration: 4100 vae_loss: 1.552935004234314 dsc_loss: 1.352082371711731
TA-VAAL iteration: 4200 vae_loss: 1.600695252418518 dsc_loss: 1.3844785690307617
TA-VAAL iteration: 4300 vae_loss: 1.7268986701965332 dsc_loss: 1.3890278339385986
TA-VAAL iteration: 4400 vae_loss: 1.7212283611297607 dsc_loss: 1.3936630487442017
TA-VAAL iteration: 4500 vae_loss: 1.5745660066604614 dsc_loss: 1.3982534408569336
TA-VAAL iteration: 4600 vae_loss: 1.6112371683120728 dsc_loss: 1.405542016029358
TA-VAAL iteration: 4700 vae_loss: 1.6134686470031738 dsc_loss: 1.3981778621673584
TA-VAAL iteration: 4800 vae_loss: 1.5731563568115234 dsc_loss: 1.3742341995239258
TA-VAAL iteration: 4900 vae_loss: 1.5981398820877075 dsc_loss: 1.3928165435791016
TA-VAAL iteration: 5000 vae_loss: 1.5789730548858643 dsc_loss: 1.3833894729614258
TA-VAAL iteration: 5100 vae_loss: 1.6041839122772217 dsc_loss: 1.378392219543457
TA-VAAL iteration: 5200 vae_loss: 1.655775785446167 dsc_loss: 1.3684561252593994
TA-VAAL iteration: 5300 vae_loss: 1.5845223665237427 dsc_loss: 1.4234418869018555
TA-VAAL iteration: 5400 vae_loss: 1.586471438407898 dsc_loss: 1.3952388763427734
TA-VAAL iteration: 5500 vae_loss: 1.5995965003967285 dsc_loss: 1.3904014825820923
TA-VAAL iteration: 5600 vae_loss: 1.6332991123199463 dsc_loss: 1.260712742805481
TA-VAAL iteration: 5700 vae_loss: 1.5966286659240723 dsc_loss: 1.374294638633728
TA-VAAL iteration: 5800 vae_loss: 1.6419057846069336 dsc_loss: 1.3789472579956055
TA-VAAL iteration: 5900 vae_loss: 1.6058931350708008 dsc_loss: 1.3943121433258057
TA-VAAL iteration: 6000 vae_loss: 1.6437442302703857 dsc_loss: 1.2990620136260986
TA-VAAL iteration: 6100 vae_loss: 1.6487764120101929 dsc_loss: 1.3848797082901
TA-VAAL iteration: 6200 vae_loss: 1.6763150691986084 dsc_loss: 1.3849753141403198
TA-VAAL iteration: 6300 vae_loss: 1.6579927206039429 dsc_loss: 1.391586184501648
TA-VAAL iteration: 6400 vae_loss: 1.6971975564956665 dsc_loss: 1.4179818630218506
TA-VAAL iteration: 6500 vae_loss: 1.6978766918182373 dsc_loss: 1.3706607818603516
TA-VAAL iteration: 6600 vae_loss: 1.7021197080612183 dsc_loss: 1.412339448928833
TA-VAAL iteration: 6700 vae_loss: 1.700246810913086 dsc_loss: 1.3487951755523682
TA-VAAL iteration: 6800 vae_loss: 1.7600748538970947 dsc_loss: 1.3934975862503052
TA-VAAL iteration: 6900 vae_loss: 1.715644121170044 dsc_loss: 1.3927781581878662
TA-VAAL iteration: 7000 vae_loss: 1.8518146276474 dsc_loss: 1.3842014074325562
TA-VAAL iteration: 7100 vae_loss: 1.7620296478271484 dsc_loss: 1.3583118915557861
TA-VAAL iteration: 7200 vae_loss: 1.91233491897583 dsc_loss: 1.4053318500518799
TA-VAAL iteration: 7300 vae_loss: 1.9461805820465088 dsc_loss: 1.3983078002929688
TA-VAAL iteration: 7400 vae_loss: 1.8420919179916382 dsc_loss: 1.3856346607208252
1400 105708 27 107099
>> Train vae and task model
epoch 0: train loss is  1.59920
epoch 10: train loss is  1.49620
epoch 20: train loss is  1.44436
epoch 30: train loss is  1.35251
epoch 40: train loss is  1.32672
epoch 50: train loss is  1.30385
epoch 60: train loss is  1.26909
epoch 70: train loss is  1.28963
epoch 80: train loss is  1.27906
epoch 90: train loss is  1.21755
epoch 100: train loss is  1.21821
epoch 110: train loss is  1.19771
epoch 120: train loss is  1.23286
 >> Test Model
Cycle 7/10 || labeled data size 1400, test loss(MAE) =  0.77791
TA-VAAL iteration: 0 vae_loss: 1.8449811935424805 dsc_loss: 1.3894670009613037
TA-VAAL iteration: 10 vae_loss: 1.4927382469177246 dsc_loss: 1.4215819835662842
TA-VAAL iteration: 20 vae_loss: 1.842021107673645 dsc_loss: 1.3869969844818115
TA-VAAL iteration: 30 vae_loss: 1.6522756814956665 dsc_loss: 1.3854823112487793
TA-VAAL iteration: 40 vae_loss: 1.7729469537734985 dsc_loss: 1.3707259893417358
TA-VAAL iteration: 50 vae_loss: 1.6820073127746582 dsc_loss: 1.3916560411453247
TA-VAAL iteration: 60 vae_loss: 1.7096898555755615 dsc_loss: 1.4302921295166016
TA-VAAL iteration: 70 vae_loss: 1.6044890880584717 dsc_loss: 1.3868494033813477
TA-VAAL iteration: 80 vae_loss: 1.7888617515563965 dsc_loss: 1.395843505859375
TA-VAAL iteration: 90 vae_loss: 1.5183334350585938 dsc_loss: 1.3913816213607788
TA-VAAL iteration: 100 vae_loss: 1.6568732261657715 dsc_loss: 1.3838684558868408
TA-VAAL iteration: 200 vae_loss: 1.5669043064117432 dsc_loss: 1.3925895690917969
TA-VAAL iteration: 300 vae_loss: 1.629619836807251 dsc_loss: 1.3937718868255615
TA-VAAL iteration: 400 vae_loss: 1.4521576166152954 dsc_loss: 1.38772451877594
TA-VAAL iteration: 500 vae_loss: 1.4556396007537842 dsc_loss: 1.3818819522857666
TA-VAAL iteration: 600 vae_loss: 1.4525007009506226 dsc_loss: 1.3870214223861694
TA-VAAL iteration: 700 vae_loss: 1.4809937477111816 dsc_loss: 1.378831148147583
TA-VAAL iteration: 800 vae_loss: 1.6033611297607422 dsc_loss: 1.3855148553848267
TA-VAAL iteration: 900 vae_loss: 1.4781508445739746 dsc_loss: 1.386716365814209
TA-VAAL iteration: 1000 vae_loss: 1.569872260093689 dsc_loss: 1.4039822816848755
TA-VAAL iteration: 1100 vae_loss: 1.7136542797088623 dsc_loss: 1.3849289417266846
TA-VAAL iteration: 1200 vae_loss: 1.5708506107330322 dsc_loss: 1.3893834352493286
TA-VAAL iteration: 1300 vae_loss: 1.652384877204895 dsc_loss: 1.3862489461898804
TA-VAAL iteration: 1400 vae_loss: 1.5973857641220093 dsc_loss: 1.3575783967971802
TA-VAAL iteration: 1500 vae_loss: 1.779113531112671 dsc_loss: 1.4217777252197266
TA-VAAL iteration: 1600 vae_loss: 1.5021905899047852 dsc_loss: 1.3837881088256836
TA-VAAL iteration: 1700 vae_loss: 1.7111072540283203 dsc_loss: 1.3845210075378418
TA-VAAL iteration: 1800 vae_loss: 1.5749934911727905 dsc_loss: 1.3805423974990845
TA-VAAL iteration: 1900 vae_loss: 1.6571818590164185 dsc_loss: 1.4068880081176758
TA-VAAL iteration: 2000 vae_loss: 1.7610249519348145 dsc_loss: 1.3866021633148193
TA-VAAL iteration: 2100 vae_loss: 1.7269537448883057 dsc_loss: 1.4026607275009155
TA-VAAL iteration: 2200 vae_loss: 1.798975944519043 dsc_loss: 1.4013667106628418
TA-VAAL iteration: 2300 vae_loss: 1.7745112180709839 dsc_loss: 1.372903823852539
TA-VAAL iteration: 2400 vae_loss: 1.7440546751022339 dsc_loss: 1.3841872215270996
TA-VAAL iteration: 2500 vae_loss: 1.889965534210205 dsc_loss: 1.3464208841323853
TA-VAAL iteration: 2600 vae_loss: 1.7005125284194946 dsc_loss: 1.3938289880752563
TA-VAAL iteration: 2700 vae_loss: 1.8605329990386963 dsc_loss: 1.3658193349838257
TA-VAAL iteration: 2800 vae_loss: 1.9050004482269287 dsc_loss: 1.3807770013809204
TA-VAAL iteration: 2900 vae_loss: 1.9712543487548828 dsc_loss: 1.3647639751434326
TA-VAAL iteration: 3000 vae_loss: 1.8133399486541748 dsc_loss: 1.374648094177246
TA-VAAL iteration: 3100 vae_loss: 2.109968662261963 dsc_loss: 1.3861072063446045
TA-VAAL iteration: 3200 vae_loss: 2.129265785217285 dsc_loss: 1.375007152557373
TA-VAAL iteration: 3300 vae_loss: 2.238452911376953 dsc_loss: 1.4107394218444824
TA-VAAL iteration: 3400 vae_loss: 2.0198090076446533 dsc_loss: 1.3629581928253174
TA-VAAL iteration: 3500 vae_loss: 2.1615424156188965 dsc_loss: 1.3619892597198486
TA-VAAL iteration: 3600 vae_loss: 2.253146171569824 dsc_loss: 1.3123494386672974
TA-VAAL iteration: 3700 vae_loss: 2.1048386096954346 dsc_loss: 1.3546303510665894
TA-VAAL iteration: 3800 vae_loss: 2.3646035194396973 dsc_loss: 1.3781660795211792
TA-VAAL iteration: 3900 vae_loss: 2.3001396656036377 dsc_loss: 1.3561387062072754
TA-VAAL iteration: 4000 vae_loss: 2.211737632751465 dsc_loss: 1.338636875152588
TA-VAAL iteration: 4100 vae_loss: 1.898735761642456 dsc_loss: 1.4019293785095215
TA-VAAL iteration: 4200 vae_loss: 2.08286452293396 dsc_loss: 1.3626190423965454
TA-VAAL iteration: 4300 vae_loss: 2.4517531394958496 dsc_loss: 1.4107801914215088
TA-VAAL iteration: 4400 vae_loss: 2.649472236633301 dsc_loss: 1.3940677642822266
TA-VAAL iteration: 4500 vae_loss: 2.788456439971924 dsc_loss: 1.3880846500396729
TA-VAAL iteration: 4600 vae_loss: 2.6548168659210205 dsc_loss: 1.3297532796859741
TA-VAAL iteration: 4700 vae_loss: 3.004230499267578 dsc_loss: 1.3623952865600586
TA-VAAL iteration: 4800 vae_loss: 2.6265344619750977 dsc_loss: 1.3353687524795532
TA-VAAL iteration: 4900 vae_loss: 2.7425177097320557 dsc_loss: 1.418166160583496
TA-VAAL iteration: 5000 vae_loss: 2.7692575454711914 dsc_loss: 1.328810214996338
TA-VAAL iteration: 5100 vae_loss: 3.017028570175171 dsc_loss: 1.3094544410705566
TA-VAAL iteration: 5200 vae_loss: 2.601722240447998 dsc_loss: 1.3494504690170288
TA-VAAL iteration: 5300 vae_loss: 2.923121213912964 dsc_loss: 1.3697655200958252
TA-VAAL iteration: 5400 vae_loss: 2.6273550987243652 dsc_loss: 1.3849855661392212
TA-VAAL iteration: 5500 vae_loss: 3.0590195655822754 dsc_loss: 1.3945584297180176
TA-VAAL iteration: 5600 vae_loss: 2.6899476051330566 dsc_loss: 1.3084086179733276
TA-VAAL iteration: 5700 vae_loss: 3.054952383041382 dsc_loss: 1.3502891063690186
TA-VAAL iteration: 5800 vae_loss: 3.163006067276001 dsc_loss: 1.362608551979065
TA-VAAL iteration: 5900 vae_loss: 2.96407413482666 dsc_loss: 1.3860247135162354
TA-VAAL iteration: 6000 vae_loss: 2.5014467239379883 dsc_loss: 1.3529322147369385
TA-VAAL iteration: 6100 vae_loss: 2.9341979026794434 dsc_loss: 1.422511339187622
TA-VAAL iteration: 6200 vae_loss: 3.3443520069122314 dsc_loss: 1.4467637538909912
TA-VAAL iteration: 6300 vae_loss: 3.1547915935516357 dsc_loss: 1.3292218446731567
TA-VAAL iteration: 6400 vae_loss: 3.204993724822998 dsc_loss: 1.321537733078003
TA-VAAL iteration: 6500 vae_loss: 3.105135917663574 dsc_loss: 1.3828366994857788
TA-VAAL iteration: 6600 vae_loss: 3.023981809616089 dsc_loss: 1.4161219596862793
TA-VAAL iteration: 6700 vae_loss: 3.2770369052886963 dsc_loss: 1.3710509538650513
TA-VAAL iteration: 6800 vae_loss: 3.5435409545898438 dsc_loss: 1.3321032524108887
TA-VAAL iteration: 6900 vae_loss: 3.721391439437866 dsc_loss: 1.3032574653625488
TA-VAAL iteration: 7000 vae_loss: 3.4079108238220215 dsc_loss: 1.3950481414794922
TA-VAAL iteration: 7100 vae_loss: 2.9781675338745117 dsc_loss: 1.3119606971740723
TA-VAAL iteration: 7200 vae_loss: 3.077765941619873 dsc_loss: 1.3942992687225342
TA-VAAL iteration: 7300 vae_loss: 3.2651219367980957 dsc_loss: 1.3354709148406982
TA-VAAL iteration: 7400 vae_loss: 3.4284048080444336 dsc_loss: 1.381805181503296
TA-VAAL iteration: 7500 vae_loss: 4.160019874572754 dsc_loss: 1.4117534160614014
TA-VAAL iteration: 7600 vae_loss: 3.280242681503296 dsc_loss: 1.3886404037475586
TA-VAAL iteration: 7700 vae_loss: 3.448315143585205 dsc_loss: 1.4005687236785889
1600 105508 27 107099
>> Train vae and task model
epoch 0: train loss is  1.59089
epoch 10: train loss is  1.50906
epoch 20: train loss is  1.42990
epoch 30: train loss is  1.39598
epoch 40: train loss is  1.33947
epoch 50: train loss is  1.30356
epoch 60: train loss is  1.27814
epoch 70: train loss is  1.26759
epoch 80: train loss is  1.22904
epoch 90: train loss is  1.25749
epoch 100: train loss is  1.24263
epoch 110: train loss is  1.24189
epoch 120: train loss is  1.21495
 >> Test Model
Cycle 8/10 || labeled data size 1600, test loss(MAE) =  0.77791
TA-VAAL iteration: 0 vae_loss: 1.7565293312072754 dsc_loss: 1.3958549499511719
TA-VAAL iteration: 10 vae_loss: 1.69752836227417 dsc_loss: 1.4096217155456543
TA-VAAL iteration: 20 vae_loss: 1.8735063076019287 dsc_loss: 1.439365029335022
TA-VAAL iteration: 30 vae_loss: 1.6907109022140503 dsc_loss: 1.4027118682861328
TA-VAAL iteration: 40 vae_loss: 1.6621601581573486 dsc_loss: 1.4339553117752075
TA-VAAL iteration: 50 vae_loss: 2.054840326309204 dsc_loss: 1.4138731956481934
TA-VAAL iteration: 60 vae_loss: 1.9212944507598877 dsc_loss: 1.3929075002670288
TA-VAAL iteration: 70 vae_loss: 1.8549907207489014 dsc_loss: 1.4166854619979858
TA-VAAL iteration: 80 vae_loss: 1.8398555517196655 dsc_loss: 1.377619981765747
TA-VAAL iteration: 90 vae_loss: 1.6648845672607422 dsc_loss: 1.3637588024139404
TA-VAAL iteration: 100 vae_loss: 1.6793663501739502 dsc_loss: 1.390810489654541
TA-VAAL iteration: 200 vae_loss: 1.6159162521362305 dsc_loss: 1.3876779079437256
TA-VAAL iteration: 300 vae_loss: 1.5796315670013428 dsc_loss: 1.4056965112686157
TA-VAAL iteration: 400 vae_loss: 1.633979082107544 dsc_loss: 1.4099922180175781
TA-VAAL iteration: 500 vae_loss: 1.7590198516845703 dsc_loss: 1.3981770277023315
TA-VAAL iteration: 600 vae_loss: 1.5780435800552368 dsc_loss: 1.391530156135559
TA-VAAL iteration: 700 vae_loss: 1.657305359840393 dsc_loss: 1.413801908493042
TA-VAAL iteration: 800 vae_loss: 1.609763741493225 dsc_loss: 1.4114423990249634
TA-VAAL iteration: 900 vae_loss: 1.612131118774414 dsc_loss: 1.4127624034881592
TA-VAAL iteration: 1000 vae_loss: 1.5533359050750732 dsc_loss: 1.3872064352035522
TA-VAAL iteration: 1100 vae_loss: 1.5599857568740845 dsc_loss: 1.3936548233032227
TA-VAAL iteration: 1200 vae_loss: 1.6359164714813232 dsc_loss: 1.420091152191162
TA-VAAL iteration: 1300 vae_loss: 1.6494909524917603 dsc_loss: 1.3958508968353271
TA-VAAL iteration: 1400 vae_loss: 1.6608226299285889 dsc_loss: 1.3999383449554443
TA-VAAL iteration: 1500 vae_loss: 1.6181925535202026 dsc_loss: 1.3799158334732056
TA-VAAL iteration: 1600 vae_loss: 1.6420953273773193 dsc_loss: 1.3979425430297852
TA-VAAL iteration: 1700 vae_loss: 1.6323055028915405 dsc_loss: 1.3994476795196533
TA-VAAL iteration: 1800 vae_loss: 1.5520447492599487 dsc_loss: 1.3936152458190918
TA-VAAL iteration: 1900 vae_loss: 1.609473705291748 dsc_loss: 1.405928373336792
TA-VAAL iteration: 2000 vae_loss: 1.6698696613311768 dsc_loss: 1.3991663455963135
TA-VAAL iteration: 2100 vae_loss: 1.6000826358795166 dsc_loss: 1.3854589462280273
TA-VAAL iteration: 2200 vae_loss: 1.6374386548995972 dsc_loss: 1.404849648475647
TA-VAAL iteration: 2300 vae_loss: 1.673163652420044 dsc_loss: 1.3876211643218994
TA-VAAL iteration: 2400 vae_loss: 1.617979884147644 dsc_loss: 1.3925836086273193
TA-VAAL iteration: 2500 vae_loss: 1.650711178779602 dsc_loss: 1.3895275592803955
TA-VAAL iteration: 2600 vae_loss: 1.6284750699996948 dsc_loss: 1.4011883735656738
TA-VAAL iteration: 2700 vae_loss: 1.649251937866211 dsc_loss: 1.3932716846466064
TA-VAAL iteration: 2800 vae_loss: 1.6313774585723877 dsc_loss: 1.3954564332962036
TA-VAAL iteration: 2900 vae_loss: 1.609336256980896 dsc_loss: 1.4038804769515991
TA-VAAL iteration: 3000 vae_loss: 1.617842674255371 dsc_loss: 1.3882408142089844
TA-VAAL iteration: 3100 vae_loss: 1.630661964416504 dsc_loss: 1.4015512466430664
TA-VAAL iteration: 3200 vae_loss: 1.6446352005004883 dsc_loss: 1.4098272323608398
TA-VAAL iteration: 3300 vae_loss: 1.6885333061218262 dsc_loss: 1.3888165950775146
TA-VAAL iteration: 3400 vae_loss: 1.6111135482788086 dsc_loss: 1.3906341791152954
TA-VAAL iteration: 3500 vae_loss: 1.698270559310913 dsc_loss: 1.4010798931121826
TA-VAAL iteration: 3600 vae_loss: 1.6322602033615112 dsc_loss: 1.3953227996826172
TA-VAAL iteration: 3700 vae_loss: 1.6078624725341797 dsc_loss: 1.4014673233032227
TA-VAAL iteration: 3800 vae_loss: 1.6316936016082764 dsc_loss: 1.3952202796936035
TA-VAAL iteration: 3900 vae_loss: 1.636164903640747 dsc_loss: 1.4110194444656372
TA-VAAL iteration: 4000 vae_loss: 1.6161295175552368 dsc_loss: 1.392808437347412
TA-VAAL iteration: 4100 vae_loss: 1.685027837753296 dsc_loss: 1.390904188156128
TA-VAAL iteration: 4200 vae_loss: 1.6296882629394531 dsc_loss: 1.398829698562622
TA-VAAL iteration: 4300 vae_loss: 1.6362199783325195 dsc_loss: 1.427772879600525
TA-VAAL iteration: 4400 vae_loss: 1.6078580617904663 dsc_loss: 1.3992362022399902
TA-VAAL iteration: 4500 vae_loss: 1.6256909370422363 dsc_loss: 1.386854887008667
TA-VAAL iteration: 4600 vae_loss: 1.6516518592834473 dsc_loss: 1.3949964046478271
TA-VAAL iteration: 4700 vae_loss: 1.6653815507888794 dsc_loss: 1.3994057178497314
TA-VAAL iteration: 4800 vae_loss: 1.658884048461914 dsc_loss: 1.396889567375183
TA-VAAL iteration: 4900 vae_loss: 1.6017721891403198 dsc_loss: 1.388907551765442
TA-VAAL iteration: 5000 vae_loss: 1.651464819908142 dsc_loss: 1.4002161026000977
TA-VAAL iteration: 5100 vae_loss: 1.6349732875823975 dsc_loss: 1.3967398405075073
TA-VAAL iteration: 5200 vae_loss: 1.6252835988998413 dsc_loss: 1.3928680419921875
TA-VAAL iteration: 5300 vae_loss: 1.6684596538543701 dsc_loss: 1.3931611776351929
TA-VAAL iteration: 5400 vae_loss: 1.6347131729125977 dsc_loss: 1.4088387489318848
TA-VAAL iteration: 5500 vae_loss: 1.6152989864349365 dsc_loss: 1.3964405059814453
TA-VAAL iteration: 5600 vae_loss: 1.6872273683547974 dsc_loss: 1.3926963806152344
TA-VAAL iteration: 5700 vae_loss: 1.6226837635040283 dsc_loss: 1.3972299098968506
TA-VAAL iteration: 5800 vae_loss: 1.6588404178619385 dsc_loss: 1.382710576057434
TA-VAAL iteration: 5900 vae_loss: 1.6129626035690308 dsc_loss: 1.3927600383758545
TA-VAAL iteration: 6000 vae_loss: 1.6566251516342163 dsc_loss: 1.379228115081787
TA-VAAL iteration: 6100 vae_loss: 1.6224392652511597 dsc_loss: 1.3888643980026245
TA-VAAL iteration: 6200 vae_loss: 1.6421637535095215 dsc_loss: 1.4106132984161377
TA-VAAL iteration: 6300 vae_loss: 1.664858102798462 dsc_loss: 1.3945952653884888
TA-VAAL iteration: 6400 vae_loss: 1.6016713380813599 dsc_loss: 1.3896245956420898
TA-VAAL iteration: 6500 vae_loss: 1.6232788562774658 dsc_loss: 1.4111683368682861
TA-VAAL iteration: 6600 vae_loss: 1.652411937713623 dsc_loss: 1.3971023559570312
TA-VAAL iteration: 6700 vae_loss: 1.6217379570007324 dsc_loss: 1.398343801498413
TA-VAAL iteration: 6800 vae_loss: 1.626789927482605 dsc_loss: 1.3974387645721436
TA-VAAL iteration: 6900 vae_loss: 1.6545898914337158 dsc_loss: 1.389369249343872
TA-VAAL iteration: 7000 vae_loss: 1.62291419506073 dsc_loss: 1.398113489151001
TA-VAAL iteration: 7100 vae_loss: 1.6462916135787964 dsc_loss: 1.3989460468292236
TA-VAAL iteration: 7200 vae_loss: 1.6488559246063232 dsc_loss: 1.3966788053512573
TA-VAAL iteration: 7300 vae_loss: 1.6493377685546875 dsc_loss: 1.4019956588745117
TA-VAAL iteration: 7400 vae_loss: 1.651248812675476 dsc_loss: 1.3925073146820068
TA-VAAL iteration: 7500 vae_loss: 1.6241971254348755 dsc_loss: 1.4010534286499023
TA-VAAL iteration: 7600 vae_loss: 1.6513490676879883 dsc_loss: 1.3905988931655884
TA-VAAL iteration: 7700 vae_loss: 1.643227219581604 dsc_loss: 1.4057804346084595
TA-VAAL iteration: 7800 vae_loss: 1.6465823650360107 dsc_loss: 1.4009504318237305
TA-VAAL iteration: 7900 vae_loss: 1.6098805665969849 dsc_loss: 1.3936421871185303
1800 105308 27 107099
>> Train vae and task model
epoch 0: train loss is  1.58208
epoch 10: train loss is  1.51681
epoch 20: train loss is  1.46944
epoch 30: train loss is  1.41504
epoch 40: train loss is  1.41984
epoch 50: train loss is  1.40245
epoch 60: train loss is  1.34974
epoch 70: train loss is  1.32065
epoch 80: train loss is  1.30591
epoch 90: train loss is  1.30724
epoch 100: train loss is  1.25112
epoch 110: train loss is  1.24500
epoch 120: train loss is  1.21554
 >> Test Model
Cycle 9/10 || labeled data size 1800, test loss(MAE) =  0.77791
TA-VAAL iteration: 0 vae_loss: 1.769115924835205 dsc_loss: 1.3910272121429443
TA-VAAL iteration: 10 vae_loss: 1.6582287549972534 dsc_loss: 1.389423131942749
TA-VAAL iteration: 20 vae_loss: 1.689387321472168 dsc_loss: 1.4192347526550293
TA-VAAL iteration: 30 vae_loss: 1.7737635374069214 dsc_loss: 1.3801981210708618
TA-VAAL iteration: 40 vae_loss: 1.7415567636489868 dsc_loss: 1.403374195098877
TA-VAAL iteration: 50 vae_loss: 1.670249342918396 dsc_loss: 1.415962815284729
TA-VAAL iteration: 60 vae_loss: 1.8805804252624512 dsc_loss: 1.3896994590759277
TA-VAAL iteration: 70 vae_loss: 1.9416134357452393 dsc_loss: 1.3921291828155518
TA-VAAL iteration: 80 vae_loss: 1.6595313549041748 dsc_loss: 1.4076902866363525
TA-VAAL iteration: 90 vae_loss: 1.7564938068389893 dsc_loss: 1.41188383102417
TA-VAAL iteration: 100 vae_loss: 1.5887949466705322 dsc_loss: 1.3884286880493164
TA-VAAL iteration: 200 vae_loss: 1.5946142673492432 dsc_loss: 1.3886265754699707
TA-VAAL iteration: 300 vae_loss: 1.4845337867736816 dsc_loss: 1.3706490993499756
TA-VAAL iteration: 400 vae_loss: 1.6278704404830933 dsc_loss: 1.387086272239685
TA-VAAL iteration: 500 vae_loss: 1.6195015907287598 dsc_loss: 1.3916395902633667
TA-VAAL iteration: 600 vae_loss: 1.439826250076294 dsc_loss: 1.3988335132598877
TA-VAAL iteration: 700 vae_loss: 1.5334551334381104 dsc_loss: 1.3905377388000488
TA-VAAL iteration: 800 vae_loss: 1.6452484130859375 dsc_loss: 1.3833215236663818
TA-VAAL iteration: 900 vae_loss: 1.6163002252578735 dsc_loss: 1.3824827671051025
TA-VAAL iteration: 1000 vae_loss: 1.6424412727355957 dsc_loss: 1.3834075927734375
TA-VAAL iteration: 1100 vae_loss: 1.6438645124435425 dsc_loss: 1.4047353267669678
TA-VAAL iteration: 1200 vae_loss: 1.5505918264389038 dsc_loss: 1.3937309980392456
TA-VAAL iteration: 1300 vae_loss: 1.5721977949142456 dsc_loss: 1.3895204067230225
TA-VAAL iteration: 1400 vae_loss: 1.5592536926269531 dsc_loss: 1.3895795345306396
TA-VAAL iteration: 1500 vae_loss: 1.6415437459945679 dsc_loss: 1.3846901655197144
TA-VAAL iteration: 1600 vae_loss: 1.5554481744766235 dsc_loss: 1.386183500289917
TA-VAAL iteration: 1700 vae_loss: 1.5997695922851562 dsc_loss: 1.3841044902801514
TA-VAAL iteration: 1800 vae_loss: 1.5822958946228027 dsc_loss: 1.387960433959961
TA-VAAL iteration: 1900 vae_loss: 1.6263409852981567 dsc_loss: 1.386559009552002
TA-VAAL iteration: 2000 vae_loss: 1.6136960983276367 dsc_loss: 1.3736083507537842
TA-VAAL iteration: 2100 vae_loss: 1.6074494123458862 dsc_loss: 1.3890165090560913
TA-VAAL iteration: 2200 vae_loss: 1.6169588565826416 dsc_loss: 1.3879375457763672
TA-VAAL iteration: 2300 vae_loss: 1.6183496713638306 dsc_loss: 1.3883531093597412
TA-VAAL iteration: 2400 vae_loss: 1.5501019954681396 dsc_loss: 1.3922868967056274
TA-VAAL iteration: 2500 vae_loss: 1.5317476987838745 dsc_loss: 1.3857687711715698
TA-VAAL iteration: 2600 vae_loss: 1.6168867349624634 dsc_loss: 1.3876585960388184
TA-VAAL iteration: 2700 vae_loss: 1.5649514198303223 dsc_loss: 1.385933756828308
TA-VAAL iteration: 2800 vae_loss: 1.5862548351287842 dsc_loss: 1.397300362586975
TA-VAAL iteration: 2900 vae_loss: 1.6231863498687744 dsc_loss: 1.3854361772537231
TA-VAAL iteration: 3000 vae_loss: 1.6267610788345337 dsc_loss: 1.3874425888061523
TA-VAAL iteration: 3100 vae_loss: 1.5902585983276367 dsc_loss: 1.3810689449310303
TA-VAAL iteration: 3200 vae_loss: 1.568755865097046 dsc_loss: 1.3828577995300293
TA-VAAL iteration: 3300 vae_loss: 1.6030815839767456 dsc_loss: 1.3930792808532715
TA-VAAL iteration: 3400 vae_loss: 1.58345365524292 dsc_loss: 1.3841629028320312
TA-VAAL iteration: 3500 vae_loss: 1.5858452320098877 dsc_loss: 1.3891119956970215
TA-VAAL iteration: 3600 vae_loss: 1.5813740491867065 dsc_loss: 1.387800693511963
TA-VAAL iteration: 3700 vae_loss: 1.583811640739441 dsc_loss: 1.3900383710861206
TA-VAAL iteration: 3800 vae_loss: 1.6282120943069458 dsc_loss: 1.3842716217041016
TA-VAAL iteration: 3900 vae_loss: 1.6698673963546753 dsc_loss: 1.3769090175628662
TA-VAAL iteration: 4000 vae_loss: 1.5936293601989746 dsc_loss: 1.3866804838180542
TA-VAAL iteration: 4100 vae_loss: 1.5896497964859009 dsc_loss: 1.3860583305358887
TA-VAAL iteration: 4200 vae_loss: 1.5936707258224487 dsc_loss: 1.3798441886901855
TA-VAAL iteration: 4300 vae_loss: 1.5989493131637573 dsc_loss: 1.3898584842681885
TA-VAAL iteration: 4400 vae_loss: 1.5989317893981934 dsc_loss: 1.390554666519165
TA-VAAL iteration: 4500 vae_loss: 1.5695425271987915 dsc_loss: 1.380951166152954
TA-VAAL iteration: 4600 vae_loss: 1.5704189538955688 dsc_loss: 1.3865219354629517
TA-VAAL iteration: 4700 vae_loss: 1.6273196935653687 dsc_loss: 1.3888320922851562
TA-VAAL iteration: 4800 vae_loss: 1.6057932376861572 dsc_loss: 1.3809338808059692
TA-VAAL iteration: 4900 vae_loss: 1.646803855895996 dsc_loss: 1.3760249614715576
TA-VAAL iteration: 5000 vae_loss: 1.61378014087677 dsc_loss: 1.3802646398544312
TA-VAAL iteration: 5100 vae_loss: 1.6073663234710693 dsc_loss: 1.3838591575622559
TA-VAAL iteration: 5200 vae_loss: 1.6170132160186768 dsc_loss: 1.386144995689392
TA-VAAL iteration: 5300 vae_loss: 1.618796467781067 dsc_loss: 1.3865329027175903
TA-VAAL iteration: 5400 vae_loss: 1.570064663887024 dsc_loss: 1.3900134563446045
TA-VAAL iteration: 5500 vae_loss: 1.5570001602172852 dsc_loss: 1.386000394821167
TA-VAAL iteration: 5600 vae_loss: 1.5896984338760376 dsc_loss: 1.3829872608184814
TA-VAAL iteration: 5700 vae_loss: 1.600564956665039 dsc_loss: 1.3929173946380615
TA-VAAL iteration: 5800 vae_loss: 1.6297403573989868 dsc_loss: 1.3867778778076172
TA-VAAL iteration: 5900 vae_loss: 1.6640689373016357 dsc_loss: 1.378644347190857
TA-VAAL iteration: 6000 vae_loss: 1.6058521270751953 dsc_loss: 1.3812282085418701
TA-VAAL iteration: 6100 vae_loss: 1.6015363931655884 dsc_loss: 1.3857241868972778
TA-VAAL iteration: 6200 vae_loss: 1.6135234832763672 dsc_loss: 1.3894507884979248
TA-VAAL iteration: 6300 vae_loss: 1.5849844217300415 dsc_loss: 1.3904030323028564
TA-VAAL iteration: 6400 vae_loss: 1.5687649250030518 dsc_loss: 1.3847317695617676
TA-VAAL iteration: 6500 vae_loss: 1.5957618951797485 dsc_loss: 1.3849008083343506
TA-VAAL iteration: 6600 vae_loss: 1.593950629234314 dsc_loss: 1.3951255083084106
TA-VAAL iteration: 6700 vae_loss: 1.672324299812317 dsc_loss: 1.3854557275772095
TA-VAAL iteration: 6800 vae_loss: 1.6567494869232178 dsc_loss: 1.3749730587005615
TA-VAAL iteration: 6900 vae_loss: 1.6075844764709473 dsc_loss: 1.3899765014648438
TA-VAAL iteration: 7000 vae_loss: 1.6243263483047485 dsc_loss: 1.3867287635803223
TA-VAAL iteration: 7100 vae_loss: 1.6107478141784668 dsc_loss: 1.38905930519104
TA-VAAL iteration: 7200 vae_loss: 1.6309814453125 dsc_loss: 1.3886033296585083
TA-VAAL iteration: 7300 vae_loss: 1.6333776712417603 dsc_loss: 1.39024019241333
TA-VAAL iteration: 7400 vae_loss: 1.6041266918182373 dsc_loss: 1.389100193977356
TA-VAAL iteration: 7500 vae_loss: 1.6075146198272705 dsc_loss: 1.3893930912017822
TA-VAAL iteration: 7600 vae_loss: 1.6300890445709229 dsc_loss: 1.3863319158554077
TA-VAAL iteration: 7700 vae_loss: 1.6541012525558472 dsc_loss: 1.3848850727081299
TA-VAAL iteration: 7800 vae_loss: 1.674621343612671 dsc_loss: 1.3824965953826904
TA-VAAL iteration: 7900 vae_loss: 1.6629438400268555 dsc_loss: 1.3892478942871094
TA-VAAL iteration: 8000 vae_loss: 1.6467081308364868 dsc_loss: 1.3906261920928955
TA-VAAL iteration: 8100 vae_loss: 1.639838457107544 dsc_loss: 1.3846062421798706
TA-VAAL iteration: 8200 vae_loss: 1.6548184156417847 dsc_loss: 1.3881645202636719
2000 105108 27 107099
>> Train vae and task model
epoch 0: train loss is  1.60090
epoch 10: train loss is  1.52415
epoch 20: train loss is  1.47624
epoch 30: train loss is  1.42842
epoch 40: train loss is  1.39516
epoch 50: train loss is  1.35637
epoch 60: train loss is  1.33266
epoch 70: train loss is  1.34749
epoch 80: train loss is  1.31732
epoch 90: train loss is  1.27572
epoch 100: train loss is  1.28232
epoch 110: train loss is  1.27170
epoch 120: train loss is  1.26278
 >> Test Model
Cycle 10/10 || labeled data size 2000, test loss(MAE) =  0.77791
Finished.
>> Train vae and task model
epoch 0: train loss is  1.64367
epoch 10: train loss is  1.49654
epoch 20: train loss is  1.48554
epoch 30: train loss is  1.33041
epoch 40: train loss is  1.31840
epoch 50: train loss is  1.19438
epoch 60: train loss is  1.12798
epoch 70: train loss is  1.04776
epoch 80: train loss is  1.07181
epoch 90: train loss is  1.07003
epoch 100: train loss is  1.03954
epoch 110: train loss is  0.89869
epoch 120: train loss is  0.85846
 >> Test Model
Cycle 1/10 || labeled data size 200, test loss(MAE) =  0.69111
TA-VAAL iteration: 0 vae_loss: 1.9233933687210083 dsc_loss: 1.386457085609436
TA-VAAL iteration: 10 vae_loss: 1.7678829431533813 dsc_loss: 1.3865277767181396
TA-VAAL iteration: 20 vae_loss: 1.8140554428100586 dsc_loss: 1.387670874595642
TA-VAAL iteration: 30 vae_loss: 1.6549651622772217 dsc_loss: 1.3868446350097656
TA-VAAL iteration: 40 vae_loss: 1.7581509351730347 dsc_loss: 1.3838143348693848
TA-VAAL iteration: 50 vae_loss: 1.7517848014831543 dsc_loss: 1.3928879499435425
TA-VAAL iteration: 60 vae_loss: 1.6790847778320312 dsc_loss: 1.3914012908935547
TA-VAAL iteration: 70 vae_loss: 1.7500174045562744 dsc_loss: 1.3915845155715942
TA-VAAL iteration: 80 vae_loss: 1.720388650894165 dsc_loss: 1.394479513168335
TA-VAAL iteration: 90 vae_loss: 1.7621512413024902 dsc_loss: 1.3856830596923828
TA-VAAL iteration: 100 vae_loss: 1.6031421422958374 dsc_loss: 1.4123446941375732
TA-VAAL iteration: 200 vae_loss: 1.5440019369125366 dsc_loss: 1.4191808700561523
TA-VAAL iteration: 300 vae_loss: 1.7405232191085815 dsc_loss: 1.4004051685333252
TA-VAAL iteration: 400 vae_loss: 1.6378287076950073 dsc_loss: 1.3925776481628418
TA-VAAL iteration: 500 vae_loss: 1.6053407192230225 dsc_loss: 1.3623549938201904
TA-VAAL iteration: 600 vae_loss: 1.5898395776748657 dsc_loss: 1.4262843132019043
TA-VAAL iteration: 700 vae_loss: 1.9246816635131836 dsc_loss: 1.3855152130126953
TA-VAAL iteration: 800 vae_loss: 1.9714384078979492 dsc_loss: 1.2840436697006226
TA-VAAL iteration: 900 vae_loss: 1.903504490852356 dsc_loss: 1.3346058130264282
TA-VAAL iteration: 1000 vae_loss: 1.8118064403533936 dsc_loss: 1.321979284286499
TA-VAAL iteration: 1100 vae_loss: 1.8717418909072876 dsc_loss: 1.3161497116088867
TA-VAAL iteration: 1200 vae_loss: 2.2891552448272705 dsc_loss: 1.255175232887268
TA-VAAL iteration: 1300 vae_loss: 1.8299238681793213 dsc_loss: 1.2568469047546387
TA-VAAL iteration: 1400 vae_loss: 2.134720802307129 dsc_loss: 1.2964175939559937
TA-VAAL iteration: 1500 vae_loss: 1.9905810356140137 dsc_loss: 1.6724215745925903
TA-VAAL iteration: 1600 vae_loss: 1.9883671998977661 dsc_loss: 1.3043019771575928
TA-VAAL iteration: 1700 vae_loss: 1.9235587120056152 dsc_loss: 1.3036854267120361
TA-VAAL iteration: 1800 vae_loss: 2.327646493911743 dsc_loss: 1.4350415468215942
TA-VAAL iteration: 1900 vae_loss: 1.8088171482086182 dsc_loss: 1.3666832447052002
TA-VAAL iteration: 2000 vae_loss: 2.253171682357788 dsc_loss: 1.2808899879455566
TA-VAAL iteration: 2100 vae_loss: 1.6504685878753662 dsc_loss: 1.3845374584197998
TA-VAAL iteration: 2200 vae_loss: 2.0326151847839355 dsc_loss: 1.362861156463623
TA-VAAL iteration: 2300 vae_loss: 2.2782278060913086 dsc_loss: 1.228664755821228
TA-VAAL iteration: 2400 vae_loss: 2.267063617706299 dsc_loss: 1.292280912399292
TA-VAAL iteration: 2500 vae_loss: 2.406590461730957 dsc_loss: 1.2688060998916626
TA-VAAL iteration: 2600 vae_loss: 2.350978136062622 dsc_loss: 1.3211390972137451
TA-VAAL iteration: 2700 vae_loss: 2.7602736949920654 dsc_loss: 1.3518818616867065
TA-VAAL iteration: 2800 vae_loss: 2.427631139755249 dsc_loss: 1.3011001348495483
TA-VAAL iteration: 2900 vae_loss: 2.942979335784912 dsc_loss: 1.3166444301605225
TA-VAAL iteration: 3000 vae_loss: 2.5254619121551514 dsc_loss: 1.2720500230789185
TA-VAAL iteration: 3100 vae_loss: 2.1789281368255615 dsc_loss: 1.3347411155700684
TA-VAAL iteration: 3200 vae_loss: 2.498992443084717 dsc_loss: 1.324342966079712
TA-VAAL iteration: 3300 vae_loss: 2.6244888305664062 dsc_loss: 1.302018404006958
TA-VAAL iteration: 3400 vae_loss: 2.050297260284424 dsc_loss: 1.3706188201904297
TA-VAAL iteration: 3500 vae_loss: 2.240941047668457 dsc_loss: 1.3551974296569824
TA-VAAL iteration: 3600 vae_loss: 2.6798043251037598 dsc_loss: 1.253902554512024
TA-VAAL iteration: 3700 vae_loss: 1.9738633632659912 dsc_loss: 1.3380528688430786
TA-VAAL iteration: 3800 vae_loss: 2.5827903747558594 dsc_loss: 1.2589812278747559
TA-VAAL iteration: 3900 vae_loss: 2.6336607933044434 dsc_loss: 1.2835158109664917
TA-VAAL iteration: 4000 vae_loss: 2.668586254119873 dsc_loss: 1.3788156509399414
TA-VAAL iteration: 4100 vae_loss: 2.7247562408447266 dsc_loss: 1.3123780488967896
TA-VAAL iteration: 4200 vae_loss: 3.1717848777770996 dsc_loss: 1.4724534749984741
TA-VAAL iteration: 4300 vae_loss: 2.7115538120269775 dsc_loss: 1.3270840644836426
TA-VAAL iteration: 4400 vae_loss: 3.281132936477661 dsc_loss: 1.3967620134353638
TA-VAAL iteration: 4500 vae_loss: 2.8331120014190674 dsc_loss: 1.257836937904358
TA-VAAL iteration: 4600 vae_loss: 2.4453678131103516 dsc_loss: 1.3335000276565552
TA-VAAL iteration: 4700 vae_loss: 3.1127231121063232 dsc_loss: 1.298781394958496
TA-VAAL iteration: 4800 vae_loss: 2.6706159114837646 dsc_loss: 1.3410911560058594
TA-VAAL iteration: 4900 vae_loss: 3.421213150024414 dsc_loss: 1.2023859024047852
TA-VAAL iteration: 5000 vae_loss: 2.8692221641540527 dsc_loss: 1.205071210861206
TA-VAAL iteration: 5100 vae_loss: 3.1439733505249023 dsc_loss: 1.2217814922332764
TA-VAAL iteration: 5200 vae_loss: 3.07728910446167 dsc_loss: 1.2953739166259766
TA-VAAL iteration: 5300 vae_loss: 3.1927225589752197 dsc_loss: 1.2485461235046387
TA-VAAL iteration: 5400 vae_loss: 3.0618529319763184 dsc_loss: 1.19413423538208
TA-VAAL iteration: 5500 vae_loss: 3.2144815921783447 dsc_loss: 1.244619607925415
TA-VAAL iteration: 5600 vae_loss: 3.5139334201812744 dsc_loss: 1.2260977029800415
TA-VAAL iteration: 5700 vae_loss: 3.7236461639404297 dsc_loss: 1.340043067932129
TA-VAAL iteration: 5800 vae_loss: 3.340101718902588 dsc_loss: 1.1999175548553467
TA-VAAL iteration: 5900 vae_loss: 3.2092037200927734 dsc_loss: 1.296971082687378
TA-VAAL iteration: 6000 vae_loss: 2.8379099369049072 dsc_loss: 1.2755757570266724
TA-VAAL iteration: 6100 vae_loss: 3.183467149734497 dsc_loss: 1.358964443206787
TA-VAAL iteration: 6200 vae_loss: 3.1592400074005127 dsc_loss: 1.2117054462432861
400 106708 713 106874
>> Train vae and task model
epoch 0: train loss is  1.56441
epoch 10: train loss is  1.48905
epoch 20: train loss is  1.38785
epoch 30: train loss is  1.43544
epoch 40: train loss is  1.29486
epoch 50: train loss is  1.41254
epoch 60: train loss is  1.37063
epoch 70: train loss is  1.28056
epoch 80: train loss is  1.25543
epoch 90: train loss is  1.16323
epoch 100: train loss is  1.11186
epoch 110: train loss is  1.04890
epoch 120: train loss is  1.03769
 >> Test Model
Cycle 2/10 || labeled data size 400, test loss(MAE) =  0.75277
TA-VAAL iteration: 0 vae_loss: 1.8173563480377197 dsc_loss: 1.392031192779541
TA-VAAL iteration: 10 vae_loss: 1.5857012271881104 dsc_loss: 1.3816252946853638
TA-VAAL iteration: 20 vae_loss: 1.7506239414215088 dsc_loss: 1.383355736732483
TA-VAAL iteration: 30 vae_loss: 1.7315454483032227 dsc_loss: 1.3957023620605469
TA-VAAL iteration: 40 vae_loss: 1.8594210147857666 dsc_loss: 1.4207465648651123
TA-VAAL iteration: 50 vae_loss: 1.8260362148284912 dsc_loss: 1.3927569389343262
TA-VAAL iteration: 60 vae_loss: 1.937359094619751 dsc_loss: 1.3766885995864868
TA-VAAL iteration: 70 vae_loss: 1.760042428970337 dsc_loss: 1.3811068534851074
TA-VAAL iteration: 80 vae_loss: 1.6489512920379639 dsc_loss: 1.383049488067627
TA-VAAL iteration: 90 vae_loss: 1.5446332693099976 dsc_loss: 1.383725643157959
TA-VAAL iteration: 100 vae_loss: 1.5692193508148193 dsc_loss: 1.382662296295166
TA-VAAL iteration: 200 vae_loss: 1.587060809135437 dsc_loss: 1.3874235153198242
TA-VAAL iteration: 300 vae_loss: 1.4708799123764038 dsc_loss: 1.376183271408081
TA-VAAL iteration: 400 vae_loss: 1.6291910409927368 dsc_loss: 1.3549948930740356
TA-VAAL iteration: 500 vae_loss: 1.54288649559021 dsc_loss: 1.3185862302780151
TA-VAAL iteration: 600 vae_loss: 1.5841681957244873 dsc_loss: 1.3705763816833496
TA-VAAL iteration: 700 vae_loss: 2.1357147693634033 dsc_loss: 1.3927788734436035
TA-VAAL iteration: 800 vae_loss: 1.9527182579040527 dsc_loss: 1.3294907808303833
TA-VAAL iteration: 900 vae_loss: 2.2922418117523193 dsc_loss: 1.389495849609375
TA-VAAL iteration: 1000 vae_loss: 1.7454805374145508 dsc_loss: 1.3645988702774048
TA-VAAL iteration: 1100 vae_loss: 1.8495652675628662 dsc_loss: 1.3353331089019775
TA-VAAL iteration: 1200 vae_loss: 1.9273676872253418 dsc_loss: 1.2994985580444336
TA-VAAL iteration: 1300 vae_loss: 1.9654045104980469 dsc_loss: 1.3082959651947021
TA-VAAL iteration: 1400 vae_loss: 1.973156213760376 dsc_loss: 1.2973222732543945
TA-VAAL iteration: 1500 vae_loss: 1.8978427648544312 dsc_loss: 1.4238206148147583
TA-VAAL iteration: 1600 vae_loss: 2.064462423324585 dsc_loss: 1.3594303131103516
TA-VAAL iteration: 1700 vae_loss: 1.846712589263916 dsc_loss: 1.311198353767395
TA-VAAL iteration: 1800 vae_loss: 2.2387328147888184 dsc_loss: 1.3786110877990723
TA-VAAL iteration: 1900 vae_loss: 2.023932695388794 dsc_loss: 1.3249726295471191
TA-VAAL iteration: 2000 vae_loss: 1.9153127670288086 dsc_loss: 1.2890129089355469
TA-VAAL iteration: 2100 vae_loss: 2.764355182647705 dsc_loss: 1.3137603998184204
TA-VAAL iteration: 2200 vae_loss: 2.3368804454803467 dsc_loss: 1.2906454801559448
TA-VAAL iteration: 2300 vae_loss: 2.0768418312072754 dsc_loss: 1.2767674922943115
TA-VAAL iteration: 2400 vae_loss: 3.027895212173462 dsc_loss: 1.4974809885025024
TA-VAAL iteration: 2500 vae_loss: 2.3844449520111084 dsc_loss: 1.2944302558898926
TA-VAAL iteration: 2600 vae_loss: 2.0721166133880615 dsc_loss: 1.396937608718872
TA-VAAL iteration: 2700 vae_loss: 2.13484525680542 dsc_loss: 1.2629996538162231
TA-VAAL iteration: 2800 vae_loss: 2.6063880920410156 dsc_loss: 1.3036818504333496
TA-VAAL iteration: 2900 vae_loss: 2.799201488494873 dsc_loss: 1.3325198888778687
TA-VAAL iteration: 3000 vae_loss: 2.8273634910583496 dsc_loss: 1.3002463579177856
TA-VAAL iteration: 3100 vae_loss: 2.8358583450317383 dsc_loss: 1.2352935075759888
TA-VAAL iteration: 3200 vae_loss: 2.0971269607543945 dsc_loss: 1.2923297882080078
TA-VAAL iteration: 3300 vae_loss: 2.2673845291137695 dsc_loss: 1.2824594974517822
TA-VAAL iteration: 3400 vae_loss: 2.3430535793304443 dsc_loss: 1.2606446743011475
TA-VAAL iteration: 3500 vae_loss: 2.340057611465454 dsc_loss: 1.4079722166061401
TA-VAAL iteration: 3600 vae_loss: 2.34584903717041 dsc_loss: 1.3651264905929565
TA-VAAL iteration: 3700 vae_loss: 2.37518048286438 dsc_loss: 1.2345846891403198
TA-VAAL iteration: 3800 vae_loss: 3.5851104259490967 dsc_loss: 1.2715184688568115
TA-VAAL iteration: 3900 vae_loss: 2.3960442543029785 dsc_loss: 1.2244952917099
TA-VAAL iteration: 4000 vae_loss: 2.3276262283325195 dsc_loss: 1.2181366682052612
TA-VAAL iteration: 4100 vae_loss: 3.280876636505127 dsc_loss: 1.3445419073104858
TA-VAAL iteration: 4200 vae_loss: 2.9239602088928223 dsc_loss: 1.3688428401947021
TA-VAAL iteration: 4300 vae_loss: 2.9583802223205566 dsc_loss: 1.361699104309082
TA-VAAL iteration: 4400 vae_loss: 1.8343830108642578 dsc_loss: 1.2659164667129517
TA-VAAL iteration: 4500 vae_loss: 2.60770845413208 dsc_loss: 1.1712487936019897
TA-VAAL iteration: 4600 vae_loss: 2.3814122676849365 dsc_loss: 1.1662843227386475
TA-VAAL iteration: 4700 vae_loss: 2.7177891731262207 dsc_loss: 1.1881532669067383
TA-VAAL iteration: 4800 vae_loss: 3.0782458782196045 dsc_loss: 1.2617510557174683
TA-VAAL iteration: 4900 vae_loss: 2.2556638717651367 dsc_loss: 1.2129957675933838
TA-VAAL iteration: 5000 vae_loss: 1.927188515663147 dsc_loss: 1.3225722312927246
TA-VAAL iteration: 5100 vae_loss: 3.247232675552368 dsc_loss: 1.299338936805725
TA-VAAL iteration: 5200 vae_loss: 2.9144911766052246 dsc_loss: 1.094933032989502
TA-VAAL iteration: 5300 vae_loss: 2.263591766357422 dsc_loss: 1.1218080520629883
TA-VAAL iteration: 5400 vae_loss: 5.291659355163574 dsc_loss: 2.1977598667144775
TA-VAAL iteration: 5500 vae_loss: 4.0699782371521 dsc_loss: 1.3803675174713135
TA-VAAL iteration: 5600 vae_loss: 3.962359666824341 dsc_loss: 1.2629141807556152
TA-VAAL iteration: 5700 vae_loss: 2.97335147857666 dsc_loss: 1.3243143558502197
TA-VAAL iteration: 5800 vae_loss: 2.7579472064971924 dsc_loss: 1.270076036453247
TA-VAAL iteration: 5900 vae_loss: 3.1517579555511475 dsc_loss: 1.3263413906097412
TA-VAAL iteration: 6000 vae_loss: 2.2991890907287598 dsc_loss: 1.303498387336731
TA-VAAL iteration: 6100 vae_loss: 2.3747386932373047 dsc_loss: 1.3149323463439941
TA-VAAL iteration: 6200 vae_loss: 2.931544780731201 dsc_loss: 1.3967950344085693
TA-VAAL iteration: 6300 vae_loss: 4.080493450164795 dsc_loss: 1.2670257091522217
TA-VAAL iteration: 6400 vae_loss: 2.2502222061157227 dsc_loss: 1.4278979301452637
600 106508 603 106874
>> Train vae and task model
epoch 0: train loss is  1.55039
epoch 10: train loss is  1.49754
epoch 20: train loss is  1.40962
epoch 30: train loss is  1.36043
epoch 40: train loss is  1.29439
epoch 50: train loss is  1.19896
epoch 60: train loss is  1.22527
epoch 70: train loss is  1.09705
epoch 80: train loss is  1.09650
epoch 90: train loss is  1.08666
epoch 100: train loss is  1.05256
epoch 110: train loss is  1.04496
epoch 120: train loss is  0.99712
 >> Test Model
Cycle 3/10 || labeled data size 600, test loss(MAE) =  0.77546
TA-VAAL iteration: 0 vae_loss: 1.8556665182113647 dsc_loss: 1.3871376514434814
TA-VAAL iteration: 10 vae_loss: 1.354888677597046 dsc_loss: 1.4665131568908691
TA-VAAL iteration: 20 vae_loss: 1.6874077320098877 dsc_loss: 1.4078004360198975
TA-VAAL iteration: 30 vae_loss: 1.997592568397522 dsc_loss: 1.4039313793182373
TA-VAAL iteration: 40 vae_loss: 1.763474941253662 dsc_loss: 1.4133028984069824
TA-VAAL iteration: 50 vae_loss: 1.7997206449508667 dsc_loss: 1.4013123512268066
TA-VAAL iteration: 60 vae_loss: 1.8762726783752441 dsc_loss: 1.3897395133972168
TA-VAAL iteration: 70 vae_loss: 1.8175771236419678 dsc_loss: 1.3681905269622803
TA-VAAL iteration: 80 vae_loss: 1.9213461875915527 dsc_loss: 1.4138708114624023
TA-VAAL iteration: 90 vae_loss: 1.671768307685852 dsc_loss: 1.3875923156738281
TA-VAAL iteration: 100 vae_loss: 1.8707722425460815 dsc_loss: 1.3881072998046875
TA-VAAL iteration: 200 vae_loss: 1.817337155342102 dsc_loss: 1.3969683647155762
TA-VAAL iteration: 300 vae_loss: 1.3376901149749756 dsc_loss: 1.4047632217407227
TA-VAAL iteration: 400 vae_loss: 1.6341372728347778 dsc_loss: 1.4132121801376343
TA-VAAL iteration: 500 vae_loss: 1.4579461812973022 dsc_loss: 1.3761037588119507
TA-VAAL iteration: 600 vae_loss: 1.6560266017913818 dsc_loss: 1.3651072978973389
TA-VAAL iteration: 700 vae_loss: 1.4660383462905884 dsc_loss: 1.3941352367401123
TA-VAAL iteration: 800 vae_loss: 1.5339620113372803 dsc_loss: 1.3936718702316284
TA-VAAL iteration: 900 vae_loss: 1.4112075567245483 dsc_loss: 1.3790682554244995
TA-VAAL iteration: 1000 vae_loss: 1.4958635568618774 dsc_loss: 1.4229607582092285
TA-VAAL iteration: 1100 vae_loss: 1.5165314674377441 dsc_loss: 1.3856847286224365
TA-VAAL iteration: 1200 vae_loss: 1.4163117408752441 dsc_loss: 1.3923732042312622
TA-VAAL iteration: 1300 vae_loss: 1.4945496320724487 dsc_loss: 1.3714394569396973
TA-VAAL iteration: 1400 vae_loss: 1.533264398574829 dsc_loss: 1.3857035636901855
TA-VAAL iteration: 1500 vae_loss: 1.4608900547027588 dsc_loss: 1.4260679483413696
TA-VAAL iteration: 1600 vae_loss: 1.5648926496505737 dsc_loss: 1.3756077289581299
TA-VAAL iteration: 1700 vae_loss: 1.56037437915802 dsc_loss: 1.387667179107666
TA-VAAL iteration: 1800 vae_loss: 1.5015591382980347 dsc_loss: 1.3685877323150635
TA-VAAL iteration: 1900 vae_loss: 1.5809229612350464 dsc_loss: 1.4254271984100342
TA-VAAL iteration: 2000 vae_loss: 1.536301851272583 dsc_loss: 1.392003059387207
TA-VAAL iteration: 2100 vae_loss: 1.624499797821045 dsc_loss: 1.4199358224868774
TA-VAAL iteration: 2200 vae_loss: 1.5633248090744019 dsc_loss: 1.3934130668640137
TA-VAAL iteration: 2300 vae_loss: 1.579947829246521 dsc_loss: 1.433884859085083
TA-VAAL iteration: 2400 vae_loss: 1.5744898319244385 dsc_loss: 1.3754513263702393
TA-VAAL iteration: 2500 vae_loss: 1.676919937133789 dsc_loss: 1.3218297958374023
TA-VAAL iteration: 2600 vae_loss: 1.5845345258712769 dsc_loss: 1.325825572013855
TA-VAAL iteration: 2700 vae_loss: 1.5199205875396729 dsc_loss: 1.300532341003418
TA-VAAL iteration: 2800 vae_loss: 1.6683093309402466 dsc_loss: 1.3174090385437012
TA-VAAL iteration: 2900 vae_loss: 1.9276025295257568 dsc_loss: 1.2973856925964355
TA-VAAL iteration: 3000 vae_loss: 1.8079832792282104 dsc_loss: 1.3041613101959229
TA-VAAL iteration: 3100 vae_loss: 1.7661547660827637 dsc_loss: 1.3436777591705322
TA-VAAL iteration: 3200 vae_loss: 1.9517498016357422 dsc_loss: 1.2954978942871094
TA-VAAL iteration: 3300 vae_loss: 1.960659146308899 dsc_loss: 1.3281713724136353
TA-VAAL iteration: 3400 vae_loss: 2.0929248332977295 dsc_loss: 1.3214447498321533
TA-VAAL iteration: 3500 vae_loss: 1.8941309452056885 dsc_loss: 1.315565586090088
TA-VAAL iteration: 3600 vae_loss: 1.9428598880767822 dsc_loss: 1.2896357774734497
TA-VAAL iteration: 3700 vae_loss: 2.1384458541870117 dsc_loss: 1.3091386556625366
TA-VAAL iteration: 3800 vae_loss: 2.3055477142333984 dsc_loss: 1.3136054277420044
TA-VAAL iteration: 3900 vae_loss: 1.9509696960449219 dsc_loss: 1.2704181671142578
TA-VAAL iteration: 4000 vae_loss: 2.129514694213867 dsc_loss: 1.2741856575012207
TA-VAAL iteration: 4100 vae_loss: 2.1650943756103516 dsc_loss: 1.27436363697052
TA-VAAL iteration: 4200 vae_loss: 1.934099793434143 dsc_loss: 1.3394393920898438
TA-VAAL iteration: 4300 vae_loss: 2.637204170227051 dsc_loss: 1.2816028594970703
TA-VAAL iteration: 4400 vae_loss: 2.2296297550201416 dsc_loss: 1.262574553489685
TA-VAAL iteration: 4500 vae_loss: 2.0498275756835938 dsc_loss: 1.2151128053665161
TA-VAAL iteration: 4600 vae_loss: 2.23913311958313 dsc_loss: 1.311678409576416
TA-VAAL iteration: 4700 vae_loss: 2.1074371337890625 dsc_loss: 1.3152189254760742
TA-VAAL iteration: 4800 vae_loss: 2.1307005882263184 dsc_loss: 1.276912808418274
TA-VAAL iteration: 4900 vae_loss: 2.6865053176879883 dsc_loss: 1.3177118301391602
TA-VAAL iteration: 5000 vae_loss: 2.2237753868103027 dsc_loss: 1.2767117023468018
TA-VAAL iteration: 5100 vae_loss: 2.4520463943481445 dsc_loss: 1.258926272392273
TA-VAAL iteration: 5200 vae_loss: 2.2571520805358887 dsc_loss: 1.2934074401855469
TA-VAAL iteration: 5300 vae_loss: 2.7402596473693848 dsc_loss: 1.3018944263458252
TA-VAAL iteration: 5400 vae_loss: 1.9743657112121582 dsc_loss: 1.307582139968872
TA-VAAL iteration: 5500 vae_loss: 2.258606433868408 dsc_loss: 1.285135269165039
TA-VAAL iteration: 5600 vae_loss: 2.671457290649414 dsc_loss: 1.256967306137085
TA-VAAL iteration: 5700 vae_loss: 1.7195630073547363 dsc_loss: 1.3137004375457764
TA-VAAL iteration: 5800 vae_loss: 2.3263237476348877 dsc_loss: 1.2794601917266846
TA-VAAL iteration: 5900 vae_loss: 1.8612877130508423 dsc_loss: 1.2764205932617188
TA-VAAL iteration: 6000 vae_loss: 1.8954285383224487 dsc_loss: 1.2816624641418457
TA-VAAL iteration: 6100 vae_loss: 2.0257585048675537 dsc_loss: 1.3149352073669434
TA-VAAL iteration: 6200 vae_loss: 2.217479944229126 dsc_loss: 1.2619397640228271
TA-VAAL iteration: 6300 vae_loss: 2.3528127670288086 dsc_loss: 1.2486791610717773
TA-VAAL iteration: 6400 vae_loss: 2.2318334579467773 dsc_loss: 1.3141250610351562
TA-VAAL iteration: 6500 vae_loss: 2.289257764816284 dsc_loss: 1.2488455772399902
TA-VAAL iteration: 6600 vae_loss: 2.1135265827178955 dsc_loss: 1.343289852142334
TA-VAAL iteration: 6700 vae_loss: 2.119776487350464 dsc_loss: 1.2495770454406738
800 106308 562 106874
>> Train vae and task model
epoch 0: train loss is  1.54036
epoch 10: train loss is  1.31589
epoch 20: train loss is  1.12807
epoch 30: train loss is  1.03272
epoch 40: train loss is  0.97476
epoch 50: train loss is  0.95550
epoch 60: train loss is  0.98598
epoch 70: train loss is  0.91439
epoch 80: train loss is  0.86411
epoch 90: train loss is  0.87215
epoch 100: train loss is  0.87620
epoch 110: train loss is  0.91122
epoch 120: train loss is  0.88011
 >> Test Model
Cycle 4/10 || labeled data size 800, test loss(MAE) =  0.58383
TA-VAAL iteration: 0 vae_loss: 1.7358580827713013 dsc_loss: 1.401207685470581
TA-VAAL iteration: 10 vae_loss: 1.6205315589904785 dsc_loss: 1.3941459655761719
TA-VAAL iteration: 20 vae_loss: 1.6416218280792236 dsc_loss: 1.3921842575073242
TA-VAAL iteration: 30 vae_loss: 1.8026049137115479 dsc_loss: 1.3904447555541992
TA-VAAL iteration: 40 vae_loss: 1.8228511810302734 dsc_loss: 1.3936829566955566
TA-VAAL iteration: 50 vae_loss: 1.7772862911224365 dsc_loss: 1.3954153060913086
TA-VAAL iteration: 60 vae_loss: 1.9602097272872925 dsc_loss: 1.3925535678863525
TA-VAAL iteration: 70 vae_loss: 2.1264772415161133 dsc_loss: 1.4080345630645752
TA-VAAL iteration: 80 vae_loss: 1.845210313796997 dsc_loss: 1.3764383792877197
TA-VAAL iteration: 90 vae_loss: 1.8697805404663086 dsc_loss: 1.396874189376831
TA-VAAL iteration: 100 vae_loss: 1.7751152515411377 dsc_loss: 1.3937759399414062
TA-VAAL iteration: 200 vae_loss: 1.6089941263198853 dsc_loss: 1.376226544380188
TA-VAAL iteration: 300 vae_loss: 1.6425191164016724 dsc_loss: 1.3846192359924316
TA-VAAL iteration: 400 vae_loss: 1.6865571737289429 dsc_loss: 1.401228427886963
TA-VAAL iteration: 500 vae_loss: 1.6462761163711548 dsc_loss: 1.3827365636825562
TA-VAAL iteration: 600 vae_loss: 1.6429355144500732 dsc_loss: 1.3940229415893555
TA-VAAL iteration: 700 vae_loss: 1.6549437046051025 dsc_loss: 1.3876359462738037
TA-VAAL iteration: 800 vae_loss: 1.549791932106018 dsc_loss: 1.390629529953003
TA-VAAL iteration: 900 vae_loss: 1.7442805767059326 dsc_loss: 1.387428641319275
TA-VAAL iteration: 1000 vae_loss: 1.6000895500183105 dsc_loss: 1.3849953413009644
TA-VAAL iteration: 1100 vae_loss: 1.6127482652664185 dsc_loss: 1.388763189315796
TA-VAAL iteration: 1200 vae_loss: 1.6455175876617432 dsc_loss: 1.387942910194397
TA-VAAL iteration: 1300 vae_loss: 1.6357253789901733 dsc_loss: 1.3768084049224854
TA-VAAL iteration: 1400 vae_loss: 1.6830893754959106 dsc_loss: 1.3902251720428467
TA-VAAL iteration: 1500 vae_loss: 1.6895513534545898 dsc_loss: 1.380589485168457
TA-VAAL iteration: 1600 vae_loss: 1.8184218406677246 dsc_loss: 1.3866779804229736
TA-VAAL iteration: 1700 vae_loss: 1.7529289722442627 dsc_loss: 1.3815646171569824
TA-VAAL iteration: 1800 vae_loss: 1.8153660297393799 dsc_loss: 1.3854572772979736
TA-VAAL iteration: 1900 vae_loss: 1.6876386404037476 dsc_loss: 1.3945553302764893
TA-VAAL iteration: 2000 vae_loss: 1.795067548751831 dsc_loss: 1.3853654861450195
TA-VAAL iteration: 2100 vae_loss: 1.789682388305664 dsc_loss: 1.3769683837890625
TA-VAAL iteration: 2200 vae_loss: 1.7424460649490356 dsc_loss: 1.3801597356796265
TA-VAAL iteration: 2300 vae_loss: 1.7767316102981567 dsc_loss: 1.3914211988449097
TA-VAAL iteration: 2400 vae_loss: 1.919743537902832 dsc_loss: 1.3764698505401611
TA-VAAL iteration: 2500 vae_loss: 1.8201621770858765 dsc_loss: 1.3844703435897827
TA-VAAL iteration: 2600 vae_loss: 1.8261675834655762 dsc_loss: 1.3883860111236572
TA-VAAL iteration: 2700 vae_loss: 1.791298270225525 dsc_loss: 1.379359245300293
TA-VAAL iteration: 2800 vae_loss: 1.7837185859680176 dsc_loss: 1.3810406923294067
TA-VAAL iteration: 2900 vae_loss: 1.7747681140899658 dsc_loss: 1.391181468963623
TA-VAAL iteration: 3000 vae_loss: 2.0043182373046875 dsc_loss: 1.3802950382232666
TA-VAAL iteration: 3100 vae_loss: 1.9933674335479736 dsc_loss: 1.378312587738037
TA-VAAL iteration: 3200 vae_loss: 1.9163109064102173 dsc_loss: 1.3952858448028564
TA-VAAL iteration: 3300 vae_loss: 1.8779995441436768 dsc_loss: 1.3781856298446655
TA-VAAL iteration: 3400 vae_loss: 2.031052350997925 dsc_loss: 1.3771286010742188
TA-VAAL iteration: 3500 vae_loss: 2.0197174549102783 dsc_loss: 1.3922468423843384
TA-VAAL iteration: 3600 vae_loss: 2.043095588684082 dsc_loss: 1.3854801654815674
TA-VAAL iteration: 3700 vae_loss: 2.1439685821533203 dsc_loss: 1.3846766948699951
TA-VAAL iteration: 3800 vae_loss: 2.059131383895874 dsc_loss: 1.3787527084350586
TA-VAAL iteration: 3900 vae_loss: 2.106196880340576 dsc_loss: 1.3848133087158203
TA-VAAL iteration: 4000 vae_loss: 2.1418094635009766 dsc_loss: 1.377164602279663
TA-VAAL iteration: 4100 vae_loss: 2.0449905395507812 dsc_loss: 1.3857501745224
TA-VAAL iteration: 4200 vae_loss: 2.079007387161255 dsc_loss: 1.389774203300476
TA-VAAL iteration: 4300 vae_loss: 2.091050863265991 dsc_loss: 1.3867943286895752
TA-VAAL iteration: 4400 vae_loss: 2.0370430946350098 dsc_loss: 1.3907926082611084
TA-VAAL iteration: 4500 vae_loss: 2.187257766723633 dsc_loss: 1.397117018699646
TA-VAAL iteration: 4600 vae_loss: 2.129093885421753 dsc_loss: 1.386906623840332
TA-VAAL iteration: 4700 vae_loss: 1.9682879447937012 dsc_loss: 1.3922836780548096
TA-VAAL iteration: 4800 vae_loss: 2.126333475112915 dsc_loss: 1.3903086185455322
TA-VAAL iteration: 4900 vae_loss: 2.2229115962982178 dsc_loss: 1.3858017921447754
TA-VAAL iteration: 5000 vae_loss: 1.935763955116272 dsc_loss: 1.3903509378433228
TA-VAAL iteration: 5100 vae_loss: 1.9058886766433716 dsc_loss: 1.3876571655273438
TA-VAAL iteration: 5200 vae_loss: 2.104271411895752 dsc_loss: 1.3796279430389404
TA-VAAL iteration: 5300 vae_loss: 2.0767319202423096 dsc_loss: 1.3690608739852905
TA-VAAL iteration: 5400 vae_loss: 2.249063491821289 dsc_loss: 1.3861591815948486
TA-VAAL iteration: 5500 vae_loss: 2.221951723098755 dsc_loss: 1.399902582168579
TA-VAAL iteration: 5600 vae_loss: 2.280801773071289 dsc_loss: 1.3852880001068115
TA-VAAL iteration: 5700 vae_loss: 2.351193904876709 dsc_loss: 1.38014817237854
TA-VAAL iteration: 5800 vae_loss: 2.4430482387542725 dsc_loss: 1.389468789100647
TA-VAAL iteration: 5900 vae_loss: 2.2629618644714355 dsc_loss: 1.384849190711975
TA-VAAL iteration: 6000 vae_loss: 2.2926039695739746 dsc_loss: 1.3787354230880737
TA-VAAL iteration: 6100 vae_loss: 2.2136287689208984 dsc_loss: 1.3905484676361084
TA-VAAL iteration: 6200 vae_loss: 2.2544240951538086 dsc_loss: 1.376465916633606
TA-VAAL iteration: 6300 vae_loss: 2.3733675479888916 dsc_loss: 1.384765863418579
TA-VAAL iteration: 6400 vae_loss: 2.2311906814575195 dsc_loss: 1.3740272521972656
TA-VAAL iteration: 6500 vae_loss: 2.1278395652770996 dsc_loss: 1.3959547281265259
TA-VAAL iteration: 6600 vae_loss: 2.2821364402770996 dsc_loss: 1.3871760368347168
TA-VAAL iteration: 6700 vae_loss: 2.3622541427612305 dsc_loss: 1.3877817392349243
TA-VAAL iteration: 6800 vae_loss: 2.1412672996520996 dsc_loss: 1.3876193761825562
TA-VAAL iteration: 6900 vae_loss: 2.226317882537842 dsc_loss: 1.3752596378326416
1000 106108 66 106874
>> Train vae and task model
epoch 0: train loss is  1.68967
epoch 10: train loss is  1.51710
epoch 20: train loss is  1.29970
epoch 30: train loss is  1.17876
epoch 40: train loss is  1.12174
epoch 50: train loss is  1.05449
epoch 60: train loss is  1.11693
epoch 70: train loss is  0.99323
epoch 80: train loss is  1.07860
epoch 90: train loss is  1.05797
epoch 100: train loss is  0.99903
epoch 110: train loss is  1.02064
epoch 120: train loss is  0.98411
 >> Test Model
Cycle 5/10 || labeled data size 1000, test loss(MAE) =  0.53339
TA-VAAL iteration: 0 vae_loss: 1.6624345779418945 dsc_loss: 1.4255115985870361
TA-VAAL iteration: 10 vae_loss: 1.8161921501159668 dsc_loss: 1.3823792934417725
TA-VAAL iteration: 20 vae_loss: 1.8304696083068848 dsc_loss: 1.509735107421875
TA-VAAL iteration: 30 vae_loss: 1.620942234992981 dsc_loss: 1.303007960319519
TA-VAAL iteration: 40 vae_loss: 2.036985397338867 dsc_loss: 1.401564359664917
TA-VAAL iteration: 50 vae_loss: 1.9716453552246094 dsc_loss: 1.4695312976837158
TA-VAAL iteration: 60 vae_loss: 1.7537304162979126 dsc_loss: 1.456472635269165
TA-VAAL iteration: 70 vae_loss: 1.7926174402236938 dsc_loss: 1.4323545694351196
TA-VAAL iteration: 80 vae_loss: 1.5116029977798462 dsc_loss: 1.4360090494155884
TA-VAAL iteration: 90 vae_loss: 1.7187740802764893 dsc_loss: 1.3938482999801636
TA-VAAL iteration: 100 vae_loss: 1.6119461059570312 dsc_loss: 1.4489436149597168
TA-VAAL iteration: 200 vae_loss: 1.5527101755142212 dsc_loss: 1.400068998336792
TA-VAAL iteration: 300 vae_loss: 1.6117225885391235 dsc_loss: 1.3584060668945312
TA-VAAL iteration: 400 vae_loss: 1.6040560007095337 dsc_loss: 1.4137593507766724
TA-VAAL iteration: 500 vae_loss: 1.605125904083252 dsc_loss: 1.4116266965866089
TA-VAAL iteration: 600 vae_loss: 1.4930061101913452 dsc_loss: 1.4181649684906006
TA-VAAL iteration: 700 vae_loss: 1.5207456350326538 dsc_loss: 1.3518706560134888
TA-VAAL iteration: 800 vae_loss: 1.9765276908874512 dsc_loss: 1.401718020439148
TA-VAAL iteration: 900 vae_loss: 1.467779517173767 dsc_loss: 1.401246190071106
TA-VAAL iteration: 1000 vae_loss: 1.3956387042999268 dsc_loss: 1.3655781745910645
TA-VAAL iteration: 1100 vae_loss: 1.4490206241607666 dsc_loss: 1.3460770845413208
TA-VAAL iteration: 1200 vae_loss: 1.8238751888275146 dsc_loss: 1.391049861907959
TA-VAAL iteration: 1300 vae_loss: 1.7178587913513184 dsc_loss: 1.3577933311462402
TA-VAAL iteration: 1400 vae_loss: 1.543859601020813 dsc_loss: 1.3801226615905762
TA-VAAL iteration: 1500 vae_loss: 1.6460139751434326 dsc_loss: 1.317711353302002
TA-VAAL iteration: 1600 vae_loss: 1.8172483444213867 dsc_loss: 1.4361236095428467
TA-VAAL iteration: 1700 vae_loss: 1.7632710933685303 dsc_loss: 1.4096604585647583
TA-VAAL iteration: 1800 vae_loss: 1.403195858001709 dsc_loss: 1.3605284690856934
TA-VAAL iteration: 1900 vae_loss: 1.4410208463668823 dsc_loss: 1.3497178554534912
TA-VAAL iteration: 2000 vae_loss: 1.6167505979537964 dsc_loss: 1.3634600639343262
TA-VAAL iteration: 2100 vae_loss: 1.6562906503677368 dsc_loss: 1.4188663959503174
TA-VAAL iteration: 2200 vae_loss: 1.5459145307540894 dsc_loss: 1.402967929840088
TA-VAAL iteration: 2300 vae_loss: 1.5069047212600708 dsc_loss: 1.3317372798919678
TA-VAAL iteration: 2400 vae_loss: 1.554364562034607 dsc_loss: 1.4343546628952026
TA-VAAL iteration: 2500 vae_loss: 1.765165090560913 dsc_loss: 1.4084975719451904
TA-VAAL iteration: 2600 vae_loss: 1.6294043064117432 dsc_loss: 1.381460189819336
TA-VAAL iteration: 2700 vae_loss: 1.4917716979980469 dsc_loss: 1.367604374885559
TA-VAAL iteration: 2800 vae_loss: 1.9177258014678955 dsc_loss: 1.4094842672348022
TA-VAAL iteration: 2900 vae_loss: 1.6566683053970337 dsc_loss: 1.3699564933776855
TA-VAAL iteration: 3000 vae_loss: 1.5917437076568604 dsc_loss: 1.380102515220642
TA-VAAL iteration: 3100 vae_loss: 1.4688420295715332 dsc_loss: 1.3507227897644043
TA-VAAL iteration: 3200 vae_loss: 1.6527348756790161 dsc_loss: 1.3834835290908813
TA-VAAL iteration: 3300 vae_loss: 1.6712074279785156 dsc_loss: 1.4306244850158691
TA-VAAL iteration: 3400 vae_loss: 1.5893769264221191 dsc_loss: 1.3814647197723389
TA-VAAL iteration: 3500 vae_loss: 1.5815125703811646 dsc_loss: 1.34764564037323
TA-VAAL iteration: 3600 vae_loss: 1.5872610807418823 dsc_loss: 1.4117155075073242
TA-VAAL iteration: 3700 vae_loss: 1.7341675758361816 dsc_loss: 1.4209754467010498
TA-VAAL iteration: 3800 vae_loss: 1.5828721523284912 dsc_loss: 1.3908709287643433
TA-VAAL iteration: 3900 vae_loss: 1.5156142711639404 dsc_loss: 1.3405230045318604
TA-VAAL iteration: 4000 vae_loss: 1.6264898777008057 dsc_loss: 1.3693716526031494
TA-VAAL iteration: 4100 vae_loss: 1.6120092868804932 dsc_loss: 1.4665882587432861
TA-VAAL iteration: 4200 vae_loss: 1.6487971544265747 dsc_loss: 1.3703535795211792
TA-VAAL iteration: 4300 vae_loss: 1.4929643869400024 dsc_loss: 1.3565983772277832
TA-VAAL iteration: 4400 vae_loss: 1.5524529218673706 dsc_loss: 1.4290666580200195
TA-VAAL iteration: 4500 vae_loss: 1.6833069324493408 dsc_loss: 1.4389772415161133
TA-VAAL iteration: 4600 vae_loss: 1.5802994966506958 dsc_loss: 1.373753547668457
TA-VAAL iteration: 4700 vae_loss: 1.5521013736724854 dsc_loss: 1.353597640991211
TA-VAAL iteration: 4800 vae_loss: 1.605163335800171 dsc_loss: 1.399235486984253
TA-VAAL iteration: 4900 vae_loss: 1.6116232872009277 dsc_loss: 1.4278919696807861
TA-VAAL iteration: 5000 vae_loss: 1.6723564863204956 dsc_loss: 1.3664016723632812
TA-VAAL iteration: 5100 vae_loss: 1.5146737098693848 dsc_loss: 1.3270057439804077
TA-VAAL iteration: 5200 vae_loss: 1.5363746881484985 dsc_loss: 1.3959345817565918
TA-VAAL iteration: 5300 vae_loss: 1.523356556892395 dsc_loss: 1.459089756011963
TA-VAAL iteration: 5400 vae_loss: 1.6142948865890503 dsc_loss: 1.378543734550476
TA-VAAL iteration: 5500 vae_loss: 1.5072388648986816 dsc_loss: 1.3132575750350952
TA-VAAL iteration: 5600 vae_loss: 1.6143536567687988 dsc_loss: 1.3651937246322632
TA-VAAL iteration: 5700 vae_loss: 1.6117104291915894 dsc_loss: 1.4345355033874512
TA-VAAL iteration: 5800 vae_loss: 1.6143920421600342 dsc_loss: 1.3836474418640137
TA-VAAL iteration: 5900 vae_loss: 1.5124540328979492 dsc_loss: 1.3553059101104736
TA-VAAL iteration: 6000 vae_loss: 1.6363486051559448 dsc_loss: 1.373769998550415
TA-VAAL iteration: 6100 vae_loss: 1.6537492275238037 dsc_loss: 1.4090850353240967
TA-VAAL iteration: 6200 vae_loss: 1.617544174194336 dsc_loss: 1.4162235260009766
TA-VAAL iteration: 6300 vae_loss: 1.5371850728988647 dsc_loss: 1.3523621559143066
TA-VAAL iteration: 6400 vae_loss: 1.6572788953781128 dsc_loss: 1.3811274766921997
TA-VAAL iteration: 6500 vae_loss: 1.7005776166915894 dsc_loss: 1.412074089050293
TA-VAAL iteration: 6600 vae_loss: 1.6788214445114136 dsc_loss: 1.359108805656433
TA-VAAL iteration: 6700 vae_loss: 1.5395108461380005 dsc_loss: 1.3236809968948364
TA-VAAL iteration: 6800 vae_loss: 1.6558700799942017 dsc_loss: 1.374197244644165
TA-VAAL iteration: 6900 vae_loss: 1.7529536485671997 dsc_loss: 1.384748935699463
TA-VAAL iteration: 7000 vae_loss: 1.7143023014068604 dsc_loss: 1.3768634796142578
TA-VAAL iteration: 7100 vae_loss: 1.5464168787002563 dsc_loss: 1.3233277797698975
TA-VAAL iteration: 7200 vae_loss: 1.6781891584396362 dsc_loss: 1.3575735092163086
1200 105908 66 106971
>> Train vae and task model
epoch 0: train loss is  1.64266
epoch 10: train loss is  1.52450
epoch 20: train loss is  1.29800
epoch 30: train loss is  1.14991
epoch 40: train loss is  1.04548
epoch 50: train loss is  1.03736
epoch 60: train loss is  1.05333
epoch 70: train loss is  1.10626
epoch 80: train loss is  1.07736
epoch 90: train loss is  0.96902
epoch 100: train loss is  0.99260
epoch 110: train loss is  0.96097
epoch 120: train loss is  0.98988
 >> Test Model
Cycle 6/10 || labeled data size 1200, test loss(MAE) =  0.54322
TA-VAAL iteration: 0 vae_loss: 1.8740346431732178 dsc_loss: 1.3876628875732422
TA-VAAL iteration: 10 vae_loss: 1.8228702545166016 dsc_loss: 1.395482063293457
TA-VAAL iteration: 20 vae_loss: 1.858656644821167 dsc_loss: 1.596041202545166
TA-VAAL iteration: 30 vae_loss: 1.6996984481811523 dsc_loss: 1.3769338130950928
TA-VAAL iteration: 40 vae_loss: 1.8164942264556885 dsc_loss: 1.5519137382507324
TA-VAAL iteration: 50 vae_loss: 1.715705156326294 dsc_loss: 1.4807604551315308
TA-VAAL iteration: 60 vae_loss: 1.5056161880493164 dsc_loss: 1.39876389503479
TA-VAAL iteration: 70 vae_loss: 1.576427936553955 dsc_loss: 1.4704358577728271
TA-VAAL iteration: 80 vae_loss: 1.5865614414215088 dsc_loss: 1.441856026649475
TA-VAAL iteration: 90 vae_loss: 1.6359570026397705 dsc_loss: 1.4101901054382324
TA-VAAL iteration: 100 vae_loss: 1.7223002910614014 dsc_loss: 1.382981300354004
TA-VAAL iteration: 200 vae_loss: 1.6265501976013184 dsc_loss: 1.4072215557098389
TA-VAAL iteration: 300 vae_loss: 1.4760011434555054 dsc_loss: 1.288948655128479
TA-VAAL iteration: 400 vae_loss: 1.670207142829895 dsc_loss: 1.4983716011047363
TA-VAAL iteration: 500 vae_loss: 1.4424045085906982 dsc_loss: 1.4432426691055298
TA-VAAL iteration: 600 vae_loss: 1.5379514694213867 dsc_loss: 1.3952717781066895
TA-VAAL iteration: 700 vae_loss: 1.560563564300537 dsc_loss: 1.379103422164917
TA-VAAL iteration: 800 vae_loss: 1.5915870666503906 dsc_loss: 1.4193651676177979
TA-VAAL iteration: 900 vae_loss: 1.587740182876587 dsc_loss: 1.41157066822052
TA-VAAL iteration: 1000 vae_loss: 1.5212929248809814 dsc_loss: 1.3657112121582031
TA-VAAL iteration: 1100 vae_loss: 1.6062507629394531 dsc_loss: 1.3838098049163818
TA-VAAL iteration: 1200 vae_loss: 1.6104696989059448 dsc_loss: 1.388779878616333
TA-VAAL iteration: 1300 vae_loss: 1.5779211521148682 dsc_loss: 1.3641042709350586
TA-VAAL iteration: 1400 vae_loss: 1.505968689918518 dsc_loss: 1.2862036228179932
TA-VAAL iteration: 1500 vae_loss: 1.7352588176727295 dsc_loss: 1.3191661834716797
TA-VAAL iteration: 1600 vae_loss: 1.5251790285110474 dsc_loss: 1.3949859142303467
TA-VAAL iteration: 1700 vae_loss: 1.5446898937225342 dsc_loss: 1.3848114013671875
TA-VAAL iteration: 1800 vae_loss: 1.5509721040725708 dsc_loss: 1.2872517108917236
TA-VAAL iteration: 1900 vae_loss: 1.6184792518615723 dsc_loss: 1.3947727680206299
TA-VAAL iteration: 2000 vae_loss: 1.560929298400879 dsc_loss: 1.3593933582305908
TA-VAAL iteration: 2100 vae_loss: 1.5742740631103516 dsc_loss: 1.408858060836792
TA-VAAL iteration: 2200 vae_loss: 1.45667564868927 dsc_loss: 1.262927770614624
TA-VAAL iteration: 2300 vae_loss: 1.8029600381851196 dsc_loss: 1.413489580154419
TA-VAAL iteration: 2400 vae_loss: 1.5579646825790405 dsc_loss: 1.404305100440979
TA-VAAL iteration: 2500 vae_loss: 1.5869685411453247 dsc_loss: 1.4190969467163086
TA-VAAL iteration: 2600 vae_loss: 1.607386589050293 dsc_loss: 1.328549861907959
TA-VAAL iteration: 2700 vae_loss: 1.7420047521591187 dsc_loss: 1.4242353439331055
TA-VAAL iteration: 2800 vae_loss: 1.6834259033203125 dsc_loss: 1.4174671173095703
TA-VAAL iteration: 2900 vae_loss: 1.5480886697769165 dsc_loss: 1.3501830101013184
TA-VAAL iteration: 3000 vae_loss: 1.5689961910247803 dsc_loss: 1.3255698680877686
TA-VAAL iteration: 3100 vae_loss: 1.6458728313446045 dsc_loss: 1.4079511165618896
TA-VAAL iteration: 3200 vae_loss: 1.621260404586792 dsc_loss: 1.3977471590042114
TA-VAAL iteration: 3300 vae_loss: 1.5063300132751465 dsc_loss: 1.258988380432129
TA-VAAL iteration: 3400 vae_loss: 1.6781936883926392 dsc_loss: 1.3334615230560303
TA-VAAL iteration: 3500 vae_loss: 1.6870675086975098 dsc_loss: 1.3966007232666016
TA-VAAL iteration: 3600 vae_loss: 1.603126049041748 dsc_loss: 1.4176464080810547
TA-VAAL iteration: 3700 vae_loss: 1.564906120300293 dsc_loss: 1.2509536743164062
TA-VAAL iteration: 3800 vae_loss: 1.788666009902954 dsc_loss: 1.3699300289154053
TA-VAAL iteration: 3900 vae_loss: 1.6672999858856201 dsc_loss: 1.4193923473358154
TA-VAAL iteration: 4000 vae_loss: 1.6766127347946167 dsc_loss: 1.4145469665527344
TA-VAAL iteration: 4100 vae_loss: 1.720517873764038 dsc_loss: 1.2250032424926758
TA-VAAL iteration: 4200 vae_loss: 1.8230373859405518 dsc_loss: 1.4336965084075928
TA-VAAL iteration: 4300 vae_loss: 1.7418725490570068 dsc_loss: 1.4290357828140259
TA-VAAL iteration: 4400 vae_loss: 1.6815550327301025 dsc_loss: 1.4249486923217773
TA-VAAL iteration: 4500 vae_loss: 1.739819884300232 dsc_loss: 1.3252787590026855
TA-VAAL iteration: 4600 vae_loss: 1.8333873748779297 dsc_loss: 1.396174430847168
TA-VAAL iteration: 4700 vae_loss: 1.6870481967926025 dsc_loss: 1.403672695159912
TA-VAAL iteration: 4800 vae_loss: 1.5989599227905273 dsc_loss: 1.3337979316711426
TA-VAAL iteration: 4900 vae_loss: 1.6585607528686523 dsc_loss: 1.3260283470153809
TA-VAAL iteration: 5000 vae_loss: 1.743830680847168 dsc_loss: 1.392662763595581
TA-VAAL iteration: 5100 vae_loss: 1.67649507522583 dsc_loss: 1.4166895151138306
TA-VAAL iteration: 5200 vae_loss: 1.5812307596206665 dsc_loss: 1.2416030168533325
TA-VAAL iteration: 5300 vae_loss: 1.7456190586090088 dsc_loss: 1.3691105842590332
TA-VAAL iteration: 5400 vae_loss: 1.6898176670074463 dsc_loss: 1.408632516860962
TA-VAAL iteration: 5500 vae_loss: 1.7379133701324463 dsc_loss: 1.3659160137176514
TA-VAAL iteration: 5600 vae_loss: 1.5996191501617432 dsc_loss: 1.2551838159561157
TA-VAAL iteration: 5700 vae_loss: 1.7611751556396484 dsc_loss: 1.409172773361206
TA-VAAL iteration: 5800 vae_loss: 1.7668761014938354 dsc_loss: 1.436415672302246
TA-VAAL iteration: 5900 vae_loss: 1.7423810958862305 dsc_loss: 1.420148491859436
TA-VAAL iteration: 6000 vae_loss: 1.5687769651412964 dsc_loss: 1.260880470275879
TA-VAAL iteration: 6100 vae_loss: 1.8809278011322021 dsc_loss: 1.4172637462615967
TA-VAAL iteration: 6200 vae_loss: 1.7764873504638672 dsc_loss: 1.3947194814682007
TA-VAAL iteration: 6300 vae_loss: 1.7077301740646362 dsc_loss: 1.437265396118164
TA-VAAL iteration: 6400 vae_loss: 1.7463144063949585 dsc_loss: 1.3219096660614014
TA-VAAL iteration: 6500 vae_loss: 1.858168363571167 dsc_loss: 1.3856725692749023
TA-VAAL iteration: 6600 vae_loss: 1.8440358638763428 dsc_loss: 1.4261877536773682
TA-VAAL iteration: 6700 vae_loss: 1.8415758609771729 dsc_loss: 1.3340635299682617
TA-VAAL iteration: 6800 vae_loss: 1.8480799198150635 dsc_loss: 1.292382001876831
TA-VAAL iteration: 6900 vae_loss: 1.7752069234848022 dsc_loss: 1.4265735149383545
TA-VAAL iteration: 7000 vae_loss: 1.825934648513794 dsc_loss: 1.3936278820037842
TA-VAAL iteration: 7100 vae_loss: 1.5654783248901367 dsc_loss: 1.2413116693496704
TA-VAAL iteration: 7200 vae_loss: 1.886887788772583 dsc_loss: 1.332247018814087
TA-VAAL iteration: 7300 vae_loss: 1.8579022884368896 dsc_loss: 1.4314098358154297
TA-VAAL iteration: 7400 vae_loss: 1.7956671714782715 dsc_loss: 1.401948094367981
1400 105708 66 106971
>> Train vae and task model
epoch 0: train loss is  1.60639
epoch 10: train loss is  1.50752
epoch 20: train loss is  1.44108
epoch 30: train loss is  1.34169
epoch 40: train loss is  1.31258
epoch 50: train loss is  1.24624
epoch 60: train loss is  1.22971
epoch 70: train loss is  1.21389
epoch 80: train loss is  1.21245
epoch 90: train loss is  1.18218
epoch 100: train loss is  1.16838
epoch 110: train loss is  1.16490
epoch 120: train loss is  1.13688
 >> Test Model
Cycle 7/10 || labeled data size 1400, test loss(MAE) =  0.77546
TA-VAAL iteration: 0 vae_loss: 1.687985897064209 dsc_loss: 1.4061105251312256
TA-VAAL iteration: 10 vae_loss: 1.5440932512283325 dsc_loss: 1.420304536819458
TA-VAAL iteration: 20 vae_loss: 1.2017605304718018 dsc_loss: 1.5599792003631592
TA-VAAL iteration: 30 vae_loss: 1.5604411363601685 dsc_loss: 1.394381046295166
TA-VAAL iteration: 40 vae_loss: 1.612850546836853 dsc_loss: 1.6067168712615967
TA-VAAL iteration: 50 vae_loss: 1.526257038116455 dsc_loss: 1.4005851745605469
TA-VAAL iteration: 60 vae_loss: 2.0243592262268066 dsc_loss: 1.5557161569595337
TA-VAAL iteration: 70 vae_loss: 1.7800651788711548 dsc_loss: 1.3833171129226685
TA-VAAL iteration: 80 vae_loss: 1.6373354196548462 dsc_loss: 1.3336384296417236
TA-VAAL iteration: 90 vae_loss: 2.087428331375122 dsc_loss: 1.3902395963668823
TA-VAAL iteration: 100 vae_loss: 1.916405200958252 dsc_loss: 1.38751220703125
TA-VAAL iteration: 200 vae_loss: 1.8641438484191895 dsc_loss: 1.3971023559570312
TA-VAAL iteration: 300 vae_loss: 1.6290149688720703 dsc_loss: 1.3406481742858887
TA-VAAL iteration: 400 vae_loss: 1.4574617147445679 dsc_loss: 1.4111342430114746
TA-VAAL iteration: 500 vae_loss: 1.6429117918014526 dsc_loss: 1.4074163436889648
TA-VAAL iteration: 600 vae_loss: 1.4760932922363281 dsc_loss: 1.3910729885101318
TA-VAAL iteration: 700 vae_loss: 1.7549189329147339 dsc_loss: 1.444650650024414
TA-VAAL iteration: 800 vae_loss: 1.4886094331741333 dsc_loss: 1.3889334201812744
TA-VAAL iteration: 900 vae_loss: 1.5967791080474854 dsc_loss: 1.423559308052063
TA-VAAL iteration: 1000 vae_loss: 1.4727554321289062 dsc_loss: 1.3940670490264893
TA-VAAL iteration: 1100 vae_loss: 1.5590120553970337 dsc_loss: 1.3593544960021973
TA-VAAL iteration: 1200 vae_loss: 1.4868371486663818 dsc_loss: 1.363150715827942
TA-VAAL iteration: 1300 vae_loss: 1.4568123817443848 dsc_loss: 1.3772435188293457
TA-VAAL iteration: 1400 vae_loss: 1.5608099699020386 dsc_loss: 1.3931658267974854
TA-VAAL iteration: 1500 vae_loss: 1.4269382953643799 dsc_loss: 1.4339861869812012
TA-VAAL iteration: 1600 vae_loss: 1.5307036638259888 dsc_loss: 1.4093255996704102
TA-VAAL iteration: 1700 vae_loss: 1.5408961772918701 dsc_loss: 1.3840794563293457
TA-VAAL iteration: 1800 vae_loss: 1.6562331914901733 dsc_loss: 1.405580759048462
TA-VAAL iteration: 1900 vae_loss: 1.6667118072509766 dsc_loss: 1.3861674070358276
TA-VAAL iteration: 2000 vae_loss: 1.6004085540771484 dsc_loss: 1.3853293657302856
TA-VAAL iteration: 2100 vae_loss: 1.6201152801513672 dsc_loss: 1.3914768695831299
TA-VAAL iteration: 2200 vae_loss: 1.491180419921875 dsc_loss: 1.3847296237945557
TA-VAAL iteration: 2300 vae_loss: 1.5601887702941895 dsc_loss: 1.3573317527770996
TA-VAAL iteration: 2400 vae_loss: 1.5262665748596191 dsc_loss: 1.3662415742874146
TA-VAAL iteration: 2500 vae_loss: 1.5440093278884888 dsc_loss: 1.3583954572677612
TA-VAAL iteration: 2600 vae_loss: 1.5438309907913208 dsc_loss: 1.3976953029632568
TA-VAAL iteration: 2700 vae_loss: 1.5882556438446045 dsc_loss: 1.413184404373169
TA-VAAL iteration: 2800 vae_loss: 1.5420210361480713 dsc_loss: 1.3862817287445068
TA-VAAL iteration: 2900 vae_loss: 1.616685152053833 dsc_loss: 1.3921482563018799
TA-VAAL iteration: 3000 vae_loss: 1.5598530769348145 dsc_loss: 1.4022245407104492
TA-VAAL iteration: 3100 vae_loss: 1.5714701414108276 dsc_loss: 1.3821513652801514
TA-VAAL iteration: 3200 vae_loss: 1.6086835861206055 dsc_loss: 1.4034651517868042
TA-VAAL iteration: 3300 vae_loss: 1.5757055282592773 dsc_loss: 1.376544713973999
TA-VAAL iteration: 3400 vae_loss: 1.560575008392334 dsc_loss: 1.375191330909729
TA-VAAL iteration: 3500 vae_loss: 1.5377516746520996 dsc_loss: 1.3669973611831665
TA-VAAL iteration: 3600 vae_loss: 1.5854697227478027 dsc_loss: 1.367218255996704
TA-VAAL iteration: 3700 vae_loss: 1.566241979598999 dsc_loss: 1.3999541997909546
TA-VAAL iteration: 3800 vae_loss: 1.6568137407302856 dsc_loss: 1.4080679416656494
TA-VAAL iteration: 3900 vae_loss: 1.581463098526001 dsc_loss: 1.3995163440704346
TA-VAAL iteration: 4000 vae_loss: 1.6424492597579956 dsc_loss: 1.3968082666397095
TA-VAAL iteration: 4100 vae_loss: 1.5705571174621582 dsc_loss: 1.3953962326049805
TA-VAAL iteration: 4200 vae_loss: 1.6865243911743164 dsc_loss: 1.3661561012268066
TA-VAAL iteration: 4300 vae_loss: 1.6233018636703491 dsc_loss: 1.3946659564971924
TA-VAAL iteration: 4400 vae_loss: 1.5665911436080933 dsc_loss: 1.376633882522583
TA-VAAL iteration: 4500 vae_loss: 1.6012001037597656 dsc_loss: 1.380710482597351
TA-VAAL iteration: 4600 vae_loss: 1.560182809829712 dsc_loss: 1.3729490041732788
TA-VAAL iteration: 4700 vae_loss: 1.6702978610992432 dsc_loss: 1.3404968976974487
TA-VAAL iteration: 4800 vae_loss: 1.5835890769958496 dsc_loss: 1.410212755203247
TA-VAAL iteration: 4900 vae_loss: 1.660720705986023 dsc_loss: 1.409520149230957
TA-VAAL iteration: 5000 vae_loss: 1.5623043775558472 dsc_loss: 1.392704725265503
TA-VAAL iteration: 5100 vae_loss: 1.668924331665039 dsc_loss: 1.3997660875320435
TA-VAAL iteration: 5200 vae_loss: 1.6157686710357666 dsc_loss: 1.3966999053955078
TA-VAAL iteration: 5300 vae_loss: 1.674665927886963 dsc_loss: 1.3730899095535278
TA-VAAL iteration: 5400 vae_loss: 1.6100231409072876 dsc_loss: 1.3948596715927124
TA-VAAL iteration: 5500 vae_loss: 1.5623055696487427 dsc_loss: 1.376886248588562
TA-VAAL iteration: 5600 vae_loss: 1.6076757907867432 dsc_loss: 1.3730757236480713
TA-VAAL iteration: 5700 vae_loss: 1.505965232849121 dsc_loss: 1.381217122077942
TA-VAAL iteration: 5800 vae_loss: 1.6239842176437378 dsc_loss: 1.3471624851226807
TA-VAAL iteration: 5900 vae_loss: 1.6128435134887695 dsc_loss: 1.394216775894165
TA-VAAL iteration: 6000 vae_loss: 1.6923577785491943 dsc_loss: 1.402172565460205
TA-VAAL iteration: 6100 vae_loss: 1.6162283420562744 dsc_loss: 1.3923916816711426
TA-VAAL iteration: 6200 vae_loss: 1.7133255004882812 dsc_loss: 1.4015393257141113
TA-VAAL iteration: 6300 vae_loss: 1.616668939590454 dsc_loss: 1.3866865634918213
TA-VAAL iteration: 6400 vae_loss: 1.6951671838760376 dsc_loss: 1.3762211799621582
TA-VAAL iteration: 6500 vae_loss: 1.6473069190979004 dsc_loss: 1.3894193172454834
TA-VAAL iteration: 6600 vae_loss: 1.6732635498046875 dsc_loss: 1.363552212715149
TA-VAAL iteration: 6700 vae_loss: 1.6534736156463623 dsc_loss: 1.3758693933486938
TA-VAAL iteration: 6800 vae_loss: 1.765611171722412 dsc_loss: 1.3631281852722168
TA-VAAL iteration: 6900 vae_loss: 1.658606767654419 dsc_loss: 1.3110380172729492
TA-VAAL iteration: 7000 vae_loss: 1.70231294631958 dsc_loss: 1.399656057357788
TA-VAAL iteration: 7100 vae_loss: 1.6645896434783936 dsc_loss: 1.416353464126587
TA-VAAL iteration: 7200 vae_loss: 1.81633460521698 dsc_loss: 1.3984713554382324
TA-VAAL iteration: 7300 vae_loss: 1.7302191257476807 dsc_loss: 1.4083359241485596
TA-VAAL iteration: 7400 vae_loss: 1.7142797708511353 dsc_loss: 1.3967583179473877
TA-VAAL iteration: 7500 vae_loss: 1.7329380512237549 dsc_loss: 1.3627309799194336
TA-VAAL iteration: 7600 vae_loss: 1.673478364944458 dsc_loss: 1.3904929161071777
TA-VAAL iteration: 7700 vae_loss: 1.7220370769500732 dsc_loss: 1.4091897010803223
1600 105508 66 106971
>> Train vae and task model
epoch 0: train loss is  1.61951
epoch 10: train loss is  1.51313
epoch 20: train loss is  1.42147
epoch 30: train loss is  1.37128
epoch 40: train loss is  1.28121
epoch 50: train loss is  1.26506
epoch 60: train loss is  1.23737
epoch 70: train loss is  1.20257
epoch 80: train loss is  1.21022
epoch 90: train loss is  1.18104
epoch 100: train loss is  1.17614
epoch 110: train loss is  1.14039
epoch 120: train loss is  1.16213
 >> Test Model
Cycle 8/10 || labeled data size 1600, test loss(MAE) =  0.77546
TA-VAAL iteration: 0 vae_loss: 1.8701646327972412 dsc_loss: 1.3872736692428589
TA-VAAL iteration: 10 vae_loss: 1.7776538133621216 dsc_loss: 1.3769333362579346
TA-VAAL iteration: 20 vae_loss: 1.327912449836731 dsc_loss: 1.543595552444458
TA-VAAL iteration: 30 vae_loss: 1.6154060363769531 dsc_loss: 1.406048059463501
TA-VAAL iteration: 40 vae_loss: 1.6954216957092285 dsc_loss: 1.2446006536483765
TA-VAAL iteration: 50 vae_loss: 1.845839262008667 dsc_loss: 1.3912136554718018
TA-VAAL iteration: 60 vae_loss: 1.8975251913070679 dsc_loss: 1.4279274940490723
TA-VAAL iteration: 70 vae_loss: 1.5441410541534424 dsc_loss: 1.4256800413131714
TA-VAAL iteration: 80 vae_loss: 1.863382339477539 dsc_loss: 1.3899098634719849
TA-VAAL iteration: 90 vae_loss: 1.6277798414230347 dsc_loss: 1.295003890991211
TA-VAAL iteration: 100 vae_loss: 1.7161457538604736 dsc_loss: 1.3740053176879883
TA-VAAL iteration: 200 vae_loss: 1.4868683815002441 dsc_loss: 1.3601237535476685
TA-VAAL iteration: 300 vae_loss: 1.4497783184051514 dsc_loss: 1.392578125
TA-VAAL iteration: 400 vae_loss: 1.460390567779541 dsc_loss: 1.395676851272583
TA-VAAL iteration: 500 vae_loss: 1.435956597328186 dsc_loss: 1.3794934749603271
TA-VAAL iteration: 600 vae_loss: 1.5201241970062256 dsc_loss: 1.364037275314331
TA-VAAL iteration: 700 vae_loss: 1.5051689147949219 dsc_loss: 1.3760063648223877
TA-VAAL iteration: 800 vae_loss: 1.494826316833496 dsc_loss: 1.3693039417266846
TA-VAAL iteration: 900 vae_loss: 1.4589040279388428 dsc_loss: 1.370938777923584
TA-VAAL iteration: 1000 vae_loss: 1.454591155052185 dsc_loss: 1.3815531730651855
TA-VAAL iteration: 1100 vae_loss: 1.4736707210540771 dsc_loss: 1.3633407354354858
TA-VAAL iteration: 1200 vae_loss: 1.53734290599823 dsc_loss: 1.369779348373413
TA-VAAL iteration: 1300 vae_loss: 1.6573854684829712 dsc_loss: 1.3719398975372314
TA-VAAL iteration: 1400 vae_loss: 1.4906878471374512 dsc_loss: 1.3750381469726562
TA-VAAL iteration: 1500 vae_loss: 1.5069856643676758 dsc_loss: 1.3686950206756592
TA-VAAL iteration: 1600 vae_loss: 1.4772977828979492 dsc_loss: 1.4021892547607422
TA-VAAL iteration: 1700 vae_loss: 1.5711127519607544 dsc_loss: 1.3844029903411865
TA-VAAL iteration: 1800 vae_loss: 1.5590078830718994 dsc_loss: 1.3718152046203613
TA-VAAL iteration: 1900 vae_loss: 1.5188844203948975 dsc_loss: 1.3845735788345337
TA-VAAL iteration: 2000 vae_loss: 1.5201685428619385 dsc_loss: 1.3651313781738281
TA-VAAL iteration: 2100 vae_loss: 1.524511456489563 dsc_loss: 1.377859354019165
TA-VAAL iteration: 2200 vae_loss: 1.5380152463912964 dsc_loss: 1.380744218826294
TA-VAAL iteration: 2300 vae_loss: 1.6190916299819946 dsc_loss: 1.3690457344055176
TA-VAAL iteration: 2400 vae_loss: 1.5272594690322876 dsc_loss: 1.379123568534851
TA-VAAL iteration: 2500 vae_loss: 1.5217195749282837 dsc_loss: 1.3872764110565186
TA-VAAL iteration: 2600 vae_loss: 1.5961140394210815 dsc_loss: 1.3753173351287842
TA-VAAL iteration: 2700 vae_loss: 1.5622332096099854 dsc_loss: 1.3735740184783936
TA-VAAL iteration: 2800 vae_loss: 1.5365979671478271 dsc_loss: 1.376334309577942
TA-VAAL iteration: 2900 vae_loss: 1.6054096221923828 dsc_loss: 1.378669023513794
TA-VAAL iteration: 3000 vae_loss: 1.5875424146652222 dsc_loss: 1.3733272552490234
TA-VAAL iteration: 3100 vae_loss: 1.5989658832550049 dsc_loss: 1.3751826286315918
TA-VAAL iteration: 3200 vae_loss: 1.5993638038635254 dsc_loss: 1.3673231601715088
TA-VAAL iteration: 3300 vae_loss: 1.5576171875 dsc_loss: 1.3890092372894287
TA-VAAL iteration: 3400 vae_loss: 1.587609052658081 dsc_loss: 1.3764914274215698
TA-VAAL iteration: 3500 vae_loss: 1.608734369277954 dsc_loss: 1.3732540607452393
TA-VAAL iteration: 3600 vae_loss: 1.6395225524902344 dsc_loss: 1.3802847862243652
TA-VAAL iteration: 3700 vae_loss: 1.6442972421646118 dsc_loss: 1.3840558528900146
TA-VAAL iteration: 3800 vae_loss: 1.664458155632019 dsc_loss: 1.3803564310073853
TA-VAAL iteration: 3900 vae_loss: 1.6532230377197266 dsc_loss: 1.3608343601226807
TA-VAAL iteration: 4000 vae_loss: 1.5727190971374512 dsc_loss: 1.3924436569213867
TA-VAAL iteration: 4100 vae_loss: 1.7166918516159058 dsc_loss: 1.3688489198684692
TA-VAAL iteration: 4200 vae_loss: 1.6613045930862427 dsc_loss: 1.3734893798828125
TA-VAAL iteration: 4300 vae_loss: 1.661716103553772 dsc_loss: 1.373673915863037
TA-VAAL iteration: 4400 vae_loss: 1.675363540649414 dsc_loss: 1.394303798675537
TA-VAAL iteration: 4500 vae_loss: 1.678660273551941 dsc_loss: 1.3747797012329102
TA-VAAL iteration: 4600 vae_loss: 1.6488370895385742 dsc_loss: 1.3739299774169922
TA-VAAL iteration: 4700 vae_loss: 1.647094488143921 dsc_loss: 1.4019707441329956
TA-VAAL iteration: 4800 vae_loss: 1.6577818393707275 dsc_loss: 1.375908374786377
TA-VAAL iteration: 4900 vae_loss: 1.7059690952301025 dsc_loss: 1.3721110820770264
TA-VAAL iteration: 5000 vae_loss: 1.6918703317642212 dsc_loss: 1.3733347654342651
TA-VAAL iteration: 5100 vae_loss: 1.7524183988571167 dsc_loss: 1.3763282299041748
TA-VAAL iteration: 5200 vae_loss: 1.7598726749420166 dsc_loss: 1.3673670291900635
TA-VAAL iteration: 5300 vae_loss: 1.7546257972717285 dsc_loss: 1.387163758277893
TA-VAAL iteration: 5400 vae_loss: 1.7103774547576904 dsc_loss: 1.3862569332122803
TA-VAAL iteration: 5500 vae_loss: 1.7813938856124878 dsc_loss: 1.3725913763046265
TA-VAAL iteration: 5600 vae_loss: 1.8522348403930664 dsc_loss: 1.3840265274047852
TA-VAAL iteration: 5700 vae_loss: 1.746016263961792 dsc_loss: 1.3836779594421387
TA-VAAL iteration: 5800 vae_loss: 1.7536585330963135 dsc_loss: 1.3691391944885254
TA-VAAL iteration: 5900 vae_loss: 1.7883220911026 dsc_loss: 1.3833500146865845
TA-VAAL iteration: 6000 vae_loss: 1.7241206169128418 dsc_loss: 1.3911113739013672
TA-VAAL iteration: 6100 vae_loss: 1.715522289276123 dsc_loss: 1.3721787929534912
TA-VAAL iteration: 6200 vae_loss: 1.7060458660125732 dsc_loss: 1.3783149719238281
TA-VAAL iteration: 6300 vae_loss: 1.7048823833465576 dsc_loss: 1.3756535053253174
TA-VAAL iteration: 6400 vae_loss: 1.684999942779541 dsc_loss: 1.379465103149414
TA-VAAL iteration: 6500 vae_loss: 1.7079293727874756 dsc_loss: 1.3714447021484375
TA-VAAL iteration: 6600 vae_loss: 1.7773832082748413 dsc_loss: 1.3820264339447021
TA-VAAL iteration: 6700 vae_loss: 1.7003695964813232 dsc_loss: 1.385605812072754
TA-VAAL iteration: 6800 vae_loss: 1.755484938621521 dsc_loss: 1.3804489374160767
TA-VAAL iteration: 6900 vae_loss: 1.7741998434066772 dsc_loss: 1.3875333070755005
TA-VAAL iteration: 7000 vae_loss: 1.7341313362121582 dsc_loss: 1.3764832019805908
TA-VAAL iteration: 7100 vae_loss: 1.7984329462051392 dsc_loss: 1.3816097974777222
TA-VAAL iteration: 7200 vae_loss: 1.8274669647216797 dsc_loss: 1.3755950927734375
TA-VAAL iteration: 7300 vae_loss: 1.780809998512268 dsc_loss: 1.3785450458526611
TA-VAAL iteration: 7400 vae_loss: 1.806708574295044 dsc_loss: 1.3727415800094604
TA-VAAL iteration: 7500 vae_loss: 1.8126790523529053 dsc_loss: 1.381582498550415
TA-VAAL iteration: 7600 vae_loss: 1.7704943418502808 dsc_loss: 1.3768048286437988
TA-VAAL iteration: 7700 vae_loss: 1.7499257326126099 dsc_loss: 1.371686339378357
TA-VAAL iteration: 7800 vae_loss: 1.8208224773406982 dsc_loss: 1.3710806369781494
TA-VAAL iteration: 7900 vae_loss: 1.850646734237671 dsc_loss: 1.3771313428878784
1800 105308 66 106971
>> Train vae and task model
epoch 0: train loss is  1.60534
epoch 10: train loss is  1.50387
epoch 20: train loss is  1.47421
epoch 30: train loss is  1.40922
epoch 40: train loss is  1.32009
epoch 50: train loss is  1.29798
epoch 60: train loss is  1.29695
epoch 70: train loss is  1.29925
epoch 80: train loss is  1.26304
epoch 90: train loss is  1.28597
epoch 100: train loss is  1.29421
epoch 110: train loss is  1.21763
epoch 120: train loss is  1.20321
 >> Test Model
Cycle 9/10 || labeled data size 1800, test loss(MAE) =  0.77546
TA-VAAL iteration: 0 vae_loss: 1.8576658964157104 dsc_loss: 1.3885419368743896
TA-VAAL iteration: 10 vae_loss: 1.7659013271331787 dsc_loss: 1.4510090351104736
TA-VAAL iteration: 20 vae_loss: 1.8134649991989136 dsc_loss: 1.452784776687622
TA-VAAL iteration: 30 vae_loss: 1.685299038887024 dsc_loss: 1.3649318218231201
TA-VAAL iteration: 40 vae_loss: 1.7984192371368408 dsc_loss: 1.4293553829193115
TA-VAAL iteration: 50 vae_loss: 1.8574129343032837 dsc_loss: 1.4182512760162354
TA-VAAL iteration: 60 vae_loss: 1.8420878648757935 dsc_loss: 1.3980460166931152
TA-VAAL iteration: 70 vae_loss: 1.7340294122695923 dsc_loss: 1.3864048719406128
TA-VAAL iteration: 80 vae_loss: 1.8181109428405762 dsc_loss: 1.3478167057037354
TA-VAAL iteration: 90 vae_loss: 1.673876404762268 dsc_loss: 1.3817366361618042
TA-VAAL iteration: 100 vae_loss: 1.7429699897766113 dsc_loss: 1.399267554283142
TA-VAAL iteration: 200 vae_loss: 1.6373538970947266 dsc_loss: 1.3792351484298706
TA-VAAL iteration: 300 vae_loss: 1.5792089700698853 dsc_loss: 1.4476395845413208
TA-VAAL iteration: 400 vae_loss: 1.4580029249191284 dsc_loss: 1.3974100351333618
TA-VAAL iteration: 500 vae_loss: 1.5838967561721802 dsc_loss: 1.3591737747192383
TA-VAAL iteration: 600 vae_loss: 1.4147008657455444 dsc_loss: 1.391601800918579
TA-VAAL iteration: 700 vae_loss: 1.6208332777023315 dsc_loss: 1.4021399021148682
TA-VAAL iteration: 800 vae_loss: 1.5591247081756592 dsc_loss: 1.390002965927124
TA-VAAL iteration: 900 vae_loss: 1.5127568244934082 dsc_loss: 1.3913588523864746
TA-VAAL iteration: 1000 vae_loss: 1.559184193611145 dsc_loss: 1.3950291872024536
TA-VAAL iteration: 1100 vae_loss: 1.6591827869415283 dsc_loss: 1.4236140251159668
TA-VAAL iteration: 1200 vae_loss: 1.5847249031066895 dsc_loss: 1.394016146659851
TA-VAAL iteration: 1300 vae_loss: 1.5862869024276733 dsc_loss: 1.390810251235962
TA-VAAL iteration: 1400 vae_loss: 1.6473956108093262 dsc_loss: 1.382606029510498
TA-VAAL iteration: 1500 vae_loss: 1.7200634479522705 dsc_loss: 1.3901365995407104
TA-VAAL iteration: 1600 vae_loss: 1.5600755214691162 dsc_loss: 1.3955283164978027
TA-VAAL iteration: 1700 vae_loss: 1.5754640102386475 dsc_loss: 1.3953913450241089
TA-VAAL iteration: 1800 vae_loss: 1.4817187786102295 dsc_loss: 1.3918800354003906
TA-VAAL iteration: 1900 vae_loss: 1.6590096950531006 dsc_loss: 1.366851806640625
TA-VAAL iteration: 2000 vae_loss: 1.7437012195587158 dsc_loss: 1.367879867553711
TA-VAAL iteration: 2100 vae_loss: 1.6469004154205322 dsc_loss: 1.3798012733459473
TA-VAAL iteration: 2200 vae_loss: 1.760636806488037 dsc_loss: 1.3638920783996582
TA-VAAL iteration: 2300 vae_loss: 1.7553126811981201 dsc_loss: 1.3820862770080566
TA-VAAL iteration: 2400 vae_loss: 1.659069538116455 dsc_loss: 1.4046530723571777
TA-VAAL iteration: 2500 vae_loss: 1.6957974433898926 dsc_loss: 1.3863892555236816
TA-VAAL iteration: 2600 vae_loss: 1.6789685487747192 dsc_loss: 1.372803807258606
TA-VAAL iteration: 2700 vae_loss: 1.6577130556106567 dsc_loss: 1.3925471305847168
TA-VAAL iteration: 2800 vae_loss: 1.6719765663146973 dsc_loss: 1.4027668237686157
TA-VAAL iteration: 2900 vae_loss: 1.7029762268066406 dsc_loss: 1.384438395500183
TA-VAAL iteration: 3000 vae_loss: 1.7314820289611816 dsc_loss: 1.3599445819854736
TA-VAAL iteration: 3100 vae_loss: 1.7847354412078857 dsc_loss: 1.362138032913208
TA-VAAL iteration: 3200 vae_loss: 1.7602425813674927 dsc_loss: 1.3905723094940186
TA-VAAL iteration: 3300 vae_loss: 1.7747071981430054 dsc_loss: 1.3941552639007568
TA-VAAL iteration: 3400 vae_loss: 1.8527097702026367 dsc_loss: 1.396202564239502
TA-VAAL iteration: 3500 vae_loss: 1.8785936832427979 dsc_loss: 1.3761606216430664
TA-VAAL iteration: 3600 vae_loss: 1.8089462518692017 dsc_loss: 1.3902897834777832
TA-VAAL iteration: 3700 vae_loss: 1.8191930055618286 dsc_loss: 1.3970474004745483
TA-VAAL iteration: 3800 vae_loss: 1.8084945678710938 dsc_loss: 1.4032540321350098
TA-VAAL iteration: 3900 vae_loss: 1.8004767894744873 dsc_loss: 1.3678447008132935
TA-VAAL iteration: 4000 vae_loss: 1.9257534742355347 dsc_loss: 1.3430429697036743
TA-VAAL iteration: 4100 vae_loss: 1.8647348880767822 dsc_loss: 1.375734806060791
TA-VAAL iteration: 4200 vae_loss: 1.8361005783081055 dsc_loss: 1.4010167121887207
TA-VAAL iteration: 4300 vae_loss: 1.9356471300125122 dsc_loss: 1.3909960985183716
TA-VAAL iteration: 4400 vae_loss: 1.9422577619552612 dsc_loss: 1.3719871044158936
TA-VAAL iteration: 4500 vae_loss: 1.9838721752166748 dsc_loss: 1.3990485668182373
TA-VAAL iteration: 4600 vae_loss: 2.0453357696533203 dsc_loss: 1.3903957605361938
TA-VAAL iteration: 4700 vae_loss: 1.9917048215866089 dsc_loss: 1.3851039409637451
TA-VAAL iteration: 4800 vae_loss: 1.9891479015350342 dsc_loss: 1.3737186193466187
TA-VAAL iteration: 4900 vae_loss: 2.138315200805664 dsc_loss: 1.3398103713989258
TA-VAAL iteration: 5000 vae_loss: 2.1716361045837402 dsc_loss: 1.3770010471343994
TA-VAAL iteration: 5100 vae_loss: 2.1638736724853516 dsc_loss: 1.352595567703247
TA-VAAL iteration: 5200 vae_loss: 2.1455416679382324 dsc_loss: 1.3774559497833252
TA-VAAL iteration: 5300 vae_loss: 2.1724283695220947 dsc_loss: 1.4103339910507202
TA-VAAL iteration: 5400 vae_loss: 2.209667921066284 dsc_loss: 1.3862899541854858
TA-VAAL iteration: 5500 vae_loss: 2.206937551498413 dsc_loss: 1.3891360759735107
TA-VAAL iteration: 5600 vae_loss: 2.131338357925415 dsc_loss: 1.3981200456619263
TA-VAAL iteration: 5700 vae_loss: 2.1806564331054688 dsc_loss: 1.3995013236999512
TA-VAAL iteration: 5800 vae_loss: 2.1061670780181885 dsc_loss: 1.381199836730957
TA-VAAL iteration: 5900 vae_loss: 2.2288808822631836 dsc_loss: 1.3605506420135498
TA-VAAL iteration: 6000 vae_loss: 2.3010265827178955 dsc_loss: 1.3515032529830933
TA-VAAL iteration: 6100 vae_loss: 2.249972343444824 dsc_loss: 1.3879704475402832
TA-VAAL iteration: 6200 vae_loss: 2.278707504272461 dsc_loss: 1.4058234691619873
TA-VAAL iteration: 6300 vae_loss: 2.377889633178711 dsc_loss: 1.3888287544250488
TA-VAAL iteration: 6400 vae_loss: 2.37532901763916 dsc_loss: 1.3540362119674683
TA-VAAL iteration: 6500 vae_loss: 2.3677687644958496 dsc_loss: 1.3955090045928955
TA-VAAL iteration: 6600 vae_loss: 2.3644907474517822 dsc_loss: 1.3895951509475708
TA-VAAL iteration: 6700 vae_loss: 2.5377540588378906 dsc_loss: 1.397262454032898
TA-VAAL iteration: 6800 vae_loss: 2.4870975017547607 dsc_loss: 1.3709490299224854
TA-VAAL iteration: 6900 vae_loss: 2.70611572265625 dsc_loss: 1.3232048749923706
TA-VAAL iteration: 7000 vae_loss: 2.649818181991577 dsc_loss: 1.3770372867584229
TA-VAAL iteration: 7100 vae_loss: 2.568207263946533 dsc_loss: 1.3954923152923584
TA-VAAL iteration: 7200 vae_loss: 2.5390045642852783 dsc_loss: 1.3863615989685059
TA-VAAL iteration: 7300 vae_loss: 2.7475733757019043 dsc_loss: 1.3622685670852661
TA-VAAL iteration: 7400 vae_loss: 2.704125165939331 dsc_loss: 1.4042658805847168
TA-VAAL iteration: 7500 vae_loss: 2.689088821411133 dsc_loss: 1.3934605121612549
TA-VAAL iteration: 7600 vae_loss: 2.6351265907287598 dsc_loss: 1.3875250816345215
TA-VAAL iteration: 7700 vae_loss: 2.7738027572631836 dsc_loss: 1.377159833908081
TA-VAAL iteration: 7800 vae_loss: 3.085622787475586 dsc_loss: 1.2981065511703491
TA-VAAL iteration: 7900 vae_loss: 3.0495243072509766 dsc_loss: 1.3924412727355957
TA-VAAL iteration: 8000 vae_loss: 2.9403951168060303 dsc_loss: 1.350372076034546
TA-VAAL iteration: 8100 vae_loss: 3.015420436859131 dsc_loss: 1.3730158805847168
TA-VAAL iteration: 8200 vae_loss: 2.8776168823242188 dsc_loss: 1.4115270376205444
2000 105108 55 106971
>> Train vae and task model
epoch 0: train loss is  1.58092
epoch 10: train loss is  1.48397
epoch 20: train loss is  1.42243
epoch 30: train loss is  1.36300
epoch 40: train loss is  1.32188
epoch 50: train loss is  1.28251
epoch 60: train loss is  1.26067
epoch 70: train loss is  1.24886
epoch 80: train loss is  1.20500
epoch 90: train loss is  1.22683
epoch 100: train loss is  1.19667
epoch 110: train loss is  1.16099
epoch 120: train loss is  1.17331
 >> Test Model
Cycle 10/10 || labeled data size 2000, test loss(MAE) =  0.77546
Finished.
>> Train vae and task model
epoch 0: train loss is  1.49134
epoch 10: train loss is  1.37737
epoch 20: train loss is  1.43241
epoch 30: train loss is  1.35827
epoch 40: train loss is  1.31030
epoch 50: train loss is  1.24863
epoch 60: train loss is  1.10992
epoch 70: train loss is  1.08425
epoch 80: train loss is  1.12440
epoch 90: train loss is  1.31440
epoch 100: train loss is  1.09204
epoch 110: train loss is  0.93301
epoch 120: train loss is  0.83947
 >> Test Model
Cycle 1/10 || labeled data size 200, test loss(MAE) =  0.73895
TA-VAAL iteration: 0 vae_loss: 1.665099859237671 dsc_loss: 1.410483479499817
TA-VAAL iteration: 10 vae_loss: 1.7784667015075684 dsc_loss: 1.403459072113037
TA-VAAL iteration: 20 vae_loss: 1.7683436870574951 dsc_loss: 1.3559837341308594
TA-VAAL iteration: 30 vae_loss: 1.812972903251648 dsc_loss: 1.3882403373718262
TA-VAAL iteration: 40 vae_loss: 1.8776930570602417 dsc_loss: 1.3751490116119385
TA-VAAL iteration: 50 vae_loss: 1.9423229694366455 dsc_loss: 1.3860092163085938
TA-VAAL iteration: 60 vae_loss: 1.6886738538742065 dsc_loss: 1.3751580715179443
TA-VAAL iteration: 70 vae_loss: 1.6385750770568848 dsc_loss: 1.3884425163269043
TA-VAAL iteration: 80 vae_loss: 1.6486589908599854 dsc_loss: 1.345819354057312
TA-VAAL iteration: 90 vae_loss: 1.4347509145736694 dsc_loss: 1.406651496887207
TA-VAAL iteration: 100 vae_loss: 1.7727406024932861 dsc_loss: 1.3522740602493286
TA-VAAL iteration: 200 vae_loss: 1.695210337638855 dsc_loss: 1.3604823350906372
TA-VAAL iteration: 300 vae_loss: 1.4697829484939575 dsc_loss: 1.3303606510162354
TA-VAAL iteration: 400 vae_loss: 1.4793483018875122 dsc_loss: 1.3415303230285645
TA-VAAL iteration: 500 vae_loss: 1.6141817569732666 dsc_loss: 1.3675050735473633
TA-VAAL iteration: 600 vae_loss: 1.4557901620864868 dsc_loss: 1.3462598323822021
TA-VAAL iteration: 700 vae_loss: 1.6216304302215576 dsc_loss: 1.3245759010314941
TA-VAAL iteration: 800 vae_loss: 1.802862286567688 dsc_loss: 1.2981054782867432
TA-VAAL iteration: 900 vae_loss: 2.0862159729003906 dsc_loss: 1.3117036819458008
TA-VAAL iteration: 1000 vae_loss: 1.8448693752288818 dsc_loss: 1.334815502166748
TA-VAAL iteration: 1100 vae_loss: 1.8269121646881104 dsc_loss: 1.2802395820617676
TA-VAAL iteration: 1200 vae_loss: 1.6851983070373535 dsc_loss: 1.335618495941162
TA-VAAL iteration: 1300 vae_loss: 1.9749951362609863 dsc_loss: 1.340327262878418
TA-VAAL iteration: 1400 vae_loss: 1.7245094776153564 dsc_loss: 1.3307452201843262
TA-VAAL iteration: 1500 vae_loss: 1.666396141052246 dsc_loss: 1.292136549949646
TA-VAAL iteration: 1600 vae_loss: 2.5562868118286133 dsc_loss: 1.362434983253479
TA-VAAL iteration: 1700 vae_loss: 2.0868639945983887 dsc_loss: 1.2794824838638306
TA-VAAL iteration: 1800 vae_loss: 2.016502857208252 dsc_loss: 1.3012664318084717
TA-VAAL iteration: 1900 vae_loss: 1.6627647876739502 dsc_loss: 1.3213123083114624
TA-VAAL iteration: 2000 vae_loss: 2.205683469772339 dsc_loss: 1.3295059204101562
TA-VAAL iteration: 2100 vae_loss: 1.7700368165969849 dsc_loss: 1.3163647651672363
TA-VAAL iteration: 2200 vae_loss: 2.535076141357422 dsc_loss: 1.362966775894165
TA-VAAL iteration: 2300 vae_loss: 1.6301066875457764 dsc_loss: 1.3865067958831787
TA-VAAL iteration: 2400 vae_loss: 2.4589319229125977 dsc_loss: 1.3345266580581665
TA-VAAL iteration: 2500 vae_loss: 2.7223024368286133 dsc_loss: 1.3627967834472656
TA-VAAL iteration: 2600 vae_loss: 1.8580529689788818 dsc_loss: 1.2774229049682617
TA-VAAL iteration: 2700 vae_loss: 1.95768404006958 dsc_loss: 1.2661232948303223
TA-VAAL iteration: 2800 vae_loss: 1.9655888080596924 dsc_loss: 1.3064428567886353
TA-VAAL iteration: 2900 vae_loss: 1.9270840883255005 dsc_loss: 1.3048487901687622
TA-VAAL iteration: 3000 vae_loss: 1.602851152420044 dsc_loss: 1.307389497756958
TA-VAAL iteration: 3100 vae_loss: 2.2677056789398193 dsc_loss: 1.352470874786377
TA-VAAL iteration: 3200 vae_loss: 2.5206658840179443 dsc_loss: 1.4659534692764282
TA-VAAL iteration: 3300 vae_loss: 1.6495530605316162 dsc_loss: 1.2857599258422852
TA-VAAL iteration: 3400 vae_loss: 1.7795281410217285 dsc_loss: 1.3512334823608398
TA-VAAL iteration: 3500 vae_loss: 2.1194849014282227 dsc_loss: 1.302519679069519
TA-VAAL iteration: 3600 vae_loss: 2.134695053100586 dsc_loss: 1.284082055091858
TA-VAAL iteration: 3700 vae_loss: 1.4048409461975098 dsc_loss: 1.432664155960083
TA-VAAL iteration: 3800 vae_loss: 1.7560796737670898 dsc_loss: 1.354738473892212
TA-VAAL iteration: 3900 vae_loss: 2.1149227619171143 dsc_loss: 1.3130559921264648
TA-VAAL iteration: 4000 vae_loss: 2.3521618843078613 dsc_loss: 1.4048854112625122
TA-VAAL iteration: 4100 vae_loss: 1.7401394844055176 dsc_loss: 1.2704652547836304
TA-VAAL iteration: 4200 vae_loss: 2.6442453861236572 dsc_loss: 1.2947016954421997
TA-VAAL iteration: 4300 vae_loss: 1.6764640808105469 dsc_loss: 1.232407808303833
TA-VAAL iteration: 4400 vae_loss: 3.1625616550445557 dsc_loss: 1.536588430404663
TA-VAAL iteration: 4500 vae_loss: 1.986060380935669 dsc_loss: 1.2812544107437134
TA-VAAL iteration: 4600 vae_loss: 1.9320704936981201 dsc_loss: 1.2892543077468872
TA-VAAL iteration: 4700 vae_loss: 3.176708221435547 dsc_loss: 1.433241844177246
TA-VAAL iteration: 4800 vae_loss: 1.6909501552581787 dsc_loss: 1.3089348077774048
TA-VAAL iteration: 4900 vae_loss: 2.110851526260376 dsc_loss: 1.421054720878601
TA-VAAL iteration: 5000 vae_loss: 1.7980499267578125 dsc_loss: 1.3150118589401245
TA-VAAL iteration: 5100 vae_loss: 1.9431390762329102 dsc_loss: 1.3097023963928223
TA-VAAL iteration: 5200 vae_loss: 2.138923168182373 dsc_loss: 1.3682184219360352
TA-VAAL iteration: 5300 vae_loss: 2.0448975563049316 dsc_loss: 1.2302299737930298
TA-VAAL iteration: 5400 vae_loss: 2.6922080516815186 dsc_loss: 1.3117215633392334
TA-VAAL iteration: 5500 vae_loss: 1.6947991847991943 dsc_loss: 1.2311358451843262
TA-VAAL iteration: 5600 vae_loss: 2.1763370037078857 dsc_loss: 1.301272988319397
TA-VAAL iteration: 5700 vae_loss: 2.3934755325317383 dsc_loss: 1.3044512271881104
TA-VAAL iteration: 5800 vae_loss: 1.837125539779663 dsc_loss: 1.3631505966186523
TA-VAAL iteration: 5900 vae_loss: 1.8046698570251465 dsc_loss: 1.400251865386963
TA-VAAL iteration: 6000 vae_loss: 1.8491950035095215 dsc_loss: 1.3965184688568115
TA-VAAL iteration: 6100 vae_loss: 3.0427966117858887 dsc_loss: 1.2614226341247559
TA-VAAL iteration: 6200 vae_loss: 1.812333583831787 dsc_loss: 1.380996584892273
400 106708 199 106952
>> Train vae and task model
epoch 0: train loss is  1.60107
epoch 10: train loss is  1.47282
epoch 20: train loss is  1.34065
epoch 30: train loss is  1.29385
epoch 40: train loss is  1.24361
epoch 50: train loss is  1.22085
epoch 60: train loss is  1.14710
epoch 70: train loss is  1.15817
epoch 80: train loss is  1.08947
epoch 90: train loss is  1.17484
epoch 100: train loss is  0.98297
epoch 110: train loss is  1.06347
epoch 120: train loss is  0.83723
 >> Test Model
Cycle 2/10 || labeled data size 400, test loss(MAE) =  0.75329
TA-VAAL iteration: 0 vae_loss: 1.5893797874450684 dsc_loss: 1.4316537380218506
TA-VAAL iteration: 10 vae_loss: 1.602192997932434 dsc_loss: 1.3861138820648193
TA-VAAL iteration: 20 vae_loss: 1.7799794673919678 dsc_loss: 1.3897874355316162
TA-VAAL iteration: 30 vae_loss: 1.7716134786605835 dsc_loss: 1.3772943019866943
TA-VAAL iteration: 40 vae_loss: 1.692710518836975 dsc_loss: 1.3777304887771606
TA-VAAL iteration: 50 vae_loss: 1.6688491106033325 dsc_loss: 1.3707211017608643
TA-VAAL iteration: 60 vae_loss: 1.76763916015625 dsc_loss: 1.3843789100646973
TA-VAAL iteration: 70 vae_loss: 1.7477184534072876 dsc_loss: 1.3784558773040771
TA-VAAL iteration: 80 vae_loss: 1.7398760318756104 dsc_loss: 1.3637070655822754
TA-VAAL iteration: 90 vae_loss: 1.6232610940933228 dsc_loss: 1.3560899496078491
TA-VAAL iteration: 100 vae_loss: 1.508269190788269 dsc_loss: 1.3825411796569824
TA-VAAL iteration: 200 vae_loss: 1.5429832935333252 dsc_loss: 1.3653240203857422
TA-VAAL iteration: 300 vae_loss: 1.4874414205551147 dsc_loss: 1.3342846632003784
TA-VAAL iteration: 400 vae_loss: 1.5420851707458496 dsc_loss: 1.4008934497833252
TA-VAAL iteration: 500 vae_loss: 1.6009893417358398 dsc_loss: 1.3430812358856201
TA-VAAL iteration: 600 vae_loss: 1.6017383337020874 dsc_loss: 1.361250400543213
TA-VAAL iteration: 700 vae_loss: 1.8273934125900269 dsc_loss: 1.3909293413162231
TA-VAAL iteration: 800 vae_loss: 1.6646499633789062 dsc_loss: 1.315525770187378
TA-VAAL iteration: 900 vae_loss: 1.817352056503296 dsc_loss: 1.3046222925186157
TA-VAAL iteration: 1000 vae_loss: 2.226980447769165 dsc_loss: 1.286381721496582
TA-VAAL iteration: 1100 vae_loss: 2.0255777835845947 dsc_loss: 1.3817932605743408
TA-VAAL iteration: 1200 vae_loss: 1.8753979206085205 dsc_loss: 1.268423080444336
TA-VAAL iteration: 1300 vae_loss: 1.9525766372680664 dsc_loss: 1.223968267440796
TA-VAAL iteration: 1400 vae_loss: 2.4706103801727295 dsc_loss: 1.2436915636062622
TA-VAAL iteration: 1500 vae_loss: 2.2621350288391113 dsc_loss: 1.3687553405761719
TA-VAAL iteration: 1600 vae_loss: 1.9803334474563599 dsc_loss: 1.2168667316436768
TA-VAAL iteration: 1700 vae_loss: 1.9752212762832642 dsc_loss: 1.053632140159607
TA-VAAL iteration: 1800 vae_loss: 2.7133445739746094 dsc_loss: 1.3396412134170532
TA-VAAL iteration: 1900 vae_loss: 2.265751838684082 dsc_loss: 1.323033094406128
TA-VAAL iteration: 2000 vae_loss: 2.3083739280700684 dsc_loss: 1.1563154458999634
TA-VAAL iteration: 2100 vae_loss: 2.64809513092041 dsc_loss: 1.2765395641326904
TA-VAAL iteration: 2200 vae_loss: 2.344881534576416 dsc_loss: 1.2870018482208252
TA-VAAL iteration: 2300 vae_loss: 2.2253975868225098 dsc_loss: 1.2407068014144897
TA-VAAL iteration: 2400 vae_loss: 2.174058675765991 dsc_loss: 1.034153699874878
TA-VAAL iteration: 2500 vae_loss: 2.530571222305298 dsc_loss: 1.3054730892181396
TA-VAAL iteration: 2600 vae_loss: 2.1679911613464355 dsc_loss: 1.2191202640533447
TA-VAAL iteration: 2700 vae_loss: 1.8694688081741333 dsc_loss: 1.3166821002960205
TA-VAAL iteration: 2800 vae_loss: 2.6100423336029053 dsc_loss: 1.1410754919052124
TA-VAAL iteration: 2900 vae_loss: 2.5449414253234863 dsc_loss: 1.2904751300811768
TA-VAAL iteration: 3000 vae_loss: 2.516964912414551 dsc_loss: 1.1521855592727661
TA-VAAL iteration: 3100 vae_loss: 2.582685947418213 dsc_loss: 1.068116545677185
TA-VAAL iteration: 3200 vae_loss: 3.0217084884643555 dsc_loss: 1.3392583131790161
TA-VAAL iteration: 3300 vae_loss: 2.5471785068511963 dsc_loss: 1.194246768951416
TA-VAAL iteration: 3400 vae_loss: 2.324349880218506 dsc_loss: 1.2044461965560913
TA-VAAL iteration: 3500 vae_loss: 2.3237781524658203 dsc_loss: 1.3664950132369995
TA-VAAL iteration: 3600 vae_loss: 2.815142869949341 dsc_loss: 1.3233619928359985
TA-VAAL iteration: 3700 vae_loss: 2.627429962158203 dsc_loss: 1.1935303211212158
TA-VAAL iteration: 3800 vae_loss: 2.5782995223999023 dsc_loss: 1.020585298538208
TA-VAAL iteration: 3900 vae_loss: 2.739933490753174 dsc_loss: 1.382321834564209
TA-VAAL iteration: 4000 vae_loss: 2.8687448501586914 dsc_loss: 1.1576197147369385
TA-VAAL iteration: 4100 vae_loss: 2.479729652404785 dsc_loss: 1.1680485010147095
TA-VAAL iteration: 4200 vae_loss: 3.2028517723083496 dsc_loss: 1.4184777736663818
TA-VAAL iteration: 4300 vae_loss: 2.8638224601745605 dsc_loss: 1.1610703468322754
TA-VAAL iteration: 4400 vae_loss: 2.289945363998413 dsc_loss: 1.2890878915786743
TA-VAAL iteration: 4500 vae_loss: 3.0117595195770264 dsc_loss: 0.9258178472518921
TA-VAAL iteration: 4600 vae_loss: 3.0276951789855957 dsc_loss: 1.1912271976470947
TA-VAAL iteration: 4700 vae_loss: 2.42887020111084 dsc_loss: 1.2465648651123047
TA-VAAL iteration: 4800 vae_loss: 2.7870354652404785 dsc_loss: 1.1848556995391846
TA-VAAL iteration: 4900 vae_loss: 3.1236085891723633 dsc_loss: 1.1986006498336792
TA-VAAL iteration: 5000 vae_loss: 3.396284341812134 dsc_loss: 1.2291107177734375
TA-VAAL iteration: 5100 vae_loss: 2.7348275184631348 dsc_loss: 1.1831035614013672
TA-VAAL iteration: 5200 vae_loss: 2.9148173332214355 dsc_loss: 1.2787606716156006
TA-VAAL iteration: 5300 vae_loss: 3.262749671936035 dsc_loss: 1.3015706539154053
TA-VAAL iteration: 5400 vae_loss: 3.016751766204834 dsc_loss: 1.2070585489273071
TA-VAAL iteration: 5500 vae_loss: 2.8151791095733643 dsc_loss: 1.1862167119979858
TA-VAAL iteration: 5600 vae_loss: 3.441007137298584 dsc_loss: 1.1299066543579102
TA-VAAL iteration: 5700 vae_loss: 2.8191447257995605 dsc_loss: 1.2409299612045288
TA-VAAL iteration: 5800 vae_loss: 2.263962984085083 dsc_loss: 1.2860842943191528
TA-VAAL iteration: 5900 vae_loss: 3.198397159576416 dsc_loss: 1.0251028537750244
TA-VAAL iteration: 6000 vae_loss: 3.3653972148895264 dsc_loss: 1.3298498392105103
TA-VAAL iteration: 6100 vae_loss: 2.679100513458252 dsc_loss: 1.2865757942199707
TA-VAAL iteration: 6200 vae_loss: 2.580570697784424 dsc_loss: 1.1952861547470093
TA-VAAL iteration: 6300 vae_loss: 2.8927292823791504 dsc_loss: 1.3674718141555786
TA-VAAL iteration: 6400 vae_loss: 3.0250072479248047 dsc_loss: 1.2101268768310547
600 106508 199 106952
>> Train vae and task model
epoch 0: train loss is  1.57248
epoch 10: train loss is  1.44986
epoch 20: train loss is  1.36015
epoch 30: train loss is  1.32369
epoch 40: train loss is  1.22340
epoch 50: train loss is  1.12925
epoch 60: train loss is  1.10782
epoch 70: train loss is  1.03896
epoch 80: train loss is  1.02351
epoch 90: train loss is  0.94881
epoch 100: train loss is  0.85943
epoch 110: train loss is  0.92267
epoch 120: train loss is  0.90015
 >> Test Model
Cycle 3/10 || labeled data size 600, test loss(MAE) =  0.72049
TA-VAAL iteration: 0 vae_loss: 1.973931074142456 dsc_loss: 1.3860690593719482
TA-VAAL iteration: 10 vae_loss: 1.8250391483306885 dsc_loss: 1.3868316411972046
TA-VAAL iteration: 20 vae_loss: 1.7324143648147583 dsc_loss: 1.3821942806243896
TA-VAAL iteration: 30 vae_loss: 1.7738280296325684 dsc_loss: 1.3686702251434326
TA-VAAL iteration: 40 vae_loss: 1.780236005783081 dsc_loss: 1.3899750709533691
TA-VAAL iteration: 50 vae_loss: 1.9856665134429932 dsc_loss: 1.387020468711853
TA-VAAL iteration: 60 vae_loss: 1.8301308155059814 dsc_loss: 1.3942450284957886
TA-VAAL iteration: 70 vae_loss: 1.9104282855987549 dsc_loss: 1.3716520071029663
TA-VAAL iteration: 80 vae_loss: 1.6530983448028564 dsc_loss: 1.3882391452789307
TA-VAAL iteration: 90 vae_loss: 1.7964608669281006 dsc_loss: 1.353055477142334
TA-VAAL iteration: 100 vae_loss: 1.6719622611999512 dsc_loss: 1.4028198719024658
TA-VAAL iteration: 200 vae_loss: 1.6037102937698364 dsc_loss: 1.3693475723266602
TA-VAAL iteration: 300 vae_loss: 2.0915441513061523 dsc_loss: 1.3971548080444336
TA-VAAL iteration: 400 vae_loss: 1.5453318357467651 dsc_loss: 1.4244310855865479
TA-VAAL iteration: 500 vae_loss: 1.7501893043518066 dsc_loss: 1.364857792854309
TA-VAAL iteration: 600 vae_loss: 1.7165321111679077 dsc_loss: 1.3799833059310913
TA-VAAL iteration: 700 vae_loss: 1.5960482358932495 dsc_loss: 1.3233795166015625
TA-VAAL iteration: 800 vae_loss: 1.668424367904663 dsc_loss: 1.359833002090454
TA-VAAL iteration: 900 vae_loss: 1.5810173749923706 dsc_loss: 1.312596321105957
TA-VAAL iteration: 1000 vae_loss: 1.81173574924469 dsc_loss: 1.2749329805374146
TA-VAAL iteration: 1100 vae_loss: 1.6234631538391113 dsc_loss: 1.2654141187667847
TA-VAAL iteration: 1200 vae_loss: 1.611911416053772 dsc_loss: 1.2926993370056152
TA-VAAL iteration: 1300 vae_loss: 1.659036636352539 dsc_loss: 1.2470669746398926
TA-VAAL iteration: 1400 vae_loss: 1.6622021198272705 dsc_loss: 1.2630865573883057
TA-VAAL iteration: 1500 vae_loss: 1.645491123199463 dsc_loss: 1.3278331756591797
TA-VAAL iteration: 1600 vae_loss: 1.8379061222076416 dsc_loss: 1.3645259141921997
TA-VAAL iteration: 1700 vae_loss: 1.6309345960617065 dsc_loss: 1.3604822158813477
TA-VAAL iteration: 1800 vae_loss: 1.6576865911483765 dsc_loss: 1.1839547157287598
TA-VAAL iteration: 1900 vae_loss: 1.7320550680160522 dsc_loss: 1.215895175933838
TA-VAAL iteration: 2000 vae_loss: 1.7437059879302979 dsc_loss: 1.3001526594161987
TA-VAAL iteration: 2100 vae_loss: 1.9756709337234497 dsc_loss: 1.2207300662994385
TA-VAAL iteration: 2200 vae_loss: 1.8502235412597656 dsc_loss: 1.2141005992889404
TA-VAAL iteration: 2300 vae_loss: 2.015681743621826 dsc_loss: 1.3498163223266602
TA-VAAL iteration: 2400 vae_loss: 2.007901430130005 dsc_loss: 1.175958275794983
TA-VAAL iteration: 2500 vae_loss: 1.8160017728805542 dsc_loss: 1.2864153385162354
TA-VAAL iteration: 2600 vae_loss: 1.706110954284668 dsc_loss: 1.1885175704956055
TA-VAAL iteration: 2700 vae_loss: 1.9391498565673828 dsc_loss: 1.1395788192749023
TA-VAAL iteration: 2800 vae_loss: 1.889786720275879 dsc_loss: 1.2150381803512573
TA-VAAL iteration: 2900 vae_loss: 1.9341696500778198 dsc_loss: 1.215852975845337
TA-VAAL iteration: 3000 vae_loss: 1.970773696899414 dsc_loss: 1.1818509101867676
TA-VAAL iteration: 3100 vae_loss: 1.9313466548919678 dsc_loss: 1.2369457483291626
TA-VAAL iteration: 3200 vae_loss: 1.5925679206848145 dsc_loss: 1.3225289583206177
TA-VAAL iteration: 3300 vae_loss: 1.974139928817749 dsc_loss: 1.2479934692382812
TA-VAAL iteration: 3400 vae_loss: 1.804985761642456 dsc_loss: 1.3106681108474731
TA-VAAL iteration: 3500 vae_loss: 1.7625396251678467 dsc_loss: 1.2539303302764893
TA-VAAL iteration: 3600 vae_loss: 1.8658254146575928 dsc_loss: 1.2067158222198486
TA-VAAL iteration: 3700 vae_loss: 1.6854846477508545 dsc_loss: 1.2333282232284546
TA-VAAL iteration: 3800 vae_loss: 2.2920870780944824 dsc_loss: 1.1746046543121338
TA-VAAL iteration: 3900 vae_loss: 1.9521006345748901 dsc_loss: 1.119147539138794
TA-VAAL iteration: 4000 vae_loss: 2.0716123580932617 dsc_loss: 1.1739754676818848
TA-VAAL iteration: 4100 vae_loss: 2.106243133544922 dsc_loss: 1.211724042892456
TA-VAAL iteration: 4200 vae_loss: 2.062549591064453 dsc_loss: 1.3257629871368408
TA-VAAL iteration: 4300 vae_loss: 1.8884379863739014 dsc_loss: 1.2559242248535156
TA-VAAL iteration: 4400 vae_loss: 2.2348556518554688 dsc_loss: 1.2335401773452759
TA-VAAL iteration: 4500 vae_loss: 2.117807626724243 dsc_loss: 1.1920652389526367
TA-VAAL iteration: 4600 vae_loss: 2.170318365097046 dsc_loss: 1.2416406869888306
TA-VAAL iteration: 4700 vae_loss: 2.0236685276031494 dsc_loss: 1.144554615020752
TA-VAAL iteration: 4800 vae_loss: 2.21085262298584 dsc_loss: 1.370476484298706
TA-VAAL iteration: 4900 vae_loss: 2.0105724334716797 dsc_loss: 1.2229405641555786
TA-VAAL iteration: 5000 vae_loss: 2.0985488891601562 dsc_loss: 1.145932674407959
TA-VAAL iteration: 5100 vae_loss: 2.1264407634735107 dsc_loss: 1.2048540115356445
TA-VAAL iteration: 5200 vae_loss: 1.7803053855895996 dsc_loss: 1.1861865520477295
TA-VAAL iteration: 5300 vae_loss: 2.637113571166992 dsc_loss: 1.3353428840637207
TA-VAAL iteration: 5400 vae_loss: 2.024219036102295 dsc_loss: 1.2360577583312988
TA-VAAL iteration: 5500 vae_loss: 2.089559555053711 dsc_loss: 1.4072191715240479
TA-VAAL iteration: 5600 vae_loss: 2.03780460357666 dsc_loss: 1.2294535636901855
TA-VAAL iteration: 5700 vae_loss: 2.194119453430176 dsc_loss: 1.159423828125
TA-VAAL iteration: 5800 vae_loss: 2.4039676189422607 dsc_loss: 1.1350802183151245
TA-VAAL iteration: 5900 vae_loss: 2.1664576530456543 dsc_loss: 1.1747335195541382
TA-VAAL iteration: 6000 vae_loss: 2.4920570850372314 dsc_loss: 1.3915951251983643
TA-VAAL iteration: 6100 vae_loss: 2.0789928436279297 dsc_loss: 1.2103502750396729
TA-VAAL iteration: 6200 vae_loss: 2.07578706741333 dsc_loss: 1.398893117904663
TA-VAAL iteration: 6300 vae_loss: 2.1232428550720215 dsc_loss: 1.2462292909622192
TA-VAAL iteration: 6400 vae_loss: 2.4837136268615723 dsc_loss: 1.2965234518051147
TA-VAAL iteration: 6500 vae_loss: 2.338801145553589 dsc_loss: 1.2396721839904785
TA-VAAL iteration: 6600 vae_loss: 2.4516260623931885 dsc_loss: 1.4099798202514648
TA-VAAL iteration: 6700 vae_loss: 2.1663029193878174 dsc_loss: 1.151798963546753
800 106308 199 106952
>> Train vae and task model
epoch 0: train loss is  1.55658
epoch 10: train loss is  1.43655
epoch 20: train loss is  1.38152
epoch 30: train loss is  1.25623
epoch 40: train loss is  1.26448
epoch 50: train loss is  1.18785
epoch 60: train loss is  1.21342
epoch 70: train loss is  1.15360
epoch 80: train loss is  1.12648
epoch 90: train loss is  1.10133
epoch 100: train loss is  1.08748
epoch 110: train loss is  1.06384
epoch 120: train loss is  1.08391
 >> Test Model
Cycle 4/10 || labeled data size 800, test loss(MAE) =  0.73895
TA-VAAL iteration: 0 vae_loss: 1.840050458908081 dsc_loss: 1.391641616821289
TA-VAAL iteration: 10 vae_loss: 1.4802277088165283 dsc_loss: 1.431702733039856
TA-VAAL iteration: 20 vae_loss: 1.7253607511520386 dsc_loss: 1.3860743045806885
TA-VAAL iteration: 30 vae_loss: 1.7533539533615112 dsc_loss: 1.390479564666748
TA-VAAL iteration: 40 vae_loss: 1.7355072498321533 dsc_loss: 1.3864448070526123
TA-VAAL iteration: 50 vae_loss: 1.8480947017669678 dsc_loss: 1.385429859161377
TA-VAAL iteration: 60 vae_loss: 1.8177711963653564 dsc_loss: 1.4025758504867554
TA-VAAL iteration: 70 vae_loss: 1.7203660011291504 dsc_loss: 1.3688478469848633
TA-VAAL iteration: 80 vae_loss: 1.827925443649292 dsc_loss: 1.3964000940322876
TA-VAAL iteration: 90 vae_loss: 1.6804481744766235 dsc_loss: 1.3786427974700928
TA-VAAL iteration: 100 vae_loss: 1.7289847135543823 dsc_loss: 1.356001615524292
TA-VAAL iteration: 200 vae_loss: 1.5344151258468628 dsc_loss: 1.3770418167114258
TA-VAAL iteration: 300 vae_loss: 1.7059903144836426 dsc_loss: 1.386678695678711
TA-VAAL iteration: 400 vae_loss: 1.8494845628738403 dsc_loss: 1.3960118293762207
TA-VAAL iteration: 500 vae_loss: 1.7830995321273804 dsc_loss: 1.3964598178863525
TA-VAAL iteration: 600 vae_loss: 1.6950111389160156 dsc_loss: 1.386548638343811
TA-VAAL iteration: 700 vae_loss: 1.6789288520812988 dsc_loss: 1.3870134353637695
TA-VAAL iteration: 800 vae_loss: 1.9178335666656494 dsc_loss: 1.3784257173538208
TA-VAAL iteration: 900 vae_loss: 1.946527361869812 dsc_loss: 1.3919955492019653
TA-VAAL iteration: 1000 vae_loss: 1.78839111328125 dsc_loss: 1.3910763263702393
TA-VAAL iteration: 1100 vae_loss: 1.9178271293640137 dsc_loss: 1.3965694904327393
TA-VAAL iteration: 1200 vae_loss: 1.9503204822540283 dsc_loss: 1.3778629302978516
TA-VAAL iteration: 1300 vae_loss: 1.9873261451721191 dsc_loss: 1.3803366422653198
TA-VAAL iteration: 1400 vae_loss: 1.999070405960083 dsc_loss: 1.380179524421692
TA-VAAL iteration: 1500 vae_loss: 2.279416084289551 dsc_loss: 1.3825242519378662
TA-VAAL iteration: 1600 vae_loss: 2.148984432220459 dsc_loss: 1.3866539001464844
TA-VAAL iteration: 1700 vae_loss: 2.2606492042541504 dsc_loss: 1.3730915784835815
TA-VAAL iteration: 1800 vae_loss: 2.2445950508117676 dsc_loss: 1.3956522941589355
TA-VAAL iteration: 1900 vae_loss: 2.327362537384033 dsc_loss: 1.3841073513031006
TA-VAAL iteration: 2000 vae_loss: 2.1127476692199707 dsc_loss: 1.3701493740081787
TA-VAAL iteration: 2100 vae_loss: 2.1793198585510254 dsc_loss: 1.3703320026397705
TA-VAAL iteration: 2200 vae_loss: 2.559953451156616 dsc_loss: 1.3835630416870117
TA-VAAL iteration: 2300 vae_loss: 2.6170473098754883 dsc_loss: 1.3369494676589966
TA-VAAL iteration: 2400 vae_loss: 2.448599338531494 dsc_loss: 1.3472880125045776
TA-VAAL iteration: 2500 vae_loss: 2.400869369506836 dsc_loss: 1.3516448736190796
TA-VAAL iteration: 2600 vae_loss: 2.6114330291748047 dsc_loss: 1.3396837711334229
TA-VAAL iteration: 2700 vae_loss: 3.1657094955444336 dsc_loss: 1.3637642860412598
TA-VAAL iteration: 2800 vae_loss: 2.8364360332489014 dsc_loss: 1.3603644371032715
TA-VAAL iteration: 2900 vae_loss: 2.754559278488159 dsc_loss: 1.3434374332427979
TA-VAAL iteration: 3000 vae_loss: 2.8880152702331543 dsc_loss: 1.311945915222168
TA-VAAL iteration: 3100 vae_loss: 4.065276145935059 dsc_loss: 1.4018776416778564
TA-VAAL iteration: 3200 vae_loss: 3.339184284210205 dsc_loss: 1.3497567176818848
TA-VAAL iteration: 3300 vae_loss: 2.9773592948913574 dsc_loss: 1.382153034210205
TA-VAAL iteration: 3400 vae_loss: 3.9609789848327637 dsc_loss: 1.3776031732559204
TA-VAAL iteration: 3500 vae_loss: 3.59870982170105 dsc_loss: 1.3297665119171143
TA-VAAL iteration: 3600 vae_loss: 2.267672061920166 dsc_loss: 1.369964838027954
TA-VAAL iteration: 3700 vae_loss: 3.4966044425964355 dsc_loss: 1.343019962310791
TA-VAAL iteration: 3800 vae_loss: 4.1684088706970215 dsc_loss: 1.3475518226623535
TA-VAAL iteration: 3900 vae_loss: 3.4904568195343018 dsc_loss: 1.3443801403045654
TA-VAAL iteration: 4000 vae_loss: 2.687714099884033 dsc_loss: 1.3545773029327393
TA-VAAL iteration: 4100 vae_loss: 3.949265241622925 dsc_loss: 1.424485683441162
TA-VAAL iteration: 4200 vae_loss: 4.22598123550415 dsc_loss: 1.4010899066925049
TA-VAAL iteration: 4300 vae_loss: 3.5486626625061035 dsc_loss: 1.2906262874603271
TA-VAAL iteration: 4400 vae_loss: 2.9559953212738037 dsc_loss: 1.3276609182357788
TA-VAAL iteration: 4500 vae_loss: 5.2863054275512695 dsc_loss: 1.5682494640350342
TA-VAAL iteration: 4600 vae_loss: 4.532629013061523 dsc_loss: 1.3934940099716187
TA-VAAL iteration: 4700 vae_loss: 3.3361339569091797 dsc_loss: 1.339720606803894
TA-VAAL iteration: 4800 vae_loss: 3.792829990386963 dsc_loss: 1.3440767526626587
TA-VAAL iteration: 4900 vae_loss: 4.653809547424316 dsc_loss: 1.3517861366271973
TA-VAAL iteration: 5000 vae_loss: 3.3857452869415283 dsc_loss: 1.2905234098434448
TA-VAAL iteration: 5100 vae_loss: 3.7368905544281006 dsc_loss: 1.2559117078781128
TA-VAAL iteration: 5200 vae_loss: 2.327951669692993 dsc_loss: 1.333401083946228
TA-VAAL iteration: 5300 vae_loss: 4.677933692932129 dsc_loss: 1.4306936264038086
TA-VAAL iteration: 5400 vae_loss: 4.121401786804199 dsc_loss: 1.320249080657959
TA-VAAL iteration: 5500 vae_loss: 3.012721300125122 dsc_loss: 1.385859727859497
TA-VAAL iteration: 5600 vae_loss: 4.862953186035156 dsc_loss: 1.2345237731933594
TA-VAAL iteration: 5700 vae_loss: 3.110413074493408 dsc_loss: 1.3271816968917847
TA-VAAL iteration: 5800 vae_loss: 3.265530824661255 dsc_loss: 1.3019769191741943
TA-VAAL iteration: 5900 vae_loss: 3.2770962715148926 dsc_loss: 1.3237884044647217
TA-VAAL iteration: 6000 vae_loss: 6.03077507019043 dsc_loss: 1.323294758796692
TA-VAAL iteration: 6100 vae_loss: 3.011060953140259 dsc_loss: 1.3641002178192139
TA-VAAL iteration: 6200 vae_loss: 3.450836420059204 dsc_loss: 1.3371729850769043
TA-VAAL iteration: 6300 vae_loss: 4.272885322570801 dsc_loss: 1.3203731775283813
TA-VAAL iteration: 6400 vae_loss: 6.942275047302246 dsc_loss: 1.539592981338501
TA-VAAL iteration: 6500 vae_loss: 3.8590493202209473 dsc_loss: 1.2676606178283691
TA-VAAL iteration: 6600 vae_loss: 3.003732919692993 dsc_loss: 1.3327261209487915
TA-VAAL iteration: 6700 vae_loss: 4.297883987426758 dsc_loss: 1.372520089149475
TA-VAAL iteration: 6800 vae_loss: 3.2016985416412354 dsc_loss: 1.2944903373718262
TA-VAAL iteration: 6900 vae_loss: 2.788936138153076 dsc_loss: 1.3055534362792969
1000 106108 199 106952
>> Train vae and task model
epoch 0: train loss is  1.51788
epoch 10: train loss is  1.39113
epoch 20: train loss is  1.32448
epoch 30: train loss is  1.22889
epoch 40: train loss is  1.19065
epoch 50: train loss is  1.11516
epoch 60: train loss is  1.12347
epoch 70: train loss is  1.05744
epoch 80: train loss is  1.09109
epoch 90: train loss is  1.00216
epoch 100: train loss is  1.01671
epoch 110: train loss is  1.08849
epoch 120: train loss is  0.97039
 >> Test Model
Cycle 5/10 || labeled data size 1000, test loss(MAE) =  0.72183
TA-VAAL iteration: 0 vae_loss: 1.987308382987976 dsc_loss: 1.38266921043396
TA-VAAL iteration: 10 vae_loss: 1.7908638715744019 dsc_loss: 1.3991639614105225
TA-VAAL iteration: 20 vae_loss: 1.8392977714538574 dsc_loss: 1.38877272605896
TA-VAAL iteration: 30 vae_loss: 1.6351416110992432 dsc_loss: 1.3915324211120605
TA-VAAL iteration: 40 vae_loss: 1.7658860683441162 dsc_loss: 1.3190319538116455
TA-VAAL iteration: 50 vae_loss: 1.7519917488098145 dsc_loss: 1.3803563117980957
TA-VAAL iteration: 60 vae_loss: 2.000225782394409 dsc_loss: 1.4437904357910156
TA-VAAL iteration: 70 vae_loss: 1.8433058261871338 dsc_loss: 1.398869276046753
TA-VAAL iteration: 80 vae_loss: 1.767590045928955 dsc_loss: 1.388083815574646
TA-VAAL iteration: 90 vae_loss: 1.990419626235962 dsc_loss: 1.4180138111114502
TA-VAAL iteration: 100 vae_loss: 1.798802137374878 dsc_loss: 1.396082878112793
TA-VAAL iteration: 200 vae_loss: 1.736802101135254 dsc_loss: 1.3616633415222168
TA-VAAL iteration: 300 vae_loss: 1.7489714622497559 dsc_loss: 1.41660737991333
TA-VAAL iteration: 400 vae_loss: 1.5839827060699463 dsc_loss: 1.4120209217071533
TA-VAAL iteration: 500 vae_loss: 1.6724427938461304 dsc_loss: 1.385486125946045
TA-VAAL iteration: 600 vae_loss: 1.7005730867385864 dsc_loss: 1.336989402770996
TA-VAAL iteration: 700 vae_loss: 1.7042312622070312 dsc_loss: 1.379807710647583
TA-VAAL iteration: 800 vae_loss: 1.7298450469970703 dsc_loss: 1.3749291896820068
TA-VAAL iteration: 900 vae_loss: 1.6379635334014893 dsc_loss: 1.3835928440093994
TA-VAAL iteration: 1000 vae_loss: 1.778114676475525 dsc_loss: 1.3602420091629028
TA-VAAL iteration: 1100 vae_loss: 1.718578577041626 dsc_loss: 1.3873367309570312
TA-VAAL iteration: 1200 vae_loss: 1.6634438037872314 dsc_loss: 1.3760377168655396
TA-VAAL iteration: 1300 vae_loss: 1.813233733177185 dsc_loss: 1.3824554681777954
TA-VAAL iteration: 1400 vae_loss: 1.7122180461883545 dsc_loss: 1.3464378118515015
TA-VAAL iteration: 1500 vae_loss: 1.7108186483383179 dsc_loss: 1.3502780199050903
TA-VAAL iteration: 1600 vae_loss: 1.8214765787124634 dsc_loss: 1.3891239166259766
TA-VAAL iteration: 1700 vae_loss: 1.7334682941436768 dsc_loss: 1.3879952430725098
TA-VAAL iteration: 1800 vae_loss: 1.8215497732162476 dsc_loss: 1.3643523454666138
TA-VAAL iteration: 1900 vae_loss: 1.8133455514907837 dsc_loss: 1.378662347793579
TA-VAAL iteration: 2000 vae_loss: 1.8651094436645508 dsc_loss: 1.3944909572601318
TA-VAAL iteration: 2100 vae_loss: 1.8807992935180664 dsc_loss: 1.401695728302002
TA-VAAL iteration: 2200 vae_loss: 1.7521350383758545 dsc_loss: 1.3772990703582764
TA-VAAL iteration: 2300 vae_loss: 1.6237168312072754 dsc_loss: 1.424466609954834
TA-VAAL iteration: 2400 vae_loss: 1.8195370435714722 dsc_loss: 1.3769536018371582
TA-VAAL iteration: 2500 vae_loss: 1.9127874374389648 dsc_loss: 1.3824315071105957
TA-VAAL iteration: 2600 vae_loss: 1.8449591398239136 dsc_loss: 1.3660926818847656
TA-VAAL iteration: 2700 vae_loss: 1.8418948650360107 dsc_loss: 1.3855233192443848
TA-VAAL iteration: 2800 vae_loss: 1.9076310396194458 dsc_loss: 1.375624656677246
TA-VAAL iteration: 2900 vae_loss: 1.8547247648239136 dsc_loss: 1.3873602151870728
TA-VAAL iteration: 3000 vae_loss: 1.8675997257232666 dsc_loss: 1.36081063747406
TA-VAAL iteration: 3100 vae_loss: 1.8094141483306885 dsc_loss: 1.4110603332519531
TA-VAAL iteration: 3200 vae_loss: 1.8482520580291748 dsc_loss: 1.3738811016082764
TA-VAAL iteration: 3300 vae_loss: 1.861720085144043 dsc_loss: 1.3992185592651367
TA-VAAL iteration: 3400 vae_loss: 1.872849941253662 dsc_loss: 1.3493613004684448
TA-VAAL iteration: 3500 vae_loss: 1.778855800628662 dsc_loss: 1.4070346355438232
TA-VAAL iteration: 3600 vae_loss: 1.9144660234451294 dsc_loss: 1.3982172012329102
TA-VAAL iteration: 3700 vae_loss: 1.970786452293396 dsc_loss: 1.3838448524475098
TA-VAAL iteration: 3800 vae_loss: 1.9560047388076782 dsc_loss: 1.3455467224121094
TA-VAAL iteration: 3900 vae_loss: 1.8299832344055176 dsc_loss: 1.3819587230682373
TA-VAAL iteration: 4000 vae_loss: 2.0272865295410156 dsc_loss: 1.3806742429733276
TA-VAAL iteration: 4100 vae_loss: 1.9259759187698364 dsc_loss: 1.3933826684951782
TA-VAAL iteration: 4200 vae_loss: 1.9394859075546265 dsc_loss: 1.3413844108581543
TA-VAAL iteration: 4300 vae_loss: 1.8605057001113892 dsc_loss: 1.393632411956787
TA-VAAL iteration: 4400 vae_loss: 1.935905933380127 dsc_loss: 1.3749947547912598
TA-VAAL iteration: 4500 vae_loss: 1.90975821018219 dsc_loss: 1.376259207725525
TA-VAAL iteration: 4600 vae_loss: 2.0243446826934814 dsc_loss: 1.351144552230835
TA-VAAL iteration: 4700 vae_loss: 2.0002522468566895 dsc_loss: 1.3737328052520752
TA-VAAL iteration: 4800 vae_loss: 1.9451820850372314 dsc_loss: 1.3972585201263428
TA-VAAL iteration: 4900 vae_loss: 2.0448412895202637 dsc_loss: 1.3878400325775146
TA-VAAL iteration: 5000 vae_loss: 2.0590710639953613 dsc_loss: 1.3529577255249023
TA-VAAL iteration: 5100 vae_loss: 2.0751585960388184 dsc_loss: 1.371358871459961
TA-VAAL iteration: 5200 vae_loss: 2.086529016494751 dsc_loss: 1.3779289722442627
TA-VAAL iteration: 5300 vae_loss: 2.0374977588653564 dsc_loss: 1.3974632024765015
TA-VAAL iteration: 5400 vae_loss: 2.123199939727783 dsc_loss: 1.34035325050354
TA-VAAL iteration: 5500 vae_loss: 2.0536394119262695 dsc_loss: 1.4061639308929443
TA-VAAL iteration: 5600 vae_loss: 2.0453577041625977 dsc_loss: 1.3839409351348877
TA-VAAL iteration: 5700 vae_loss: 2.1425974369049072 dsc_loss: 1.3820433616638184
TA-VAAL iteration: 5800 vae_loss: 2.019160747528076 dsc_loss: 1.3525832891464233
TA-VAAL iteration: 5900 vae_loss: 2.0608081817626953 dsc_loss: 1.3950016498565674
TA-VAAL iteration: 6000 vae_loss: 2.055614948272705 dsc_loss: 1.393592119216919
TA-VAAL iteration: 6100 vae_loss: 2.129979372024536 dsc_loss: 1.3927500247955322
TA-VAAL iteration: 6200 vae_loss: 2.1580209732055664 dsc_loss: 1.3544487953186035
TA-VAAL iteration: 6300 vae_loss: 2.1156060695648193 dsc_loss: 1.3831241130828857
TA-VAAL iteration: 6400 vae_loss: 2.082599639892578 dsc_loss: 1.3875948190689087
TA-VAAL iteration: 6500 vae_loss: 2.19919490814209 dsc_loss: 1.3910256624221802
TA-VAAL iteration: 6600 vae_loss: 2.112011432647705 dsc_loss: 1.336876630783081
TA-VAAL iteration: 6700 vae_loss: 2.1213088035583496 dsc_loss: 1.407628059387207
TA-VAAL iteration: 6800 vae_loss: 2.1714329719543457 dsc_loss: 1.3770313262939453
TA-VAAL iteration: 6900 vae_loss: 2.150406837463379 dsc_loss: 1.3796775341033936
TA-VAAL iteration: 7000 vae_loss: 2.1213879585266113 dsc_loss: 1.3603332042694092
TA-VAAL iteration: 7100 vae_loss: 2.1456263065338135 dsc_loss: 1.3911418914794922
TA-VAAL iteration: 7200 vae_loss: 2.159849166870117 dsc_loss: 1.3890950679779053
1200 105908 199 106952
>> Train vae and task model
epoch 0: train loss is  1.59124
epoch 10: train loss is  1.45111
epoch 20: train loss is  1.38713
epoch 30: train loss is  1.38080
epoch 40: train loss is  1.36424
epoch 50: train loss is  1.33340
epoch 60: train loss is  1.29704
epoch 70: train loss is  1.34297
epoch 80: train loss is  1.23260
epoch 90: train loss is  1.18502
epoch 100: train loss is  1.21596
epoch 110: train loss is  1.17194
epoch 120: train loss is  1.21331
 >> Test Model
Cycle 6/10 || labeled data size 1200, test loss(MAE) =  0.73895
TA-VAAL iteration: 0 vae_loss: 1.7443104982376099 dsc_loss: 1.3898423910140991
TA-VAAL iteration: 10 vae_loss: 1.6789900064468384 dsc_loss: 1.3973357677459717
TA-VAAL iteration: 20 vae_loss: 1.474048137664795 dsc_loss: 1.3841261863708496
TA-VAAL iteration: 30 vae_loss: 1.6068425178527832 dsc_loss: 1.3815953731536865
TA-VAAL iteration: 40 vae_loss: 1.7112866640090942 dsc_loss: 1.3845261335372925
TA-VAAL iteration: 50 vae_loss: 1.8226830959320068 dsc_loss: 1.3909289836883545
TA-VAAL iteration: 60 vae_loss: 1.7364487648010254 dsc_loss: 1.3719685077667236
TA-VAAL iteration: 70 vae_loss: 1.769822359085083 dsc_loss: 1.3795154094696045
TA-VAAL iteration: 80 vae_loss: 1.7506717443466187 dsc_loss: 1.4200983047485352
TA-VAAL iteration: 90 vae_loss: 1.6948037147521973 dsc_loss: 1.3746755123138428
TA-VAAL iteration: 100 vae_loss: 1.5607306957244873 dsc_loss: 1.3841828107833862
TA-VAAL iteration: 200 vae_loss: 1.5765849351882935 dsc_loss: 1.3911237716674805
TA-VAAL iteration: 300 vae_loss: 1.599586009979248 dsc_loss: 1.3883070945739746
TA-VAAL iteration: 400 vae_loss: 1.5265536308288574 dsc_loss: 1.3901162147521973
TA-VAAL iteration: 500 vae_loss: 1.597576379776001 dsc_loss: 1.3702176809310913
TA-VAAL iteration: 600 vae_loss: 1.5841965675354004 dsc_loss: 1.3796982765197754
TA-VAAL iteration: 700 vae_loss: 1.7198035717010498 dsc_loss: 1.3946378231048584
TA-VAAL iteration: 800 vae_loss: 1.555523157119751 dsc_loss: 1.387563705444336
TA-VAAL iteration: 900 vae_loss: 1.7261511087417603 dsc_loss: 1.385586142539978
TA-VAAL iteration: 1000 vae_loss: 1.6247344017028809 dsc_loss: 1.3929028511047363
TA-VAAL iteration: 1100 vae_loss: 1.6868236064910889 dsc_loss: 1.3807015419006348
TA-VAAL iteration: 1200 vae_loss: 1.6410783529281616 dsc_loss: 1.3951020240783691
TA-VAAL iteration: 1300 vae_loss: 1.6971184015274048 dsc_loss: 1.385331392288208
TA-VAAL iteration: 1400 vae_loss: 1.6721398830413818 dsc_loss: 1.3875292539596558
TA-VAAL iteration: 1500 vae_loss: 1.6542882919311523 dsc_loss: 1.3615262508392334
TA-VAAL iteration: 1600 vae_loss: 1.797368049621582 dsc_loss: 1.3790733814239502
TA-VAAL iteration: 1700 vae_loss: 1.662569522857666 dsc_loss: 1.3964707851409912
TA-VAAL iteration: 1800 vae_loss: 1.6491484642028809 dsc_loss: 1.390350580215454
TA-VAAL iteration: 1900 vae_loss: 1.6527687311172485 dsc_loss: 1.383184552192688
TA-VAAL iteration: 2000 vae_loss: 1.851967453956604 dsc_loss: 1.3822073936462402
TA-VAAL iteration: 2100 vae_loss: 1.6290369033813477 dsc_loss: 1.3883814811706543
TA-VAAL iteration: 2200 vae_loss: 1.6814415454864502 dsc_loss: 1.3935596942901611
TA-VAAL iteration: 2300 vae_loss: 1.6241276264190674 dsc_loss: 1.393141746520996
TA-VAAL iteration: 2400 vae_loss: 1.9331527948379517 dsc_loss: 1.3964252471923828
TA-VAAL iteration: 2500 vae_loss: 1.7754324674606323 dsc_loss: 1.3839104175567627
TA-VAAL iteration: 2600 vae_loss: 1.7424027919769287 dsc_loss: 1.3795440196990967
TA-VAAL iteration: 2700 vae_loss: 1.6669994592666626 dsc_loss: 1.3860485553741455
TA-VAAL iteration: 2800 vae_loss: 1.8673909902572632 dsc_loss: 1.3755831718444824
TA-VAAL iteration: 2900 vae_loss: 1.706000804901123 dsc_loss: 1.3802858591079712
TA-VAAL iteration: 3000 vae_loss: 1.8158442974090576 dsc_loss: 1.3507500886917114
TA-VAAL iteration: 3100 vae_loss: 1.8136820793151855 dsc_loss: 1.3818448781967163
TA-VAAL iteration: 3200 vae_loss: 1.8834584951400757 dsc_loss: 1.3896719217300415
TA-VAAL iteration: 3300 vae_loss: 1.6690430641174316 dsc_loss: 1.3899563550949097
TA-VAAL iteration: 3400 vae_loss: 1.7420991659164429 dsc_loss: 1.3339024782180786
TA-VAAL iteration: 3500 vae_loss: 1.9928336143493652 dsc_loss: 1.3768892288208008
TA-VAAL iteration: 3600 vae_loss: 1.6875629425048828 dsc_loss: 1.4095511436462402
TA-VAAL iteration: 3700 vae_loss: 1.9565881490707397 dsc_loss: 1.4049859046936035
TA-VAAL iteration: 3800 vae_loss: 1.6999448537826538 dsc_loss: 1.38962721824646
TA-VAAL iteration: 3900 vae_loss: 1.9021488428115845 dsc_loss: 1.374164342880249
TA-VAAL iteration: 4000 vae_loss: 1.7836644649505615 dsc_loss: 1.4016437530517578
TA-VAAL iteration: 4100 vae_loss: 1.8343955278396606 dsc_loss: 1.3815500736236572
TA-VAAL iteration: 4200 vae_loss: 1.7721703052520752 dsc_loss: 1.3824717998504639
TA-VAAL iteration: 4300 vae_loss: 2.091559410095215 dsc_loss: 1.3903883695602417
TA-VAAL iteration: 4400 vae_loss: 1.9209734201431274 dsc_loss: 1.378420114517212
TA-VAAL iteration: 4500 vae_loss: 2.0119986534118652 dsc_loss: 1.366530418395996
TA-VAAL iteration: 4600 vae_loss: 2.1207275390625 dsc_loss: 1.3716790676116943
TA-VAAL iteration: 4700 vae_loss: 1.8834786415100098 dsc_loss: 1.3706316947937012
TA-VAAL iteration: 4800 vae_loss: 1.8508343696594238 dsc_loss: 1.3946387767791748
TA-VAAL iteration: 4900 vae_loss: 1.9409191608428955 dsc_loss: 1.335740327835083
TA-VAAL iteration: 5000 vae_loss: 2.339834213256836 dsc_loss: 1.3712965250015259
TA-VAAL iteration: 5100 vae_loss: 1.894163966178894 dsc_loss: 1.3781558275222778
TA-VAAL iteration: 5200 vae_loss: 1.9871262311935425 dsc_loss: 1.3783583641052246
TA-VAAL iteration: 5300 vae_loss: 1.9218074083328247 dsc_loss: 1.3725532293319702
TA-VAAL iteration: 5400 vae_loss: 2.2036659717559814 dsc_loss: 1.3662912845611572
TA-VAAL iteration: 5500 vae_loss: 2.1605944633483887 dsc_loss: 1.345018982887268
TA-VAAL iteration: 5600 vae_loss: 2.264723777770996 dsc_loss: 1.3429598808288574
TA-VAAL iteration: 5700 vae_loss: 2.035487174987793 dsc_loss: 1.3487756252288818
TA-VAAL iteration: 5800 vae_loss: 2.5504846572875977 dsc_loss: 1.4017592668533325
TA-VAAL iteration: 5900 vae_loss: 2.172718048095703 dsc_loss: 1.3470122814178467
TA-VAAL iteration: 6000 vae_loss: 2.2552237510681152 dsc_loss: 1.3377476930618286
TA-VAAL iteration: 6100 vae_loss: 2.1150553226470947 dsc_loss: 1.4237151145935059
TA-VAAL iteration: 6200 vae_loss: 2.191183090209961 dsc_loss: 1.3394650220870972
TA-VAAL iteration: 6300 vae_loss: 2.1413347721099854 dsc_loss: 1.3859705924987793
TA-VAAL iteration: 6400 vae_loss: 2.507333755493164 dsc_loss: 1.3521032333374023
TA-VAAL iteration: 6500 vae_loss: 1.8011913299560547 dsc_loss: 1.356168508529663
TA-VAAL iteration: 6600 vae_loss: 2.351593017578125 dsc_loss: 1.3725111484527588
TA-VAAL iteration: 6700 vae_loss: 1.9572837352752686 dsc_loss: 1.3532642126083374
TA-VAAL iteration: 6800 vae_loss: 2.5536088943481445 dsc_loss: 1.3784418106079102
TA-VAAL iteration: 6900 vae_loss: 2.0338683128356934 dsc_loss: 1.3486456871032715
TA-VAAL iteration: 7000 vae_loss: 2.5443315505981445 dsc_loss: 1.3711121082305908
TA-VAAL iteration: 7100 vae_loss: 2.1345319747924805 dsc_loss: 1.351725459098816
TA-VAAL iteration: 7200 vae_loss: 2.126483678817749 dsc_loss: 1.3773225545883179
TA-VAAL iteration: 7300 vae_loss: 2.729642868041992 dsc_loss: 1.3935750722885132
TA-VAAL iteration: 7400 vae_loss: 2.1241607666015625 dsc_loss: 1.3692622184753418
1400 105708 199 106952
>> Train vae and task model
epoch 0: train loss is  1.60628
epoch 10: train loss is  1.46708
epoch 20: train loss is  1.41476
epoch 30: train loss is  1.38016
epoch 40: train loss is  1.34427
epoch 50: train loss is  1.29722
epoch 60: train loss is  1.33093
epoch 70: train loss is  1.28069
epoch 80: train loss is  1.20569
epoch 90: train loss is  1.20386
epoch 100: train loss is  1.17909
epoch 110: train loss is  1.14497
epoch 120: train loss is  1.10493
 >> Test Model
Cycle 7/10 || labeled data size 1400, test loss(MAE) =  0.72226
TA-VAAL iteration: 0 vae_loss: 1.6692047119140625 dsc_loss: 1.4075090885162354
TA-VAAL iteration: 10 vae_loss: 1.6887422800064087 dsc_loss: 1.3982715606689453
TA-VAAL iteration: 20 vae_loss: 1.911144495010376 dsc_loss: 1.4077637195587158
TA-VAAL iteration: 30 vae_loss: 1.7085834741592407 dsc_loss: 1.3866596221923828
TA-VAAL iteration: 40 vae_loss: 1.900472640991211 dsc_loss: 1.3167595863342285
TA-VAAL iteration: 50 vae_loss: 1.8329460620880127 dsc_loss: 1.3932526111602783
TA-VAAL iteration: 60 vae_loss: 2.1172776222229004 dsc_loss: 1.3712644577026367
TA-VAAL iteration: 70 vae_loss: 1.8290162086486816 dsc_loss: 1.384011149406433
TA-VAAL iteration: 80 vae_loss: 1.8577183485031128 dsc_loss: 1.359872579574585
TA-VAAL iteration: 90 vae_loss: 1.7528102397918701 dsc_loss: 1.3829386234283447
TA-VAAL iteration: 100 vae_loss: 1.7470684051513672 dsc_loss: 1.3854711055755615
TA-VAAL iteration: 200 vae_loss: 1.5745558738708496 dsc_loss: 1.4039602279663086
TA-VAAL iteration: 300 vae_loss: 1.7190557718276978 dsc_loss: 1.380993127822876
TA-VAAL iteration: 400 vae_loss: 1.6831483840942383 dsc_loss: 1.3642082214355469
TA-VAAL iteration: 500 vae_loss: 1.7682982683181763 dsc_loss: 1.3981441259384155
TA-VAAL iteration: 600 vae_loss: 1.7442338466644287 dsc_loss: 1.401716947555542
TA-VAAL iteration: 700 vae_loss: 1.7050468921661377 dsc_loss: 1.344238519668579
TA-VAAL iteration: 800 vae_loss: 1.7270252704620361 dsc_loss: 1.3891373872756958
TA-VAAL iteration: 900 vae_loss: 1.786224365234375 dsc_loss: 1.3733127117156982
TA-VAAL iteration: 1000 vae_loss: 1.7967725992202759 dsc_loss: 1.399261713027954
TA-VAAL iteration: 1100 vae_loss: 1.6701970100402832 dsc_loss: 1.3859437704086304
TA-VAAL iteration: 1200 vae_loss: 1.7558608055114746 dsc_loss: 1.3816726207733154
TA-VAAL iteration: 1300 vae_loss: 1.6555194854736328 dsc_loss: 1.365067720413208
TA-VAAL iteration: 1400 vae_loss: 1.6528146266937256 dsc_loss: 1.3923282623291016
TA-VAAL iteration: 1500 vae_loss: 1.6724016666412354 dsc_loss: 1.417651891708374
TA-VAAL iteration: 1600 vae_loss: 1.6296825408935547 dsc_loss: 1.3553212881088257
TA-VAAL iteration: 1700 vae_loss: 1.7677409648895264 dsc_loss: 1.3741202354431152
TA-VAAL iteration: 1800 vae_loss: 1.656156063079834 dsc_loss: 1.3420507907867432
TA-VAAL iteration: 1900 vae_loss: 1.7666001319885254 dsc_loss: 1.396681785583496
TA-VAAL iteration: 2000 vae_loss: 1.7510911226272583 dsc_loss: 1.378689169883728
TA-VAAL iteration: 2100 vae_loss: 1.6762436628341675 dsc_loss: 1.397117018699646
TA-VAAL iteration: 2200 vae_loss: 1.7073662281036377 dsc_loss: 1.3747402429580688
TA-VAAL iteration: 2300 vae_loss: 1.7016432285308838 dsc_loss: 1.3992857933044434
TA-VAAL iteration: 2400 vae_loss: 1.5907180309295654 dsc_loss: 1.3958346843719482
TA-VAAL iteration: 2500 vae_loss: 1.8520307540893555 dsc_loss: 1.4005236625671387
TA-VAAL iteration: 2600 vae_loss: 1.7137858867645264 dsc_loss: 1.387890338897705
TA-VAAL iteration: 2700 vae_loss: 1.7161797285079956 dsc_loss: 1.3565287590026855
TA-VAAL iteration: 2800 vae_loss: 1.7413499355316162 dsc_loss: 1.3937569856643677
TA-VAAL iteration: 2900 vae_loss: 1.8287758827209473 dsc_loss: 1.346449375152588
TA-VAAL iteration: 3000 vae_loss: 1.8000725507736206 dsc_loss: 1.3964202404022217
TA-VAAL iteration: 3100 vae_loss: 1.8231565952301025 dsc_loss: 1.3906928300857544
TA-VAAL iteration: 3200 vae_loss: 1.7090877294540405 dsc_loss: 1.4013676643371582
TA-VAAL iteration: 3300 vae_loss: 1.6245794296264648 dsc_loss: 1.402482032775879
TA-VAAL iteration: 3400 vae_loss: 1.8436815738677979 dsc_loss: 1.3779253959655762
TA-VAAL iteration: 3500 vae_loss: 1.6809170246124268 dsc_loss: 1.3698515892028809
TA-VAAL iteration: 3600 vae_loss: 1.724053144454956 dsc_loss: 1.408933162689209
TA-VAAL iteration: 3700 vae_loss: 1.7974803447723389 dsc_loss: 1.374079704284668
TA-VAAL iteration: 3800 vae_loss: 1.7971599102020264 dsc_loss: 1.3405344486236572
TA-VAAL iteration: 3900 vae_loss: 1.84702467918396 dsc_loss: 1.3716455698013306
TA-VAAL iteration: 4000 vae_loss: 1.9163813591003418 dsc_loss: 1.3418176174163818
TA-VAAL iteration: 4100 vae_loss: 1.8671774864196777 dsc_loss: 1.3980859518051147
TA-VAAL iteration: 4200 vae_loss: 1.876510739326477 dsc_loss: 1.3848869800567627
TA-VAAL iteration: 4300 vae_loss: 1.8157167434692383 dsc_loss: 1.3956835269927979
TA-VAAL iteration: 4400 vae_loss: 1.7944300174713135 dsc_loss: 1.369586706161499
TA-VAAL iteration: 4500 vae_loss: 1.8523156642913818 dsc_loss: 1.3934242725372314
TA-VAAL iteration: 4600 vae_loss: 1.6787563562393188 dsc_loss: 1.4023922681808472
TA-VAAL iteration: 4700 vae_loss: 1.8758509159088135 dsc_loss: 1.404801368713379
TA-VAAL iteration: 4800 vae_loss: 1.8401861190795898 dsc_loss: 1.3586386442184448
TA-VAAL iteration: 4900 vae_loss: 1.8640565872192383 dsc_loss: 1.3620755672454834
TA-VAAL iteration: 5000 vae_loss: 1.8078702688217163 dsc_loss: 1.3865110874176025
TA-VAAL iteration: 5100 vae_loss: 1.9657007455825806 dsc_loss: 1.3480174541473389
TA-VAAL iteration: 5200 vae_loss: 2.077406883239746 dsc_loss: 1.3879585266113281
TA-VAAL iteration: 5300 vae_loss: 1.9997832775115967 dsc_loss: 1.3800513744354248
TA-VAAL iteration: 5400 vae_loss: 1.9396309852600098 dsc_loss: 1.379137396812439
TA-VAAL iteration: 5500 vae_loss: 1.9427783489227295 dsc_loss: 1.3727039098739624
TA-VAAL iteration: 5600 vae_loss: 1.9579428434371948 dsc_loss: 1.3743680715560913
TA-VAAL iteration: 5700 vae_loss: 1.9508018493652344 dsc_loss: 1.3586204051971436
TA-VAAL iteration: 5800 vae_loss: 1.9651294946670532 dsc_loss: 1.4072744846343994
TA-VAAL iteration: 5900 vae_loss: 1.9304890632629395 dsc_loss: 1.369545340538025
TA-VAAL iteration: 6000 vae_loss: 2.162754535675049 dsc_loss: 1.3575329780578613
TA-VAAL iteration: 6100 vae_loss: 2.0344607830047607 dsc_loss: 1.366881251335144
TA-VAAL iteration: 6200 vae_loss: 2.101167678833008 dsc_loss: 1.284165859222412
TA-VAAL iteration: 6300 vae_loss: 2.0898633003234863 dsc_loss: 1.3991036415100098
TA-VAAL iteration: 6400 vae_loss: 2.027690887451172 dsc_loss: 1.3941302299499512
TA-VAAL iteration: 6500 vae_loss: 1.9109187126159668 dsc_loss: 1.3898224830627441
TA-VAAL iteration: 6600 vae_loss: 2.0284996032714844 dsc_loss: 1.3489981889724731
TA-VAAL iteration: 6700 vae_loss: 2.0557703971862793 dsc_loss: 1.3851028680801392
TA-VAAL iteration: 6800 vae_loss: 1.9058867692947388 dsc_loss: 1.3955659866333008
TA-VAAL iteration: 6900 vae_loss: 2.221121072769165 dsc_loss: 1.3752391338348389
TA-VAAL iteration: 7000 vae_loss: 2.3294548988342285 dsc_loss: 1.3833787441253662
TA-VAAL iteration: 7100 vae_loss: 2.2592875957489014 dsc_loss: 1.3461991548538208
TA-VAAL iteration: 7200 vae_loss: 2.117339611053467 dsc_loss: 1.3931126594543457
TA-VAAL iteration: 7300 vae_loss: 2.1591615676879883 dsc_loss: 1.3220458030700684
TA-VAAL iteration: 7400 vae_loss: 2.059451103210449 dsc_loss: 1.3893027305603027
TA-VAAL iteration: 7500 vae_loss: 2.0184857845306396 dsc_loss: 1.3798640966415405
TA-VAAL iteration: 7600 vae_loss: 2.0372753143310547 dsc_loss: 1.402459979057312
TA-VAAL iteration: 7700 vae_loss: 2.0071263313293457 dsc_loss: 1.3697659969329834
1600 105508 150 106952
>> Train vae and task model
epoch 0: train loss is  1.57157
epoch 10: train loss is  1.42870
epoch 20: train loss is  1.33565
epoch 30: train loss is  1.27885
epoch 40: train loss is  1.27979
epoch 50: train loss is  1.27068
epoch 60: train loss is  1.20825
epoch 70: train loss is  1.17660
epoch 80: train loss is  1.14696
epoch 90: train loss is  1.12640
epoch 100: train loss is  1.14395
epoch 110: train loss is  1.12415
epoch 120: train loss is  1.14060
 >> Test Model
Cycle 8/10 || labeled data size 1600, test loss(MAE) =  0.70075
TA-VAAL iteration: 0 vae_loss: 1.8485043048858643 dsc_loss: 1.3887676000595093
TA-VAAL iteration: 10 vae_loss: 1.83684241771698 dsc_loss: 1.407377004623413
TA-VAAL iteration: 20 vae_loss: 1.7820762395858765 dsc_loss: 1.3942577838897705
TA-VAAL iteration: 30 vae_loss: 1.7754360437393188 dsc_loss: 1.3569304943084717
TA-VAAL iteration: 40 vae_loss: 1.7580379247665405 dsc_loss: 1.3877066373825073
TA-VAAL iteration: 50 vae_loss: 1.8487595319747925 dsc_loss: 1.3945156335830688
TA-VAAL iteration: 60 vae_loss: 1.906387448310852 dsc_loss: 1.3904550075531006
TA-VAAL iteration: 70 vae_loss: 1.7336913347244263 dsc_loss: 1.457688808441162
TA-VAAL iteration: 80 vae_loss: 1.7878868579864502 dsc_loss: 1.3657673597335815
TA-VAAL iteration: 90 vae_loss: 1.7597203254699707 dsc_loss: 1.3926746845245361
TA-VAAL iteration: 100 vae_loss: 1.7013776302337646 dsc_loss: 1.4004460573196411
TA-VAAL iteration: 200 vae_loss: 1.4739915132522583 dsc_loss: 1.4386529922485352
TA-VAAL iteration: 300 vae_loss: 1.693967580795288 dsc_loss: 1.3941352367401123
TA-VAAL iteration: 400 vae_loss: 1.6980432271957397 dsc_loss: 1.3874210119247437
TA-VAAL iteration: 500 vae_loss: 1.6434310674667358 dsc_loss: 1.3872363567352295
TA-VAAL iteration: 600 vae_loss: 1.710503339767456 dsc_loss: 1.400146484375
TA-VAAL iteration: 700 vae_loss: 1.6458150148391724 dsc_loss: 1.3910081386566162
TA-VAAL iteration: 800 vae_loss: 1.633229374885559 dsc_loss: 1.400294542312622
TA-VAAL iteration: 900 vae_loss: 1.6255476474761963 dsc_loss: 1.3977594375610352
TA-VAAL iteration: 1000 vae_loss: 1.7844889163970947 dsc_loss: 1.3814623355865479
TA-VAAL iteration: 1100 vae_loss: 1.6711138486862183 dsc_loss: 1.384652853012085
TA-VAAL iteration: 1200 vae_loss: 1.6614497900009155 dsc_loss: 1.4032670259475708
TA-VAAL iteration: 1300 vae_loss: 1.6746935844421387 dsc_loss: 1.401860237121582
TA-VAAL iteration: 1400 vae_loss: 1.552370309829712 dsc_loss: 1.3901565074920654
TA-VAAL iteration: 1500 vae_loss: 1.5914762020111084 dsc_loss: 1.3874744176864624
TA-VAAL iteration: 1600 vae_loss: 1.5421222448349 dsc_loss: 1.396726369857788
TA-VAAL iteration: 1700 vae_loss: 1.5381149053573608 dsc_loss: 1.3963980674743652
TA-VAAL iteration: 1800 vae_loss: 1.6847164630889893 dsc_loss: 1.3844391107559204
TA-VAAL iteration: 1900 vae_loss: 1.5654168128967285 dsc_loss: 1.4088778495788574
TA-VAAL iteration: 2000 vae_loss: 1.645512342453003 dsc_loss: 1.3864867687225342
TA-VAAL iteration: 2100 vae_loss: 1.5954900979995728 dsc_loss: 1.3919059038162231
TA-VAAL iteration: 2200 vae_loss: 1.62416410446167 dsc_loss: 1.3829742670059204
TA-VAAL iteration: 2300 vae_loss: 1.7010586261749268 dsc_loss: 1.3862791061401367
TA-VAAL iteration: 2400 vae_loss: 1.5645874738693237 dsc_loss: 1.383023738861084
TA-VAAL iteration: 2500 vae_loss: 1.5511484146118164 dsc_loss: 1.3929660320281982
TA-VAAL iteration: 2600 vae_loss: 1.635119915008545 dsc_loss: 1.385256290435791
TA-VAAL iteration: 2700 vae_loss: 1.5748414993286133 dsc_loss: 1.3910322189331055
TA-VAAL iteration: 2800 vae_loss: 1.610325813293457 dsc_loss: 1.3949270248413086
TA-VAAL iteration: 2900 vae_loss: 1.5344609022140503 dsc_loss: 1.3981585502624512
TA-VAAL iteration: 3000 vae_loss: 1.5767996311187744 dsc_loss: 1.3952664136886597
TA-VAAL iteration: 3100 vae_loss: 1.488355278968811 dsc_loss: 1.3907067775726318
TA-VAAL iteration: 3200 vae_loss: 1.5616377592086792 dsc_loss: 1.390830397605896
TA-VAAL iteration: 3300 vae_loss: 1.5151045322418213 dsc_loss: 1.3887975215911865
TA-VAAL iteration: 3400 vae_loss: 1.5921123027801514 dsc_loss: 1.3827519416809082
TA-VAAL iteration: 3500 vae_loss: 1.6172857284545898 dsc_loss: 1.3897316455841064
TA-VAAL iteration: 3600 vae_loss: 1.6399098634719849 dsc_loss: 1.3941344022750854
TA-VAAL iteration: 3700 vae_loss: 1.612621545791626 dsc_loss: 1.3886833190917969
TA-VAAL iteration: 3800 vae_loss: 1.6145998239517212 dsc_loss: 1.3918160200119019
TA-VAAL iteration: 3900 vae_loss: 1.5582518577575684 dsc_loss: 1.387389898300171
TA-VAAL iteration: 4000 vae_loss: 1.5661876201629639 dsc_loss: 1.3880858421325684
TA-VAAL iteration: 4100 vae_loss: 1.6025385856628418 dsc_loss: 1.3918583393096924
TA-VAAL iteration: 4200 vae_loss: 1.5625534057617188 dsc_loss: 1.4075818061828613
TA-VAAL iteration: 4300 vae_loss: 1.694008708000183 dsc_loss: 1.375380039215088
TA-VAAL iteration: 4400 vae_loss: 1.6977273225784302 dsc_loss: 1.384812831878662
TA-VAAL iteration: 4500 vae_loss: 1.6861876249313354 dsc_loss: 1.3794296979904175
TA-VAAL iteration: 4600 vae_loss: 1.668152093887329 dsc_loss: 1.3780477046966553
TA-VAAL iteration: 4700 vae_loss: 1.6631320714950562 dsc_loss: 1.3822709321975708
TA-VAAL iteration: 4800 vae_loss: 1.6300618648529053 dsc_loss: 1.3828279972076416
TA-VAAL iteration: 4900 vae_loss: 1.626488447189331 dsc_loss: 1.3908791542053223
TA-VAAL iteration: 5000 vae_loss: 1.621349811553955 dsc_loss: 1.3861663341522217
TA-VAAL iteration: 5100 vae_loss: 1.609809398651123 dsc_loss: 1.3934221267700195
TA-VAAL iteration: 5200 vae_loss: 1.591125726699829 dsc_loss: 1.3735744953155518
TA-VAAL iteration: 5300 vae_loss: 1.6742651462554932 dsc_loss: 1.3821182250976562
TA-VAAL iteration: 5400 vae_loss: 1.6525166034698486 dsc_loss: 1.3752926588058472
TA-VAAL iteration: 5500 vae_loss: 1.6727159023284912 dsc_loss: 1.3791247606277466
TA-VAAL iteration: 5600 vae_loss: 1.555344581604004 dsc_loss: 1.3912197351455688
TA-VAAL iteration: 5700 vae_loss: 1.5638349056243896 dsc_loss: 1.381276249885559
TA-VAAL iteration: 5800 vae_loss: 1.6241734027862549 dsc_loss: 1.3693675994873047
TA-VAAL iteration: 5900 vae_loss: 1.6151278018951416 dsc_loss: 1.3846625089645386
TA-VAAL iteration: 6000 vae_loss: 1.7249391078948975 dsc_loss: 1.3751227855682373
TA-VAAL iteration: 6100 vae_loss: 1.7650748491287231 dsc_loss: 1.3818632364273071
TA-VAAL iteration: 6200 vae_loss: 1.6077111959457397 dsc_loss: 1.3851690292358398
TA-VAAL iteration: 6300 vae_loss: 1.694022536277771 dsc_loss: 1.3791215419769287
TA-VAAL iteration: 6400 vae_loss: 1.6932659149169922 dsc_loss: 1.3938188552856445
TA-VAAL iteration: 6500 vae_loss: 1.7426021099090576 dsc_loss: 1.3820796012878418
TA-VAAL iteration: 6600 vae_loss: 1.6418545246124268 dsc_loss: 1.3944675922393799
TA-VAAL iteration: 6700 vae_loss: 1.6727792024612427 dsc_loss: 1.3630857467651367
TA-VAAL iteration: 6800 vae_loss: 1.638780117034912 dsc_loss: 1.3859524726867676
TA-VAAL iteration: 6900 vae_loss: 1.7169427871704102 dsc_loss: 1.3798210620880127
TA-VAAL iteration: 7000 vae_loss: 1.6864306926727295 dsc_loss: 1.381025791168213
TA-VAAL iteration: 7100 vae_loss: 1.671588659286499 dsc_loss: 1.38573157787323
TA-VAAL iteration: 7200 vae_loss: 1.7053301334381104 dsc_loss: 1.3772090673446655
TA-VAAL iteration: 7300 vae_loss: 1.5969949960708618 dsc_loss: 1.3825582265853882
TA-VAAL iteration: 7400 vae_loss: 1.6068556308746338 dsc_loss: 1.3930342197418213
TA-VAAL iteration: 7500 vae_loss: 1.6991424560546875 dsc_loss: 1.388326644897461
TA-VAAL iteration: 7600 vae_loss: 1.759250283241272 dsc_loss: 1.388059377670288
TA-VAAL iteration: 7700 vae_loss: 1.7611943483352661 dsc_loss: 1.392094373703003
TA-VAAL iteration: 7800 vae_loss: 1.7162151336669922 dsc_loss: 1.3811237812042236
TA-VAAL iteration: 7900 vae_loss: 1.7840615510940552 dsc_loss: 1.3833661079406738
1800 105308 150 107053
>> Train vae and task model
epoch 0: train loss is  1.55368
epoch 10: train loss is  1.42832
epoch 20: train loss is  1.41529
epoch 30: train loss is  1.38209
epoch 40: train loss is  1.32180
epoch 50: train loss is  1.30448
epoch 60: train loss is  1.27086
epoch 70: train loss is  1.28839
epoch 80: train loss is  1.28018
epoch 90: train loss is  1.23202
epoch 100: train loss is  1.22571
epoch 110: train loss is  1.21407
epoch 120: train loss is  1.22300
 >> Test Model
Cycle 9/10 || labeled data size 1800, test loss(MAE) =  0.73895
TA-VAAL iteration: 0 vae_loss: 1.9387071132659912 dsc_loss: 1.3857290744781494
TA-VAAL iteration: 10 vae_loss: 1.919119119644165 dsc_loss: 1.4138542413711548
TA-VAAL iteration: 20 vae_loss: 1.7266820669174194 dsc_loss: 1.322812795639038
TA-VAAL iteration: 30 vae_loss: 1.8359448909759521 dsc_loss: 1.383875846862793
TA-VAAL iteration: 40 vae_loss: 1.8268413543701172 dsc_loss: 1.3746142387390137
TA-VAAL iteration: 50 vae_loss: 2.073542594909668 dsc_loss: 1.4580085277557373
TA-VAAL iteration: 60 vae_loss: 1.6919546127319336 dsc_loss: 1.377814769744873
TA-VAAL iteration: 70 vae_loss: 1.7732114791870117 dsc_loss: 1.3884844779968262
TA-VAAL iteration: 80 vae_loss: 1.748359203338623 dsc_loss: 1.5713478326797485
TA-VAAL iteration: 90 vae_loss: 1.6023890972137451 dsc_loss: 1.4377071857452393
TA-VAAL iteration: 100 vae_loss: 1.728962779045105 dsc_loss: 1.3975975513458252
TA-VAAL iteration: 200 vae_loss: 1.3394163846969604 dsc_loss: 1.402159333229065
TA-VAAL iteration: 300 vae_loss: 1.5786268711090088 dsc_loss: 1.3848152160644531
TA-VAAL iteration: 400 vae_loss: 1.753090739250183 dsc_loss: 1.4492745399475098
TA-VAAL iteration: 500 vae_loss: 1.6733067035675049 dsc_loss: 1.388227105140686
TA-VAAL iteration: 600 vae_loss: 1.6979910135269165 dsc_loss: 1.3458490371704102
TA-VAAL iteration: 700 vae_loss: 1.6142487525939941 dsc_loss: 1.3848321437835693
TA-VAAL iteration: 800 vae_loss: 1.6137168407440186 dsc_loss: 1.4146549701690674
TA-VAAL iteration: 900 vae_loss: 1.440435528755188 dsc_loss: 1.3915199041366577
TA-VAAL iteration: 1000 vae_loss: 1.549299716949463 dsc_loss: 1.3850429058074951
TA-VAAL iteration: 1100 vae_loss: 1.4359674453735352 dsc_loss: 1.3881995677947998
TA-VAAL iteration: 1200 vae_loss: 1.6794567108154297 dsc_loss: 1.390120029449463
TA-VAAL iteration: 1300 vae_loss: 1.5376341342926025 dsc_loss: 1.4213095903396606
TA-VAAL iteration: 1400 vae_loss: 1.657839298248291 dsc_loss: 1.385737657546997
TA-VAAL iteration: 1500 vae_loss: 1.6635289192199707 dsc_loss: 1.375640630722046
TA-VAAL iteration: 1600 vae_loss: 1.550457239151001 dsc_loss: 1.3897827863693237
TA-VAAL iteration: 1700 vae_loss: 1.5960931777954102 dsc_loss: 1.371608853340149
TA-VAAL iteration: 1800 vae_loss: 1.566477656364441 dsc_loss: 1.395026445388794
TA-VAAL iteration: 1900 vae_loss: 1.6145408153533936 dsc_loss: 1.3826801776885986
TA-VAAL iteration: 2000 vae_loss: 1.4852994680404663 dsc_loss: 1.3818707466125488
TA-VAAL iteration: 2100 vae_loss: 1.565230131149292 dsc_loss: 1.3996134996414185
TA-VAAL iteration: 2200 vae_loss: 1.5835025310516357 dsc_loss: 1.3853588104248047
TA-VAAL iteration: 2300 vae_loss: 1.7297940254211426 dsc_loss: 1.3937089443206787
TA-VAAL iteration: 2400 vae_loss: 1.7928273677825928 dsc_loss: 1.400568962097168
TA-VAAL iteration: 2500 vae_loss: 1.7263309955596924 dsc_loss: 1.384867787361145
TA-VAAL iteration: 2600 vae_loss: 1.6398513317108154 dsc_loss: 1.3848217725753784
TA-VAAL iteration: 2700 vae_loss: 1.7128428220748901 dsc_loss: 1.3870837688446045
TA-VAAL iteration: 2800 vae_loss: 1.6961607933044434 dsc_loss: 1.369513750076294
TA-VAAL iteration: 2900 vae_loss: 1.696735143661499 dsc_loss: 1.3855555057525635
TA-VAAL iteration: 3000 vae_loss: 1.7629966735839844 dsc_loss: 1.3939487934112549
TA-VAAL iteration: 3100 vae_loss: 1.7395336627960205 dsc_loss: 1.3723796606063843
TA-VAAL iteration: 3200 vae_loss: 1.7642872333526611 dsc_loss: 1.393151879310608
TA-VAAL iteration: 3300 vae_loss: 1.7467983961105347 dsc_loss: 1.4029405117034912
TA-VAAL iteration: 3400 vae_loss: 1.9134584665298462 dsc_loss: 1.3977164030075073
TA-VAAL iteration: 3500 vae_loss: 1.7842438220977783 dsc_loss: 1.3759315013885498
TA-VAAL iteration: 3600 vae_loss: 1.7877717018127441 dsc_loss: 1.3925610780715942
TA-VAAL iteration: 3700 vae_loss: 1.8703138828277588 dsc_loss: 1.3558217287063599
TA-VAAL iteration: 3800 vae_loss: 1.903083086013794 dsc_loss: 1.3932769298553467
TA-VAAL iteration: 3900 vae_loss: 1.8610821962356567 dsc_loss: 1.393087387084961
TA-VAAL iteration: 4000 vae_loss: 1.8361464738845825 dsc_loss: 1.3766038417816162
TA-VAAL iteration: 4100 vae_loss: 1.8976390361785889 dsc_loss: 1.385564923286438
TA-VAAL iteration: 4200 vae_loss: 1.8381410837173462 dsc_loss: 1.4045040607452393
TA-VAAL iteration: 4300 vae_loss: 1.8956687450408936 dsc_loss: 1.3892481327056885
TA-VAAL iteration: 4400 vae_loss: 1.9410109519958496 dsc_loss: 1.3916473388671875
TA-VAAL iteration: 4500 vae_loss: 1.9841159582138062 dsc_loss: 1.38844895362854
TA-VAAL iteration: 4600 vae_loss: 1.9141738414764404 dsc_loss: 1.3610633611679077
TA-VAAL iteration: 4700 vae_loss: 2.007357358932495 dsc_loss: 1.380157709121704
TA-VAAL iteration: 4800 vae_loss: 1.9807053804397583 dsc_loss: 1.3761892318725586
TA-VAAL iteration: 4900 vae_loss: 2.071471691131592 dsc_loss: 1.373561978340149
TA-VAAL iteration: 5000 vae_loss: 1.9515628814697266 dsc_loss: 1.3948674201965332
TA-VAAL iteration: 5100 vae_loss: 1.942427158355713 dsc_loss: 1.3661701679229736
TA-VAAL iteration: 5200 vae_loss: 2.1310293674468994 dsc_loss: 1.3880475759506226
TA-VAAL iteration: 5300 vae_loss: 2.190816640853882 dsc_loss: 1.3931986093521118
TA-VAAL iteration: 5400 vae_loss: 2.0248193740844727 dsc_loss: 1.3923249244689941
TA-VAAL iteration: 5500 vae_loss: 2.023975372314453 dsc_loss: 1.3875166177749634
TA-VAAL iteration: 5600 vae_loss: 2.088019371032715 dsc_loss: 1.3853099346160889
TA-VAAL iteration: 5700 vae_loss: 2.0996618270874023 dsc_loss: 1.3626530170440674
TA-VAAL iteration: 5800 vae_loss: 2.084094524383545 dsc_loss: 1.3851799964904785
TA-VAAL iteration: 5900 vae_loss: 2.126729965209961 dsc_loss: 1.3913532495498657
TA-VAAL iteration: 6000 vae_loss: 2.1578590869903564 dsc_loss: 1.3652970790863037
TA-VAAL iteration: 6100 vae_loss: 2.1253035068511963 dsc_loss: 1.4023157358169556
TA-VAAL iteration: 6200 vae_loss: 2.0039803981781006 dsc_loss: 1.414265513420105
TA-VAAL iteration: 6300 vae_loss: 2.0531201362609863 dsc_loss: 1.3964018821716309
TA-VAAL iteration: 6400 vae_loss: 2.1149892807006836 dsc_loss: 1.3827550411224365
TA-VAAL iteration: 6500 vae_loss: 2.163602113723755 dsc_loss: 1.3909695148468018
TA-VAAL iteration: 6600 vae_loss: 2.1369354724884033 dsc_loss: 1.3488447666168213
TA-VAAL iteration: 6700 vae_loss: 2.1765642166137695 dsc_loss: 1.3986382484436035
TA-VAAL iteration: 6800 vae_loss: 2.190791130065918 dsc_loss: 1.398046612739563
TA-VAAL iteration: 6900 vae_loss: 2.1760129928588867 dsc_loss: 1.3650286197662354
TA-VAAL iteration: 7000 vae_loss: 2.204684257507324 dsc_loss: 1.3882067203521729
TA-VAAL iteration: 7100 vae_loss: 2.23612117767334 dsc_loss: 1.3972692489624023
TA-VAAL iteration: 7200 vae_loss: 2.2683510780334473 dsc_loss: 1.3793678283691406
TA-VAAL iteration: 7300 vae_loss: 2.2560596466064453 dsc_loss: 1.3911914825439453
TA-VAAL iteration: 7400 vae_loss: 2.282508611679077 dsc_loss: 1.3880834579467773
TA-VAAL iteration: 7500 vae_loss: 2.225001096725464 dsc_loss: 1.3547601699829102
TA-VAAL iteration: 7600 vae_loss: 2.243420124053955 dsc_loss: 1.3802556991577148
TA-VAAL iteration: 7700 vae_loss: 2.1937620639801025 dsc_loss: 1.3711636066436768
TA-VAAL iteration: 7800 vae_loss: 2.2220423221588135 dsc_loss: 1.3669638633728027
TA-VAAL iteration: 7900 vae_loss: 2.2416763305664062 dsc_loss: 1.397949457168579
TA-VAAL iteration: 8000 vae_loss: 2.255615711212158 dsc_loss: 1.3698676824569702
TA-VAAL iteration: 8100 vae_loss: 2.297220468521118 dsc_loss: 1.384960651397705
TA-VAAL iteration: 8200 vae_loss: 2.350212574005127 dsc_loss: 1.3942705392837524
2000 105108 150 107067
>> Train vae and task model
epoch 0: train loss is  1.55726
epoch 10: train loss is  1.42078
epoch 20: train loss is  1.36497
epoch 30: train loss is  1.32624
epoch 40: train loss is  1.30170
epoch 50: train loss is  1.29688
epoch 60: train loss is  1.25518
epoch 70: train loss is  1.21921
epoch 80: train loss is  1.23636
epoch 90: train loss is  1.21358
epoch 100: train loss is  1.18574
epoch 110: train loss is  1.17283
epoch 120: train loss is  1.14316
 >> Test Model
Cycle 10/10 || labeled data size 2000, test loss(MAE) =  0.73472
Finished.
>> Train vae and task model
epoch 0: train loss is  1.59393
epoch 10: train loss is  1.52906
epoch 20: train loss is  1.44032
epoch 30: train loss is  1.29919
epoch 40: train loss is  1.13436
epoch 50: train loss is  1.14223
epoch 60: train loss is  1.09941
epoch 70: train loss is  0.98616
epoch 80: train loss is  1.14347
epoch 90: train loss is  1.01902
epoch 100: train loss is  0.90225
epoch 110: train loss is  1.04404
epoch 120: train loss is  0.94382
 >> Test Model
Cycle 1/10 || labeled data size 200, test loss(MAE) =  0.64762
TA-VAAL iteration: 0 vae_loss: 1.7135632038116455 dsc_loss: 1.4105310440063477
TA-VAAL iteration: 10 vae_loss: 1.7328916788101196 dsc_loss: 1.3973137140274048
TA-VAAL iteration: 20 vae_loss: 1.7106525897979736 dsc_loss: 1.3852120637893677
TA-VAAL iteration: 30 vae_loss: 1.7745378017425537 dsc_loss: 1.3839726448059082
TA-VAAL iteration: 40 vae_loss: 1.7651784420013428 dsc_loss: 1.379675030708313
TA-VAAL iteration: 50 vae_loss: 1.7703725099563599 dsc_loss: 1.3699394464492798
TA-VAAL iteration: 60 vae_loss: 1.6098806858062744 dsc_loss: 1.3752214908599854
TA-VAAL iteration: 70 vae_loss: 1.6267836093902588 dsc_loss: 1.3862802982330322
TA-VAAL iteration: 80 vae_loss: 1.6050300598144531 dsc_loss: 1.3877387046813965
TA-VAAL iteration: 90 vae_loss: 1.5762507915496826 dsc_loss: 1.4129183292388916
TA-VAAL iteration: 100 vae_loss: 1.602787733078003 dsc_loss: 1.3779048919677734
TA-VAAL iteration: 200 vae_loss: 1.5911048650741577 dsc_loss: 1.3773045539855957
TA-VAAL iteration: 300 vae_loss: 1.6201125383377075 dsc_loss: 1.3815758228302002
TA-VAAL iteration: 400 vae_loss: 1.730480432510376 dsc_loss: 1.384012222290039
TA-VAAL iteration: 500 vae_loss: 1.8372063636779785 dsc_loss: 1.3775994777679443
TA-VAAL iteration: 600 vae_loss: 1.7413475513458252 dsc_loss: 1.3845226764678955
TA-VAAL iteration: 700 vae_loss: 1.6199305057525635 dsc_loss: 1.393984317779541
TA-VAAL iteration: 800 vae_loss: 1.695906639099121 dsc_loss: 1.3985971212387085
TA-VAAL iteration: 900 vae_loss: 2.0247936248779297 dsc_loss: 1.3978915214538574
TA-VAAL iteration: 1000 vae_loss: 2.074449300765991 dsc_loss: 1.38466215133667
TA-VAAL iteration: 1100 vae_loss: 1.81790030002594 dsc_loss: 1.3900091648101807
TA-VAAL iteration: 1200 vae_loss: 1.8769522905349731 dsc_loss: 1.3855712413787842
TA-VAAL iteration: 1300 vae_loss: 2.1385748386383057 dsc_loss: 1.3789799213409424
TA-VAAL iteration: 1400 vae_loss: 2.174978256225586 dsc_loss: 1.352405309677124
TA-VAAL iteration: 1500 vae_loss: 2.1363537311553955 dsc_loss: 1.3390896320343018
TA-VAAL iteration: 1600 vae_loss: 1.9040511846542358 dsc_loss: 1.37970769405365
TA-VAAL iteration: 1700 vae_loss: 2.3064587116241455 dsc_loss: 1.359958529472351
TA-VAAL iteration: 1800 vae_loss: 1.8613996505737305 dsc_loss: 1.3671448230743408
TA-VAAL iteration: 1900 vae_loss: 2.125619649887085 dsc_loss: 1.370293140411377
TA-VAAL iteration: 2000 vae_loss: 2.4446635246276855 dsc_loss: 1.32651948928833
TA-VAAL iteration: 2100 vae_loss: 2.2208125591278076 dsc_loss: 1.3249006271362305
TA-VAAL iteration: 2200 vae_loss: 2.60996150970459 dsc_loss: 1.368975043296814
TA-VAAL iteration: 2300 vae_loss: 2.337110996246338 dsc_loss: 1.3465642929077148
TA-VAAL iteration: 2400 vae_loss: 2.9810357093811035 dsc_loss: 1.3595495223999023
TA-VAAL iteration: 2500 vae_loss: 2.599869728088379 dsc_loss: 1.3308427333831787
TA-VAAL iteration: 2600 vae_loss: 2.425166368484497 dsc_loss: 1.3076891899108887
TA-VAAL iteration: 2700 vae_loss: 3.5771751403808594 dsc_loss: 1.378257393836975
TA-VAAL iteration: 2800 vae_loss: 2.0111188888549805 dsc_loss: 1.3860920667648315
TA-VAAL iteration: 2900 vae_loss: 2.6186418533325195 dsc_loss: 1.2982854843139648
TA-VAAL iteration: 3000 vae_loss: 2.5004725456237793 dsc_loss: 1.2973628044128418
TA-VAAL iteration: 3100 vae_loss: 2.220219373703003 dsc_loss: 1.3696653842926025
TA-VAAL iteration: 3200 vae_loss: 2.7363624572753906 dsc_loss: 1.315969467163086
TA-VAAL iteration: 3300 vae_loss: 2.4882946014404297 dsc_loss: 1.3597955703735352
TA-VAAL iteration: 3400 vae_loss: 3.401655673980713 dsc_loss: 1.3669040203094482
TA-VAAL iteration: 3500 vae_loss: 2.625908851623535 dsc_loss: 1.3113826513290405
TA-VAAL iteration: 3600 vae_loss: 3.4712817668914795 dsc_loss: 1.4252939224243164
TA-VAAL iteration: 3700 vae_loss: 2.6066458225250244 dsc_loss: 1.307227611541748
TA-VAAL iteration: 3800 vae_loss: 2.615471601486206 dsc_loss: 1.3588628768920898
TA-VAAL iteration: 3900 vae_loss: 3.300814390182495 dsc_loss: 1.3985226154327393
TA-VAAL iteration: 4000 vae_loss: 2.8557610511779785 dsc_loss: 1.2952022552490234
TA-VAAL iteration: 4100 vae_loss: 2.978456497192383 dsc_loss: 1.4442756175994873
TA-VAAL iteration: 4200 vae_loss: 3.128131866455078 dsc_loss: 1.3583619594573975
TA-VAAL iteration: 4300 vae_loss: 3.381802797317505 dsc_loss: 1.3712489604949951
TA-VAAL iteration: 4400 vae_loss: 3.6196017265319824 dsc_loss: 1.393923282623291
TA-VAAL iteration: 4500 vae_loss: 2.940241813659668 dsc_loss: 1.345503330230713
TA-VAAL iteration: 4600 vae_loss: 3.2381484508514404 dsc_loss: 1.3563861846923828
TA-VAAL iteration: 4700 vae_loss: 3.1326029300689697 dsc_loss: 1.3160473108291626
TA-VAAL iteration: 4800 vae_loss: 3.412665843963623 dsc_loss: 1.3182742595672607
TA-VAAL iteration: 4900 vae_loss: 3.1222479343414307 dsc_loss: 1.3094456195831299
TA-VAAL iteration: 5000 vae_loss: 3.403083324432373 dsc_loss: 1.349544882774353
TA-VAAL iteration: 5100 vae_loss: 3.1187453269958496 dsc_loss: 1.3666462898254395
TA-VAAL iteration: 5200 vae_loss: 2.774925708770752 dsc_loss: 1.3749823570251465
TA-VAAL iteration: 5300 vae_loss: 3.113473653793335 dsc_loss: 1.3417688608169556
TA-VAAL iteration: 5400 vae_loss: 3.1666181087493896 dsc_loss: 1.3628686666488647
TA-VAAL iteration: 5500 vae_loss: 3.9075918197631836 dsc_loss: 1.3795506954193115
TA-VAAL iteration: 5600 vae_loss: 2.4603216648101807 dsc_loss: 1.3662385940551758
TA-VAAL iteration: 5700 vae_loss: 3.2725718021392822 dsc_loss: 1.3759191036224365
TA-VAAL iteration: 5800 vae_loss: 3.2543835639953613 dsc_loss: 1.3690249919891357
TA-VAAL iteration: 5900 vae_loss: 3.304980754852295 dsc_loss: 1.4189209938049316
TA-VAAL iteration: 6000 vae_loss: 2.9950318336486816 dsc_loss: 1.3493196964263916
TA-VAAL iteration: 6100 vae_loss: 3.023876667022705 dsc_loss: 1.3639365434646606
TA-VAAL iteration: 6200 vae_loss: 3.0660054683685303 dsc_loss: 1.4741194248199463
400 106708 21 106717
>> Train vae and task model
epoch 0: train loss is  1.58976
epoch 10: train loss is  1.50775
epoch 20: train loss is  1.38621
epoch 30: train loss is  1.35775
epoch 40: train loss is  1.29629
epoch 50: train loss is  1.14392
epoch 60: train loss is  1.07404
epoch 70: train loss is  1.01659
epoch 80: train loss is  1.08179
epoch 90: train loss is  1.04362
epoch 100: train loss is  1.00075
epoch 110: train loss is  0.96245
epoch 120: train loss is  0.96029
 >> Test Model
Cycle 2/10 || labeled data size 400, test loss(MAE) =  0.82738
TA-VAAL iteration: 0 vae_loss: 1.828258991241455 dsc_loss: 1.3912131786346436
TA-VAAL iteration: 10 vae_loss: 1.85959792137146 dsc_loss: 1.4242706298828125
TA-VAAL iteration: 20 vae_loss: 1.7364788055419922 dsc_loss: 1.3893733024597168
TA-VAAL iteration: 30 vae_loss: 1.6867661476135254 dsc_loss: 1.3725039958953857
TA-VAAL iteration: 40 vae_loss: 1.7001497745513916 dsc_loss: 1.3858277797698975
TA-VAAL iteration: 50 vae_loss: 1.8036413192749023 dsc_loss: 1.3808397054672241
TA-VAAL iteration: 60 vae_loss: 1.8045783042907715 dsc_loss: 1.345602035522461
TA-VAAL iteration: 70 vae_loss: 1.8008744716644287 dsc_loss: 1.3915009498596191
TA-VAAL iteration: 80 vae_loss: 1.5819624662399292 dsc_loss: 1.3724509477615356
TA-VAAL iteration: 90 vae_loss: 1.5502924919128418 dsc_loss: 1.365490436553955
TA-VAAL iteration: 100 vae_loss: 1.4891966581344604 dsc_loss: 1.4038218259811401
TA-VAAL iteration: 200 vae_loss: 1.5145008563995361 dsc_loss: 1.362372636795044
TA-VAAL iteration: 300 vae_loss: 1.7267979383468628 dsc_loss: 1.3743131160736084
TA-VAAL iteration: 400 vae_loss: 1.6295835971832275 dsc_loss: 1.3454900979995728
TA-VAAL iteration: 500 vae_loss: 1.816143274307251 dsc_loss: 1.3510451316833496
TA-VAAL iteration: 600 vae_loss: 1.5528630018234253 dsc_loss: 1.2918293476104736
TA-VAAL iteration: 700 vae_loss: 2.0704424381256104 dsc_loss: 1.2998971939086914
TA-VAAL iteration: 800 vae_loss: 1.7796334028244019 dsc_loss: 1.339331865310669
TA-VAAL iteration: 900 vae_loss: 2.0007057189941406 dsc_loss: 1.2782437801361084
TA-VAAL iteration: 1000 vae_loss: 2.3993802070617676 dsc_loss: 1.0469623804092407
TA-VAAL iteration: 1100 vae_loss: 2.3781352043151855 dsc_loss: 1.3187766075134277
TA-VAAL iteration: 1200 vae_loss: 3.0620083808898926 dsc_loss: 1.3674710988998413
TA-VAAL iteration: 1300 vae_loss: 2.741715908050537 dsc_loss: 1.3398032188415527
TA-VAAL iteration: 1400 vae_loss: 2.564742088317871 dsc_loss: 1.1877952814102173
TA-VAAL iteration: 1500 vae_loss: 1.6827232837677002 dsc_loss: 1.6039624214172363
TA-VAAL iteration: 1600 vae_loss: 1.7771941423416138 dsc_loss: 1.3039188385009766
TA-VAAL iteration: 1700 vae_loss: 2.630463123321533 dsc_loss: 1.2849528789520264
TA-VAAL iteration: 1800 vae_loss: 2.694859504699707 dsc_loss: 1.3447387218475342
TA-VAAL iteration: 1900 vae_loss: 2.355267286300659 dsc_loss: 1.1326565742492676
TA-VAAL iteration: 2000 vae_loss: 2.1963977813720703 dsc_loss: 1.3210505247116089
TA-VAAL iteration: 2100 vae_loss: 2.6695446968078613 dsc_loss: 1.3271479606628418
TA-VAAL iteration: 2200 vae_loss: 2.036252021789551 dsc_loss: 1.278593897819519
TA-VAAL iteration: 2300 vae_loss: 2.527139663696289 dsc_loss: 1.2716248035430908
TA-VAAL iteration: 2400 vae_loss: 1.8417003154754639 dsc_loss: 1.3740426301956177
TA-VAAL iteration: 2500 vae_loss: 1.9719491004943848 dsc_loss: 1.3275761604309082
TA-VAAL iteration: 2600 vae_loss: 2.387442111968994 dsc_loss: 1.2886524200439453
TA-VAAL iteration: 2700 vae_loss: 2.032623767852783 dsc_loss: 1.2878973484039307
TA-VAAL iteration: 2800 vae_loss: 2.7153687477111816 dsc_loss: 1.2361202239990234
TA-VAAL iteration: 2900 vae_loss: 1.9387118816375732 dsc_loss: 1.2185896635055542
TA-VAAL iteration: 3000 vae_loss: 2.55147123336792 dsc_loss: 1.3207944631576538
TA-VAAL iteration: 3100 vae_loss: 2.2341318130493164 dsc_loss: 1.3189499378204346
TA-VAAL iteration: 3200 vae_loss: 2.0625388622283936 dsc_loss: 1.292182207107544
TA-VAAL iteration: 3300 vae_loss: 2.1521034240722656 dsc_loss: 1.2794561386108398
TA-VAAL iteration: 3400 vae_loss: 2.5507125854492188 dsc_loss: 1.2452216148376465
TA-VAAL iteration: 3500 vae_loss: 2.6534130573272705 dsc_loss: 1.2822418212890625
TA-VAAL iteration: 3600 vae_loss: 2.3573923110961914 dsc_loss: 1.1578638553619385
TA-VAAL iteration: 3700 vae_loss: 2.3239622116088867 dsc_loss: 1.3561537265777588
TA-VAAL iteration: 3800 vae_loss: 2.3990392684936523 dsc_loss: 1.257416009902954
TA-VAAL iteration: 3900 vae_loss: 2.1171154975891113 dsc_loss: 1.2759790420532227
TA-VAAL iteration: 4000 vae_loss: 2.816835880279541 dsc_loss: 1.3300254344940186
TA-VAAL iteration: 4100 vae_loss: 2.2952463626861572 dsc_loss: 1.3282378911972046
TA-VAAL iteration: 4200 vae_loss: 1.9777476787567139 dsc_loss: 1.279837965965271
TA-VAAL iteration: 4300 vae_loss: 2.0384931564331055 dsc_loss: 1.2835510969161987
TA-VAAL iteration: 4400 vae_loss: 2.4494919776916504 dsc_loss: 1.3158036470413208
TA-VAAL iteration: 4500 vae_loss: 2.7034313678741455 dsc_loss: 1.1668992042541504
TA-VAAL iteration: 4600 vae_loss: 2.647780656814575 dsc_loss: 1.2146596908569336
TA-VAAL iteration: 4700 vae_loss: 2.2562804222106934 dsc_loss: 1.3276665210723877
TA-VAAL iteration: 4800 vae_loss: 2.046705722808838 dsc_loss: 1.183762788772583
TA-VAAL iteration: 4900 vae_loss: 2.378416061401367 dsc_loss: 1.2469013929367065
TA-VAAL iteration: 5000 vae_loss: 2.340181350708008 dsc_loss: 1.2743737697601318
TA-VAAL iteration: 5100 vae_loss: 2.2186713218688965 dsc_loss: 1.1628730297088623
TA-VAAL iteration: 5200 vae_loss: 2.9248790740966797 dsc_loss: 1.1714411973953247
TA-VAAL iteration: 5300 vae_loss: 2.0142714977264404 dsc_loss: 1.3165578842163086
TA-VAAL iteration: 5400 vae_loss: 2.173161506652832 dsc_loss: 1.1726998090744019
TA-VAAL iteration: 5500 vae_loss: 2.1039371490478516 dsc_loss: 1.3724734783172607
TA-VAAL iteration: 5600 vae_loss: 2.0821433067321777 dsc_loss: 1.3160839080810547
TA-VAAL iteration: 5700 vae_loss: 2.882211685180664 dsc_loss: 1.4582386016845703
TA-VAAL iteration: 5800 vae_loss: 2.3359971046447754 dsc_loss: 1.2727868556976318
TA-VAAL iteration: 5900 vae_loss: 2.4941446781158447 dsc_loss: 1.1685799360275269
TA-VAAL iteration: 6000 vae_loss: 2.591843605041504 dsc_loss: 1.237838625907898
TA-VAAL iteration: 6100 vae_loss: 2.0279347896575928 dsc_loss: 1.4085848331451416
TA-VAAL iteration: 6200 vae_loss: 2.2567520141601562 dsc_loss: 1.2582463026046753
TA-VAAL iteration: 6300 vae_loss: 2.7475554943084717 dsc_loss: 1.2421998977661133
TA-VAAL iteration: 6400 vae_loss: 2.882688045501709 dsc_loss: 1.4786304235458374
600 106508 21 106968
>> Train vae and task model
epoch 0: train loss is  1.55582
epoch 10: train loss is  1.44979
epoch 20: train loss is  1.34363
epoch 30: train loss is  1.28691
epoch 40: train loss is  1.17693
epoch 50: train loss is  1.15781
epoch 60: train loss is  1.13166
epoch 70: train loss is  1.07993
epoch 80: train loss is  1.08589
epoch 90: train loss is  1.02232
epoch 100: train loss is  1.02987
epoch 110: train loss is  1.01840
epoch 120: train loss is  0.99215
 >> Test Model
Cycle 3/10 || labeled data size 600, test loss(MAE) =  0.82738
TA-VAAL iteration: 0 vae_loss: 1.8560895919799805 dsc_loss: 1.3909655809402466
TA-VAAL iteration: 10 vae_loss: 1.5625263452529907 dsc_loss: 1.3919346332550049
TA-VAAL iteration: 20 vae_loss: 1.3813080787658691 dsc_loss: 1.4562294483184814
TA-VAAL iteration: 30 vae_loss: 1.915281057357788 dsc_loss: 1.376427173614502
TA-VAAL iteration: 40 vae_loss: 1.84711754322052 dsc_loss: 1.3897405862808228
TA-VAAL iteration: 50 vae_loss: 2.0098683834075928 dsc_loss: 1.4059430360794067
TA-VAAL iteration: 60 vae_loss: 1.8450411558151245 dsc_loss: 1.3970746994018555
TA-VAAL iteration: 70 vae_loss: 1.7841119766235352 dsc_loss: 1.3816189765930176
TA-VAAL iteration: 80 vae_loss: 1.6929535865783691 dsc_loss: 1.3857084512710571
TA-VAAL iteration: 90 vae_loss: 1.7506492137908936 dsc_loss: 1.3808929920196533
TA-VAAL iteration: 100 vae_loss: 1.765760898590088 dsc_loss: 1.3829337358474731
TA-VAAL iteration: 200 vae_loss: 1.6774860620498657 dsc_loss: 1.3789198398590088
TA-VAAL iteration: 300 vae_loss: 1.6378592252731323 dsc_loss: 1.3807306289672852
TA-VAAL iteration: 400 vae_loss: 1.6130731105804443 dsc_loss: 1.3981800079345703
TA-VAAL iteration: 500 vae_loss: 1.8791910409927368 dsc_loss: 1.355332374572754
TA-VAAL iteration: 600 vae_loss: 1.6286184787750244 dsc_loss: 1.4081623554229736
TA-VAAL iteration: 700 vae_loss: 1.7227097749710083 dsc_loss: 1.3292781114578247
TA-VAAL iteration: 800 vae_loss: 1.7613435983657837 dsc_loss: 1.3552088737487793
TA-VAAL iteration: 900 vae_loss: 1.7958797216415405 dsc_loss: 1.345747470855713
TA-VAAL iteration: 1000 vae_loss: 1.7720996141433716 dsc_loss: 1.3517704010009766
TA-VAAL iteration: 1100 vae_loss: 1.794816493988037 dsc_loss: 1.3593872785568237
TA-VAAL iteration: 1200 vae_loss: 1.9147162437438965 dsc_loss: 1.3514968156814575
TA-VAAL iteration: 1300 vae_loss: 1.6307997703552246 dsc_loss: 1.4228712320327759
TA-VAAL iteration: 1400 vae_loss: 1.8102649450302124 dsc_loss: 1.4097248315811157
TA-VAAL iteration: 1500 vae_loss: 1.6195666790008545 dsc_loss: 1.4397499561309814
TA-VAAL iteration: 1600 vae_loss: 1.638118028640747 dsc_loss: 1.3713865280151367
TA-VAAL iteration: 1700 vae_loss: 1.8387713432312012 dsc_loss: 1.3735761642456055
TA-VAAL iteration: 1800 vae_loss: 1.7900853157043457 dsc_loss: 1.3588197231292725
TA-VAAL iteration: 1900 vae_loss: 1.6882954835891724 dsc_loss: 1.3286724090576172
TA-VAAL iteration: 2000 vae_loss: 1.7100985050201416 dsc_loss: 1.342113733291626
TA-VAAL iteration: 2100 vae_loss: 1.686768889427185 dsc_loss: 1.3714649677276611
TA-VAAL iteration: 2200 vae_loss: 1.7163875102996826 dsc_loss: 1.3760104179382324
TA-VAAL iteration: 2300 vae_loss: 1.610453724861145 dsc_loss: 1.3763337135314941
TA-VAAL iteration: 2400 vae_loss: 1.7995376586914062 dsc_loss: 1.4116133451461792
TA-VAAL iteration: 2500 vae_loss: 1.5641088485717773 dsc_loss: 1.3636608123779297
TA-VAAL iteration: 2600 vae_loss: 1.6995114088058472 dsc_loss: 1.3766894340515137
TA-VAAL iteration: 2700 vae_loss: 1.7766032218933105 dsc_loss: 1.4045586585998535
TA-VAAL iteration: 2800 vae_loss: 1.711172342300415 dsc_loss: 1.3755072355270386
TA-VAAL iteration: 2900 vae_loss: 1.7464702129364014 dsc_loss: 1.383345127105713
TA-VAAL iteration: 3000 vae_loss: 1.7961249351501465 dsc_loss: 1.371321201324463
TA-VAAL iteration: 3100 vae_loss: 1.8922579288482666 dsc_loss: 1.3608338832855225
TA-VAAL iteration: 3200 vae_loss: 2.052701473236084 dsc_loss: 1.387836217880249
TA-VAAL iteration: 3300 vae_loss: 1.9477397203445435 dsc_loss: 1.362011194229126
TA-VAAL iteration: 3400 vae_loss: 2.2976865768432617 dsc_loss: 1.3482977151870728
TA-VAAL iteration: 3500 vae_loss: 2.0228872299194336 dsc_loss: 1.3813376426696777
TA-VAAL iteration: 3600 vae_loss: 2.0597879886627197 dsc_loss: 1.324599266052246
TA-VAAL iteration: 3700 vae_loss: 2.0720033645629883 dsc_loss: 1.3717223405838013
TA-VAAL iteration: 3800 vae_loss: 2.0489706993103027 dsc_loss: 1.3813145160675049
TA-VAAL iteration: 3900 vae_loss: 2.1239547729492188 dsc_loss: 1.3533371686935425
TA-VAAL iteration: 4000 vae_loss: 2.1102657318115234 dsc_loss: 1.3389393091201782
TA-VAAL iteration: 4100 vae_loss: 1.9686262607574463 dsc_loss: 1.3740049600601196
TA-VAAL iteration: 4200 vae_loss: 2.0191471576690674 dsc_loss: 1.3771607875823975
TA-VAAL iteration: 4300 vae_loss: 1.8754297494888306 dsc_loss: 1.4023566246032715
TA-VAAL iteration: 4400 vae_loss: 1.985657811164856 dsc_loss: 1.394439935684204
TA-VAAL iteration: 4500 vae_loss: 1.9420545101165771 dsc_loss: 1.3489530086517334
TA-VAAL iteration: 4600 vae_loss: 1.9121133089065552 dsc_loss: 1.3627004623413086
TA-VAAL iteration: 4700 vae_loss: 1.9714795351028442 dsc_loss: 1.3309507369995117
TA-VAAL iteration: 4800 vae_loss: 1.9746264219284058 dsc_loss: 1.3811745643615723
TA-VAAL iteration: 4900 vae_loss: 2.041163682937622 dsc_loss: 1.3089706897735596
TA-VAAL iteration: 5000 vae_loss: 1.7915732860565186 dsc_loss: 1.341231107711792
TA-VAAL iteration: 5100 vae_loss: 1.8299622535705566 dsc_loss: 1.3371517658233643
TA-VAAL iteration: 5200 vae_loss: 1.8056856393814087 dsc_loss: 1.3046092987060547
TA-VAAL iteration: 5300 vae_loss: 2.0791983604431152 dsc_loss: 1.4481537342071533
TA-VAAL iteration: 5400 vae_loss: 1.59416663646698 dsc_loss: 1.3855701684951782
TA-VAAL iteration: 5500 vae_loss: 1.6658717393875122 dsc_loss: 1.3595726490020752
TA-VAAL iteration: 5600 vae_loss: 2.1030285358428955 dsc_loss: 1.315699815750122
TA-VAAL iteration: 5700 vae_loss: 2.285909414291382 dsc_loss: 1.2479605674743652
TA-VAAL iteration: 5800 vae_loss: 1.898017406463623 dsc_loss: 1.2453207969665527
TA-VAAL iteration: 5900 vae_loss: 1.9852135181427002 dsc_loss: 1.2746140956878662
TA-VAAL iteration: 6000 vae_loss: 1.84810209274292 dsc_loss: 1.3570411205291748
TA-VAAL iteration: 6100 vae_loss: 1.9222092628479004 dsc_loss: 1.313073754310608
TA-VAAL iteration: 6200 vae_loss: 1.9562498331069946 dsc_loss: 1.234537959098816
TA-VAAL iteration: 6300 vae_loss: 2.1742444038391113 dsc_loss: 1.2052748203277588
TA-VAAL iteration: 6400 vae_loss: 3.0351736545562744 dsc_loss: 1.3874189853668213
TA-VAAL iteration: 6500 vae_loss: 1.7805731296539307 dsc_loss: 1.2590869665145874
TA-VAAL iteration: 6600 vae_loss: 2.1464052200317383 dsc_loss: 1.166835069656372
TA-VAAL iteration: 6700 vae_loss: 1.6020476818084717 dsc_loss: 1.3015151023864746
800 106308 21 106968
>> Train vae and task model
epoch 0: train loss is  1.57969
epoch 10: train loss is  1.48378
epoch 20: train loss is  1.32983
epoch 30: train loss is  1.27312
epoch 40: train loss is  1.21429
epoch 50: train loss is  1.14516
epoch 60: train loss is  1.11752
epoch 70: train loss is  1.13479
epoch 80: train loss is  1.17681
epoch 90: train loss is  1.02852
epoch 100: train loss is  1.12156
epoch 110: train loss is  1.04649
epoch 120: train loss is  1.03642
 >> Test Model
Cycle 4/10 || labeled data size 800, test loss(MAE) =  0.82738
TA-VAAL iteration: 0 vae_loss: 1.8618921041488647 dsc_loss: 1.3890597820281982
TA-VAAL iteration: 10 vae_loss: 1.6297200918197632 dsc_loss: 1.399038553237915
TA-VAAL iteration: 20 vae_loss: 1.8255741596221924 dsc_loss: 1.3709678649902344
TA-VAAL iteration: 30 vae_loss: 1.7118114233016968 dsc_loss: 1.4011423587799072
TA-VAAL iteration: 40 vae_loss: 1.7039132118225098 dsc_loss: 1.3756307363510132
TA-VAAL iteration: 50 vae_loss: 1.7306833267211914 dsc_loss: 1.3783820867538452
TA-VAAL iteration: 60 vae_loss: 1.743842601776123 dsc_loss: 1.38783597946167
TA-VAAL iteration: 70 vae_loss: 1.9946234226226807 dsc_loss: 1.3674547672271729
TA-VAAL iteration: 80 vae_loss: 1.6665118932724 dsc_loss: 1.4624154567718506
TA-VAAL iteration: 90 vae_loss: 1.5500967502593994 dsc_loss: 1.3703885078430176
TA-VAAL iteration: 100 vae_loss: 1.7990096807479858 dsc_loss: 1.3919165134429932
TA-VAAL iteration: 200 vae_loss: 1.6326686143875122 dsc_loss: 1.4130895137786865
TA-VAAL iteration: 300 vae_loss: 1.6584585905075073 dsc_loss: 1.382606029510498
TA-VAAL iteration: 400 vae_loss: 1.9790782928466797 dsc_loss: 1.4080226421356201
TA-VAAL iteration: 500 vae_loss: 1.6740953922271729 dsc_loss: 1.3744099140167236
TA-VAAL iteration: 600 vae_loss: 1.7782022953033447 dsc_loss: 1.3626339435577393
TA-VAAL iteration: 700 vae_loss: 1.9247944355010986 dsc_loss: 1.3808493614196777
TA-VAAL iteration: 800 vae_loss: 1.693652868270874 dsc_loss: 1.3757706880569458
TA-VAAL iteration: 900 vae_loss: 1.9373289346694946 dsc_loss: 1.371353030204773
TA-VAAL iteration: 1000 vae_loss: 1.9567368030548096 dsc_loss: 1.369032859802246
TA-VAAL iteration: 1100 vae_loss: 2.0779876708984375 dsc_loss: 1.3676996231079102
TA-VAAL iteration: 1200 vae_loss: 1.9982917308807373 dsc_loss: 1.3432823419570923
TA-VAAL iteration: 1300 vae_loss: 2.0778706073760986 dsc_loss: 1.3799456357955933
TA-VAAL iteration: 1400 vae_loss: 2.175442934036255 dsc_loss: 1.3538203239440918
TA-VAAL iteration: 1500 vae_loss: 2.3665759563446045 dsc_loss: 1.3484779596328735
TA-VAAL iteration: 1600 vae_loss: 2.1774938106536865 dsc_loss: 1.3805110454559326
TA-VAAL iteration: 1700 vae_loss: 2.2919936180114746 dsc_loss: 1.406443476676941
TA-VAAL iteration: 1800 vae_loss: 2.4350552558898926 dsc_loss: 1.350590705871582
TA-VAAL iteration: 1900 vae_loss: 2.5905601978302 dsc_loss: 1.3916263580322266
TA-VAAL iteration: 2000 vae_loss: 2.859522819519043 dsc_loss: 1.38399076461792
TA-VAAL iteration: 2100 vae_loss: 2.4866316318511963 dsc_loss: 1.385624885559082
TA-VAAL iteration: 2200 vae_loss: 2.674642562866211 dsc_loss: 1.4010536670684814
TA-VAAL iteration: 2300 vae_loss: 2.5640296936035156 dsc_loss: 1.369497299194336
TA-VAAL iteration: 2400 vae_loss: 2.7215375900268555 dsc_loss: 1.3705618381500244
TA-VAAL iteration: 2500 vae_loss: 2.7586846351623535 dsc_loss: 1.357421875
TA-VAAL iteration: 2600 vae_loss: 2.7193360328674316 dsc_loss: 1.3618134260177612
TA-VAAL iteration: 2700 vae_loss: 2.6401565074920654 dsc_loss: 1.365486979484558
TA-VAAL iteration: 2800 vae_loss: 3.0698204040527344 dsc_loss: 1.3434317111968994
TA-VAAL iteration: 2900 vae_loss: 2.8892693519592285 dsc_loss: 1.3820624351501465
TA-VAAL iteration: 3000 vae_loss: 3.144239664077759 dsc_loss: 1.4004687070846558
TA-VAAL iteration: 3100 vae_loss: 3.0366878509521484 dsc_loss: 1.3400158882141113
TA-VAAL iteration: 3200 vae_loss: 3.0497100353240967 dsc_loss: 1.3830409049987793
TA-VAAL iteration: 3300 vae_loss: 3.037647008895874 dsc_loss: 1.4151456356048584
TA-VAAL iteration: 3400 vae_loss: 3.1904501914978027 dsc_loss: 1.3912407159805298
TA-VAAL iteration: 3500 vae_loss: 3.137471914291382 dsc_loss: 1.3669296503067017
TA-VAAL iteration: 3600 vae_loss: 3.047111749649048 dsc_loss: 1.38773512840271
TA-VAAL iteration: 3700 vae_loss: 3.096047878265381 dsc_loss: 1.4012959003448486
TA-VAAL iteration: 3800 vae_loss: 3.4845128059387207 dsc_loss: 1.36191987991333
TA-VAAL iteration: 3900 vae_loss: 3.5994369983673096 dsc_loss: 1.3941867351531982
TA-VAAL iteration: 4000 vae_loss: 3.087153434753418 dsc_loss: 1.3432739973068237
TA-VAAL iteration: 4100 vae_loss: 3.3120479583740234 dsc_loss: 1.328526258468628
TA-VAAL iteration: 4200 vae_loss: 3.1106395721435547 dsc_loss: 1.3167802095413208
TA-VAAL iteration: 4300 vae_loss: 3.4385199546813965 dsc_loss: 1.3638319969177246
TA-VAAL iteration: 4400 vae_loss: 3.49617338180542 dsc_loss: 1.3371869325637817
TA-VAAL iteration: 4500 vae_loss: 3.444845676422119 dsc_loss: 1.3696203231811523
TA-VAAL iteration: 4600 vae_loss: 3.3965985774993896 dsc_loss: 1.3301544189453125
TA-VAAL iteration: 4700 vae_loss: 3.5178616046905518 dsc_loss: 1.3521363735198975
TA-VAAL iteration: 4800 vae_loss: 3.3033199310302734 dsc_loss: 1.2945575714111328
TA-VAAL iteration: 4900 vae_loss: 3.6733438968658447 dsc_loss: 1.29103422164917
TA-VAAL iteration: 5000 vae_loss: 3.6214137077331543 dsc_loss: 1.4316110610961914
TA-VAAL iteration: 5100 vae_loss: 3.286931276321411 dsc_loss: 1.3344361782073975
TA-VAAL iteration: 5200 vae_loss: 3.690722942352295 dsc_loss: 1.3338236808776855
TA-VAAL iteration: 5300 vae_loss: 3.393385410308838 dsc_loss: 1.3194743394851685
TA-VAAL iteration: 5400 vae_loss: 3.683187961578369 dsc_loss: 1.2933485507965088
TA-VAAL iteration: 5500 vae_loss: 3.07132887840271 dsc_loss: 1.3423078060150146
TA-VAAL iteration: 5600 vae_loss: 3.3128128051757812 dsc_loss: 1.3942396640777588
TA-VAAL iteration: 5700 vae_loss: 3.344592332839966 dsc_loss: 1.3174912929534912
TA-VAAL iteration: 5800 vae_loss: 3.3839614391326904 dsc_loss: 1.493711233139038
TA-VAAL iteration: 5900 vae_loss: 3.947751522064209 dsc_loss: 1.3192799091339111
TA-VAAL iteration: 6000 vae_loss: 3.527683734893799 dsc_loss: 1.350584626197815
TA-VAAL iteration: 6100 vae_loss: 3.5575597286224365 dsc_loss: 1.3076285123825073
TA-VAAL iteration: 6200 vae_loss: 3.197138786315918 dsc_loss: 1.248171091079712
TA-VAAL iteration: 6300 vae_loss: 3.472942352294922 dsc_loss: 1.2923767566680908
TA-VAAL iteration: 6400 vae_loss: 3.2531304359436035 dsc_loss: 1.323836088180542
TA-VAAL iteration: 6500 vae_loss: 3.8459184169769287 dsc_loss: 1.3659929037094116
TA-VAAL iteration: 6600 vae_loss: 3.165191411972046 dsc_loss: 1.3244322538375854
TA-VAAL iteration: 6700 vae_loss: 3.4579410552978516 dsc_loss: 1.2635951042175293
TA-VAAL iteration: 6800 vae_loss: 3.495242118835449 dsc_loss: 1.333319902420044
TA-VAAL iteration: 6900 vae_loss: 3.340847969055176 dsc_loss: 1.3416130542755127
1000 106108 21 106968
>> Train vae and task model
epoch 0: train loss is  1.54964
epoch 10: train loss is  1.38158
epoch 20: train loss is  1.14503
epoch 30: train loss is  1.07167
epoch 40: train loss is  1.04431
epoch 50: train loss is  1.01751
epoch 60: train loss is  1.02307
epoch 70: train loss is  1.04562
epoch 80: train loss is  0.98589
epoch 90: train loss is  0.97200
epoch 100: train loss is  0.91098
epoch 110: train loss is  0.94933
epoch 120: train loss is  0.93268
 >> Test Model
Cycle 5/10 || labeled data size 1000, test loss(MAE) =  0.55693
TA-VAAL iteration: 0 vae_loss: 1.7726874351501465 dsc_loss: 1.3931525945663452
TA-VAAL iteration: 10 vae_loss: 1.4947242736816406 dsc_loss: 1.4364899396896362
TA-VAAL iteration: 20 vae_loss: 1.5101453065872192 dsc_loss: 1.4167571067810059
TA-VAAL iteration: 30 vae_loss: 1.6507678031921387 dsc_loss: 1.393038272857666
TA-VAAL iteration: 40 vae_loss: 1.888176679611206 dsc_loss: 1.435927391052246
TA-VAAL iteration: 50 vae_loss: 1.810869812965393 dsc_loss: 1.3648991584777832
TA-VAAL iteration: 60 vae_loss: 2.015129327774048 dsc_loss: 1.4343101978302002
TA-VAAL iteration: 70 vae_loss: 1.9135174751281738 dsc_loss: 1.4159696102142334
TA-VAAL iteration: 80 vae_loss: 1.8567819595336914 dsc_loss: 1.4190179109573364
TA-VAAL iteration: 90 vae_loss: 1.871872901916504 dsc_loss: 1.4154900312423706
TA-VAAL iteration: 100 vae_loss: 1.8654015064239502 dsc_loss: 1.4009910821914673
TA-VAAL iteration: 200 vae_loss: 1.8667199611663818 dsc_loss: 1.4475191831588745
TA-VAAL iteration: 300 vae_loss: 1.722642183303833 dsc_loss: 1.3686597347259521
TA-VAAL iteration: 400 vae_loss: 1.8740975856781006 dsc_loss: 1.3902721405029297
TA-VAAL iteration: 500 vae_loss: 1.847729206085205 dsc_loss: 1.3641788959503174
TA-VAAL iteration: 600 vae_loss: 1.693411111831665 dsc_loss: 1.408471703529358
TA-VAAL iteration: 700 vae_loss: 1.85532808303833 dsc_loss: 1.3733327388763428
TA-VAAL iteration: 800 vae_loss: 1.6006778478622437 dsc_loss: 1.3917417526245117
TA-VAAL iteration: 900 vae_loss: 1.9751176834106445 dsc_loss: 1.3717424869537354
TA-VAAL iteration: 1000 vae_loss: 1.8903658390045166 dsc_loss: 1.412460207939148
TA-VAAL iteration: 1100 vae_loss: 1.8221956491470337 dsc_loss: 1.3727781772613525
TA-VAAL iteration: 1200 vae_loss: 1.8168381452560425 dsc_loss: 1.3716485500335693
TA-VAAL iteration: 1300 vae_loss: 1.9563874006271362 dsc_loss: 1.3626080751419067
TA-VAAL iteration: 1400 vae_loss: 2.0621023178100586 dsc_loss: 1.3974671363830566
TA-VAAL iteration: 1500 vae_loss: 1.9137961864471436 dsc_loss: 1.3502583503723145
TA-VAAL iteration: 1600 vae_loss: 2.143322467803955 dsc_loss: 1.3732669353485107
TA-VAAL iteration: 1700 vae_loss: 2.1637728214263916 dsc_loss: 1.3581228256225586
TA-VAAL iteration: 1800 vae_loss: 2.084789752960205 dsc_loss: 1.3973536491394043
TA-VAAL iteration: 1900 vae_loss: 2.150195598602295 dsc_loss: 1.3718342781066895
TA-VAAL iteration: 2000 vae_loss: 2.148542642593384 dsc_loss: 1.3717098236083984
TA-VAAL iteration: 2100 vae_loss: 2.1731796264648438 dsc_loss: 1.3583159446716309
TA-VAAL iteration: 2200 vae_loss: 2.159299373626709 dsc_loss: 1.4018402099609375
TA-VAAL iteration: 2300 vae_loss: 2.043391704559326 dsc_loss: 1.3561460971832275
TA-VAAL iteration: 2400 vae_loss: 2.2311666011810303 dsc_loss: 1.3615436553955078
TA-VAAL iteration: 2500 vae_loss: 2.1629621982574463 dsc_loss: 1.359819769859314
TA-VAAL iteration: 2600 vae_loss: 2.3101963996887207 dsc_loss: 1.3946452140808105
TA-VAAL iteration: 2700 vae_loss: 2.1664605140686035 dsc_loss: 1.3655610084533691
TA-VAAL iteration: 2800 vae_loss: 2.2543153762817383 dsc_loss: 1.3891783952713013
TA-VAAL iteration: 2900 vae_loss: 2.141850709915161 dsc_loss: 1.3683907985687256
TA-VAAL iteration: 3000 vae_loss: 2.3668200969696045 dsc_loss: 1.3886964321136475
TA-VAAL iteration: 3100 vae_loss: 2.398301362991333 dsc_loss: 1.3703947067260742
TA-VAAL iteration: 3200 vae_loss: 2.5138297080993652 dsc_loss: 1.3764979839324951
TA-VAAL iteration: 3300 vae_loss: 2.4200782775878906 dsc_loss: 1.371159315109253
TA-VAAL iteration: 3400 vae_loss: 2.502715826034546 dsc_loss: 1.401625156402588
TA-VAAL iteration: 3500 vae_loss: 2.4454965591430664 dsc_loss: 1.3652477264404297
TA-VAAL iteration: 3600 vae_loss: 2.5590710639953613 dsc_loss: 1.3695058822631836
TA-VAAL iteration: 3700 vae_loss: 2.6289918422698975 dsc_loss: 1.3635202646255493
TA-VAAL iteration: 3800 vae_loss: 2.471129894256592 dsc_loss: 1.3878611326217651
TA-VAAL iteration: 3900 vae_loss: 2.548304557800293 dsc_loss: 1.3715498447418213
TA-VAAL iteration: 4000 vae_loss: 2.5165657997131348 dsc_loss: 1.3711810111999512
TA-VAAL iteration: 4100 vae_loss: 2.524735927581787 dsc_loss: 1.3704097270965576
TA-VAAL iteration: 4200 vae_loss: 2.528757333755493 dsc_loss: 1.3807010650634766
TA-VAAL iteration: 4300 vae_loss: 2.5675442218780518 dsc_loss: 1.3599157333374023
TA-VAAL iteration: 4400 vae_loss: 2.845329761505127 dsc_loss: 1.394146203994751
TA-VAAL iteration: 4500 vae_loss: 2.593228340148926 dsc_loss: 1.374889850616455
TA-VAAL iteration: 4600 vae_loss: 2.720820188522339 dsc_loss: 1.3926506042480469
TA-VAAL iteration: 4700 vae_loss: 2.676736831665039 dsc_loss: 1.3607463836669922
TA-VAAL iteration: 4800 vae_loss: 2.812778949737549 dsc_loss: 1.3863348960876465
TA-VAAL iteration: 4900 vae_loss: 2.8787384033203125 dsc_loss: 1.3771283626556396
TA-VAAL iteration: 5000 vae_loss: 2.7852296829223633 dsc_loss: 1.3854646682739258
TA-VAAL iteration: 5100 vae_loss: 2.732912540435791 dsc_loss: 1.3836548328399658
TA-VAAL iteration: 5200 vae_loss: 2.654208183288574 dsc_loss: 1.4043307304382324
TA-VAAL iteration: 5300 vae_loss: 2.789276599884033 dsc_loss: 1.3572280406951904
TA-VAAL iteration: 5400 vae_loss: 2.707791328430176 dsc_loss: 1.3827745914459229
TA-VAAL iteration: 5500 vae_loss: 2.9844894409179688 dsc_loss: 1.3785765171051025
TA-VAAL iteration: 5600 vae_loss: 2.8093786239624023 dsc_loss: 1.379546880722046
TA-VAAL iteration: 5700 vae_loss: 2.9460947513580322 dsc_loss: 1.3638336658477783
TA-VAAL iteration: 5800 vae_loss: 2.853087902069092 dsc_loss: 1.3862378597259521
TA-VAAL iteration: 5900 vae_loss: 3.018404483795166 dsc_loss: 1.364928960800171
TA-VAAL iteration: 6000 vae_loss: 2.877017021179199 dsc_loss: 1.380673885345459
TA-VAAL iteration: 6100 vae_loss: 2.9425411224365234 dsc_loss: 1.3706037998199463
TA-VAAL iteration: 6200 vae_loss: 2.9030730724334717 dsc_loss: 1.3760014772415161
TA-VAAL iteration: 6300 vae_loss: 3.015213966369629 dsc_loss: 1.3737812042236328
TA-VAAL iteration: 6400 vae_loss: 2.9084606170654297 dsc_loss: 1.4049427509307861
TA-VAAL iteration: 6500 vae_loss: 3.048405647277832 dsc_loss: 1.357213020324707
TA-VAAL iteration: 6600 vae_loss: 3.3111414909362793 dsc_loss: 1.3857247829437256
TA-VAAL iteration: 6700 vae_loss: 3.043045997619629 dsc_loss: 1.365325689315796
TA-VAAL iteration: 6800 vae_loss: 3.0581576824188232 dsc_loss: 1.383507251739502
TA-VAAL iteration: 6900 vae_loss: 3.0198729038238525 dsc_loss: 1.3541488647460938
TA-VAAL iteration: 7000 vae_loss: 3.087038040161133 dsc_loss: 1.398273229598999
TA-VAAL iteration: 7100 vae_loss: 3.573532819747925 dsc_loss: 1.3971238136291504
TA-VAAL iteration: 7200 vae_loss: 3.0736470222473145 dsc_loss: 1.3776096105575562
1200 105908 21 106968
>> Train vae and task model
epoch 0: train loss is  1.60772
epoch 10: train loss is  1.48160
epoch 20: train loss is  1.32098
epoch 30: train loss is  1.28636
epoch 40: train loss is  1.21812
epoch 50: train loss is  1.24008
epoch 60: train loss is  1.18131
epoch 70: train loss is  1.15842
epoch 80: train loss is  1.14267
epoch 90: train loss is  1.18209
epoch 100: train loss is  1.16024
epoch 110: train loss is  1.12494
epoch 120: train loss is  1.09859
 >> Test Model
Cycle 6/10 || labeled data size 1200, test loss(MAE) =  0.82738
TA-VAAL iteration: 0 vae_loss: 1.724194049835205 dsc_loss: 1.4054286479949951
TA-VAAL iteration: 10 vae_loss: 1.7021195888519287 dsc_loss: 1.4542843103408813
TA-VAAL iteration: 20 vae_loss: 1.5302950143814087 dsc_loss: 1.4724621772766113
TA-VAAL iteration: 30 vae_loss: 1.4737070798873901 dsc_loss: 1.4457886219024658
TA-VAAL iteration: 40 vae_loss: 1.7175936698913574 dsc_loss: 1.422994613647461
TA-VAAL iteration: 50 vae_loss: 1.7919803857803345 dsc_loss: 1.3863376379013062
TA-VAAL iteration: 60 vae_loss: 1.9629929065704346 dsc_loss: 1.4566563367843628
TA-VAAL iteration: 70 vae_loss: 1.5854594707489014 dsc_loss: 1.3609720468521118
TA-VAAL iteration: 80 vae_loss: 1.8572852611541748 dsc_loss: 1.431015968322754
TA-VAAL iteration: 90 vae_loss: 1.7201454639434814 dsc_loss: 1.3834019899368286
TA-VAAL iteration: 100 vae_loss: 1.7079784870147705 dsc_loss: 1.3936386108398438
TA-VAAL iteration: 200 vae_loss: 1.6840543746948242 dsc_loss: 1.4475922584533691
TA-VAAL iteration: 300 vae_loss: 1.6318916082382202 dsc_loss: 1.4069888591766357
TA-VAAL iteration: 400 vae_loss: 1.324521780014038 dsc_loss: 1.4015395641326904
TA-VAAL iteration: 500 vae_loss: 1.725661039352417 dsc_loss: 1.3833563327789307
TA-VAAL iteration: 600 vae_loss: 1.5679380893707275 dsc_loss: 1.4085824489593506
TA-VAAL iteration: 700 vae_loss: 1.4717077016830444 dsc_loss: 1.402933120727539
TA-VAAL iteration: 800 vae_loss: 1.4591400623321533 dsc_loss: 1.3630318641662598
TA-VAAL iteration: 900 vae_loss: 1.6023950576782227 dsc_loss: 1.3823513984680176
TA-VAAL iteration: 1000 vae_loss: 1.5573430061340332 dsc_loss: 1.3846898078918457
TA-VAAL iteration: 1100 vae_loss: 1.5630426406860352 dsc_loss: 1.4021940231323242
TA-VAAL iteration: 1200 vae_loss: 1.4366908073425293 dsc_loss: 1.4412522315979004
TA-VAAL iteration: 1300 vae_loss: 1.4090160131454468 dsc_loss: 1.3911690711975098
TA-VAAL iteration: 1400 vae_loss: 1.6794041395187378 dsc_loss: 1.355247974395752
TA-VAAL iteration: 1500 vae_loss: 1.524606466293335 dsc_loss: 1.3610596656799316
TA-VAAL iteration: 1600 vae_loss: 1.6925591230392456 dsc_loss: 1.4218025207519531
TA-VAAL iteration: 1700 vae_loss: 1.5750749111175537 dsc_loss: 1.3453596830368042
TA-VAAL iteration: 1800 vae_loss: 1.5768462419509888 dsc_loss: 1.3429954051971436
TA-VAAL iteration: 1900 vae_loss: 1.6567834615707397 dsc_loss: 1.3784399032592773
TA-VAAL iteration: 2000 vae_loss: 1.5810174942016602 dsc_loss: 1.3839479684829712
TA-VAAL iteration: 2100 vae_loss: 1.7234418392181396 dsc_loss: 1.3772261142730713
TA-VAAL iteration: 2200 vae_loss: 1.6483126878738403 dsc_loss: 1.365736484527588
TA-VAAL iteration: 2300 vae_loss: 1.6240535974502563 dsc_loss: 1.3882255554199219
TA-VAAL iteration: 2400 vae_loss: 1.59807288646698 dsc_loss: 1.4050981998443604
TA-VAAL iteration: 2500 vae_loss: 1.5648876428604126 dsc_loss: 1.3815433979034424
TA-VAAL iteration: 2600 vae_loss: 1.5347867012023926 dsc_loss: 1.3276395797729492
TA-VAAL iteration: 2700 vae_loss: 1.5302002429962158 dsc_loss: 1.368156909942627
TA-VAAL iteration: 2800 vae_loss: 1.5008878707885742 dsc_loss: 1.3766334056854248
TA-VAAL iteration: 2900 vae_loss: 1.5113568305969238 dsc_loss: 1.4126927852630615
TA-VAAL iteration: 3000 vae_loss: 1.5882452726364136 dsc_loss: 1.3551883697509766
TA-VAAL iteration: 3100 vae_loss: 1.6513596773147583 dsc_loss: 1.4225603342056274
TA-VAAL iteration: 3200 vae_loss: 1.5509978532791138 dsc_loss: 1.3700690269470215
TA-VAAL iteration: 3300 vae_loss: 1.5567197799682617 dsc_loss: 1.372929573059082
TA-VAAL iteration: 3400 vae_loss: 1.5199158191680908 dsc_loss: 1.2903733253479004
TA-VAAL iteration: 3500 vae_loss: 1.5467593669891357 dsc_loss: 1.418221116065979
TA-VAAL iteration: 3600 vae_loss: 1.5382121801376343 dsc_loss: 1.3751106262207031
TA-VAAL iteration: 3700 vae_loss: 1.590623140335083 dsc_loss: 1.3262498378753662
TA-VAAL iteration: 3800 vae_loss: 1.5801643133163452 dsc_loss: 1.340456247329712
TA-VAAL iteration: 3900 vae_loss: 1.708133578300476 dsc_loss: 1.3849527835845947
TA-VAAL iteration: 4000 vae_loss: 1.5746952295303345 dsc_loss: 1.39166259765625
TA-VAAL iteration: 4100 vae_loss: 1.508997917175293 dsc_loss: 1.3537194728851318
TA-VAAL iteration: 4200 vae_loss: 1.6087169647216797 dsc_loss: 1.383793592453003
TA-VAAL iteration: 4300 vae_loss: 1.652550458908081 dsc_loss: 1.4322807788848877
TA-VAAL iteration: 4400 vae_loss: 1.5878512859344482 dsc_loss: 1.3956522941589355
TA-VAAL iteration: 4500 vae_loss: 1.447434663772583 dsc_loss: 1.3260332345962524
TA-VAAL iteration: 4600 vae_loss: 1.609708547592163 dsc_loss: 1.3688840866088867
TA-VAAL iteration: 4700 vae_loss: 1.5167385339736938 dsc_loss: 1.3858999013900757
TA-VAAL iteration: 4800 vae_loss: 1.585111141204834 dsc_loss: 1.3960752487182617
TA-VAAL iteration: 4900 vae_loss: 1.5848867893218994 dsc_loss: 1.275363564491272
TA-VAAL iteration: 5000 vae_loss: 1.6624033451080322 dsc_loss: 1.4023447036743164
TA-VAAL iteration: 5100 vae_loss: 1.4582717418670654 dsc_loss: 1.3403346538543701
TA-VAAL iteration: 5200 vae_loss: 1.6004670858383179 dsc_loss: 1.3366073369979858
TA-VAAL iteration: 5300 vae_loss: 1.3938883543014526 dsc_loss: 1.2205350399017334
TA-VAAL iteration: 5400 vae_loss: 1.6825543642044067 dsc_loss: 1.3195267915725708
TA-VAAL iteration: 5500 vae_loss: 1.6824588775634766 dsc_loss: 1.3722202777862549
TA-VAAL iteration: 5600 vae_loss: 1.5372449159622192 dsc_loss: 1.383490800857544
TA-VAAL iteration: 5700 vae_loss: 2.9596633911132812 dsc_loss: 1.3991936445236206
TA-VAAL iteration: 5800 vae_loss: 1.7847201824188232 dsc_loss: 1.3567442893981934
TA-VAAL iteration: 5900 vae_loss: 1.6236923933029175 dsc_loss: 1.3623101711273193
TA-VAAL iteration: 6000 vae_loss: 1.6475355625152588 dsc_loss: 1.3627815246582031
TA-VAAL iteration: 6100 vae_loss: 1.605226993560791 dsc_loss: 1.3988215923309326
TA-VAAL iteration: 6200 vae_loss: 1.7457606792449951 dsc_loss: 1.3970682621002197
TA-VAAL iteration: 6300 vae_loss: 1.6670610904693604 dsc_loss: 1.3856544494628906
TA-VAAL iteration: 6400 vae_loss: 1.5783376693725586 dsc_loss: 1.3030400276184082
TA-VAAL iteration: 6500 vae_loss: 1.6663836240768433 dsc_loss: 1.3612914085388184
TA-VAAL iteration: 6600 vae_loss: 1.6425511837005615 dsc_loss: 1.3913371562957764
TA-VAAL iteration: 6700 vae_loss: 1.6888009309768677 dsc_loss: 1.4157872200012207
TA-VAAL iteration: 6800 vae_loss: 1.5045310258865356 dsc_loss: 1.273924708366394
TA-VAAL iteration: 6900 vae_loss: 1.7192661762237549 dsc_loss: 1.3960164785385132
TA-VAAL iteration: 7000 vae_loss: 1.7276930809020996 dsc_loss: 1.2857801914215088
TA-VAAL iteration: 7100 vae_loss: 1.7363762855529785 dsc_loss: 1.314570665359497
TA-VAAL iteration: 7200 vae_loss: 1.5985242128372192 dsc_loss: 1.2331085205078125
TA-VAAL iteration: 7300 vae_loss: 1.8333200216293335 dsc_loss: 1.3698064088821411
TA-VAAL iteration: 7400 vae_loss: 1.795011043548584 dsc_loss: 1.3686355352401733
1400 105708 21 107020
>> Train vae and task model
epoch 0: train loss is  1.61883
epoch 10: train loss is  1.25882
epoch 20: train loss is  1.07859
epoch 30: train loss is  1.04285
epoch 40: train loss is  1.00777
epoch 50: train loss is  0.96682
epoch 60: train loss is  0.94181
epoch 70: train loss is  0.95829
epoch 80: train loss is  0.95401
epoch 90: train loss is  0.89053
epoch 100: train loss is  0.93297
epoch 110: train loss is  0.87715
epoch 120: train loss is  0.86410
 >> Test Model
Cycle 7/10 || labeled data size 1400, test loss(MAE) =  0.54735
TA-VAAL iteration: 0 vae_loss: 1.602271556854248 dsc_loss: 1.414368748664856
TA-VAAL iteration: 10 vae_loss: 1.7642630338668823 dsc_loss: 1.3801167011260986
TA-VAAL iteration: 20 vae_loss: 1.786287784576416 dsc_loss: 1.4850916862487793
TA-VAAL iteration: 30 vae_loss: 1.7876027822494507 dsc_loss: 1.420098066329956
TA-VAAL iteration: 40 vae_loss: 1.6905735731124878 dsc_loss: 1.3129347562789917
TA-VAAL iteration: 50 vae_loss: 1.9429479837417603 dsc_loss: 1.430765151977539
TA-VAAL iteration: 60 vae_loss: 1.8852417469024658 dsc_loss: 1.3862509727478027
TA-VAAL iteration: 70 vae_loss: 1.9205195903778076 dsc_loss: 1.3757015466690063
TA-VAAL iteration: 80 vae_loss: 2.240200996398926 dsc_loss: 1.3901903629302979
TA-VAAL iteration: 90 vae_loss: 1.6759542226791382 dsc_loss: 1.3891949653625488
TA-VAAL iteration: 100 vae_loss: 1.7760688066482544 dsc_loss: 1.3767298460006714
TA-VAAL iteration: 200 vae_loss: 1.4851233959197998 dsc_loss: 1.4042481184005737
TA-VAAL iteration: 300 vae_loss: 1.5589488744735718 dsc_loss: 1.3949871063232422
TA-VAAL iteration: 400 vae_loss: 1.5728133916854858 dsc_loss: 1.3885819911956787
TA-VAAL iteration: 500 vae_loss: 1.6207191944122314 dsc_loss: 1.381560206413269
TA-VAAL iteration: 600 vae_loss: 1.6448357105255127 dsc_loss: 1.3858139514923096
TA-VAAL iteration: 700 vae_loss: 1.536047339439392 dsc_loss: 1.3399118185043335
TA-VAAL iteration: 800 vae_loss: 1.565064787864685 dsc_loss: 1.3942070007324219
TA-VAAL iteration: 900 vae_loss: 1.6628422737121582 dsc_loss: 1.421234369277954
TA-VAAL iteration: 1000 vae_loss: 1.6314024925231934 dsc_loss: 1.3876032829284668
TA-VAAL iteration: 1100 vae_loss: 1.6821187734603882 dsc_loss: 1.39674973487854
TA-VAAL iteration: 1200 vae_loss: 1.5967559814453125 dsc_loss: 1.380124807357788
TA-VAAL iteration: 1300 vae_loss: 1.4162507057189941 dsc_loss: 1.3907787799835205
TA-VAAL iteration: 1400 vae_loss: 1.7721647024154663 dsc_loss: 1.3898687362670898
TA-VAAL iteration: 1500 vae_loss: 1.4985706806182861 dsc_loss: 1.4106675386428833
TA-VAAL iteration: 1600 vae_loss: 1.5555353164672852 dsc_loss: 1.4026782512664795
TA-VAAL iteration: 1700 vae_loss: 1.4736851453781128 dsc_loss: 1.3801190853118896
TA-VAAL iteration: 1800 vae_loss: 1.65090012550354 dsc_loss: 1.392856240272522
TA-VAAL iteration: 1900 vae_loss: 1.507696509361267 dsc_loss: 1.388498306274414
TA-VAAL iteration: 2000 vae_loss: 1.6856952905654907 dsc_loss: 1.386388897895813
TA-VAAL iteration: 2100 vae_loss: 1.5937482118606567 dsc_loss: 1.3880056142807007
TA-VAAL iteration: 2200 vae_loss: 1.6538256406784058 dsc_loss: 1.3862745761871338
TA-VAAL iteration: 2300 vae_loss: 1.6391512155532837 dsc_loss: 1.3829872608184814
TA-VAAL iteration: 2400 vae_loss: 1.5820289850234985 dsc_loss: 1.3829808235168457
TA-VAAL iteration: 2500 vae_loss: 1.6949055194854736 dsc_loss: 1.386638879776001
TA-VAAL iteration: 2600 vae_loss: 1.5667645931243896 dsc_loss: 1.3908109664916992
TA-VAAL iteration: 2700 vae_loss: 1.6195820569992065 dsc_loss: 1.398094654083252
TA-VAAL iteration: 2800 vae_loss: 1.516406774520874 dsc_loss: 1.380435824394226
TA-VAAL iteration: 2900 vae_loss: 1.607866883277893 dsc_loss: 1.386413335800171
TA-VAAL iteration: 3000 vae_loss: 1.5317933559417725 dsc_loss: 1.3862321376800537
TA-VAAL iteration: 3100 vae_loss: 1.6526213884353638 dsc_loss: 1.3874292373657227
TA-VAAL iteration: 3200 vae_loss: 1.5694338083267212 dsc_loss: 1.381491780281067
TA-VAAL iteration: 3300 vae_loss: 1.6579182147979736 dsc_loss: 1.3864624500274658
TA-VAAL iteration: 3400 vae_loss: 1.5906457901000977 dsc_loss: 1.3836278915405273
TA-VAAL iteration: 3500 vae_loss: 1.568192720413208 dsc_loss: 1.3825364112854004
TA-VAAL iteration: 3600 vae_loss: 1.6375197172164917 dsc_loss: 1.3864582777023315
TA-VAAL iteration: 3700 vae_loss: 1.5982459783554077 dsc_loss: 1.3835785388946533
TA-VAAL iteration: 3800 vae_loss: 1.6134809255599976 dsc_loss: 1.3857247829437256
TA-VAAL iteration: 3900 vae_loss: 1.5304713249206543 dsc_loss: 1.3827133178710938
TA-VAAL iteration: 4000 vae_loss: 1.6584304571151733 dsc_loss: 1.3851821422576904
TA-VAAL iteration: 4100 vae_loss: 1.5581738948822021 dsc_loss: 1.389324426651001
TA-VAAL iteration: 4200 vae_loss: 1.690600037574768 dsc_loss: 1.3856691122055054
TA-VAAL iteration: 4300 vae_loss: 1.6241523027420044 dsc_loss: 1.380674123764038
TA-VAAL iteration: 4400 vae_loss: 1.6294660568237305 dsc_loss: 1.3842506408691406
TA-VAAL iteration: 4500 vae_loss: 1.6081838607788086 dsc_loss: 1.3878085613250732
TA-VAAL iteration: 4600 vae_loss: 1.5997872352600098 dsc_loss: 1.39095139503479
TA-VAAL iteration: 4700 vae_loss: 1.6242849826812744 dsc_loss: 1.3855092525482178
TA-VAAL iteration: 4800 vae_loss: 1.5895541906356812 dsc_loss: 1.38555908203125
TA-VAAL iteration: 4900 vae_loss: 1.6185303926467896 dsc_loss: 1.392442226409912
TA-VAAL iteration: 5000 vae_loss: 1.6244781017303467 dsc_loss: 1.380570650100708
TA-VAAL iteration: 5100 vae_loss: 1.681562900543213 dsc_loss: 1.388277292251587
TA-VAAL iteration: 5200 vae_loss: 1.5847251415252686 dsc_loss: 1.3893816471099854
TA-VAAL iteration: 5300 vae_loss: 1.658555030822754 dsc_loss: 1.3885602951049805
TA-VAAL iteration: 5400 vae_loss: 1.6267876625061035 dsc_loss: 1.382013201713562
TA-VAAL iteration: 5500 vae_loss: 1.6295313835144043 dsc_loss: 1.391290307044983
TA-VAAL iteration: 5600 vae_loss: 1.6304268836975098 dsc_loss: 1.3865342140197754
TA-VAAL iteration: 5700 vae_loss: 1.5708527565002441 dsc_loss: 1.386133074760437
TA-VAAL iteration: 5800 vae_loss: 1.6220543384552002 dsc_loss: 1.387030839920044
TA-VAAL iteration: 5900 vae_loss: 1.6188604831695557 dsc_loss: 1.384603500366211
TA-VAAL iteration: 6000 vae_loss: 1.6280916929244995 dsc_loss: 1.3913782835006714
TA-VAAL iteration: 6100 vae_loss: 1.57930588722229 dsc_loss: 1.3785319328308105
TA-VAAL iteration: 6200 vae_loss: 1.6355080604553223 dsc_loss: 1.389736533164978
TA-VAAL iteration: 6300 vae_loss: 1.6122678518295288 dsc_loss: 1.3883063793182373
TA-VAAL iteration: 6400 vae_loss: 1.689215064048767 dsc_loss: 1.3826298713684082
TA-VAAL iteration: 6500 vae_loss: 1.6375877857208252 dsc_loss: 1.3808255195617676
TA-VAAL iteration: 6600 vae_loss: 1.6677049398422241 dsc_loss: 1.3899898529052734
TA-VAAL iteration: 6700 vae_loss: 1.69610595703125 dsc_loss: 1.3862109184265137
TA-VAAL iteration: 6800 vae_loss: 1.6479575634002686 dsc_loss: 1.3867652416229248
TA-VAAL iteration: 6900 vae_loss: 1.6517527103424072 dsc_loss: 1.38825261592865
TA-VAAL iteration: 7000 vae_loss: 1.7023664712905884 dsc_loss: 1.3896864652633667
TA-VAAL iteration: 7100 vae_loss: 1.6498510837554932 dsc_loss: 1.3817591667175293
TA-VAAL iteration: 7200 vae_loss: 1.6754133701324463 dsc_loss: 1.3847057819366455
TA-VAAL iteration: 7300 vae_loss: 1.655850887298584 dsc_loss: 1.3801603317260742
TA-VAAL iteration: 7400 vae_loss: 1.6804375648498535 dsc_loss: 1.3922871351242065
TA-VAAL iteration: 7500 vae_loss: 1.7030668258666992 dsc_loss: 1.380244493484497
TA-VAAL iteration: 7600 vae_loss: 1.6341335773468018 dsc_loss: 1.3790898323059082
TA-VAAL iteration: 7700 vae_loss: 1.706418752670288 dsc_loss: 1.3848609924316406
1600 105508 21 107020
>> Train vae and task model
epoch 0: train loss is  1.64303
epoch 10: train loss is  1.51867
epoch 20: train loss is  1.42239
epoch 30: train loss is  1.32869
epoch 40: train loss is  1.29921
epoch 50: train loss is  1.26691
epoch 60: train loss is  1.25676
epoch 70: train loss is  1.22957
epoch 80: train loss is  1.25837
epoch 90: train loss is  1.19065
epoch 100: train loss is  1.24126
epoch 110: train loss is  1.18404
epoch 120: train loss is  1.20555
 >> Test Model
Cycle 8/10 || labeled data size 1600, test loss(MAE) =  0.82738
TA-VAAL iteration: 0 vae_loss: 1.7895301580429077 dsc_loss: 1.4006319046020508
TA-VAAL iteration: 10 vae_loss: 1.5901355743408203 dsc_loss: 1.415736198425293
TA-VAAL iteration: 20 vae_loss: 1.5669734477996826 dsc_loss: 1.3825912475585938
TA-VAAL iteration: 30 vae_loss: 1.787468671798706 dsc_loss: 1.4378137588500977
TA-VAAL iteration: 40 vae_loss: 1.8138926029205322 dsc_loss: 1.3873631954193115
TA-VAAL iteration: 50 vae_loss: 2.2110207080841064 dsc_loss: 1.405623435974121
TA-VAAL iteration: 60 vae_loss: 1.761780858039856 dsc_loss: 1.4652554988861084
TA-VAAL iteration: 70 vae_loss: 1.7667192220687866 dsc_loss: 1.4084863662719727
TA-VAAL iteration: 80 vae_loss: 1.8207844495773315 dsc_loss: 1.3881895542144775
TA-VAAL iteration: 90 vae_loss: 1.784858226776123 dsc_loss: 1.3913276195526123
TA-VAAL iteration: 100 vae_loss: 1.8445650339126587 dsc_loss: 1.4430186748504639
TA-VAAL iteration: 200 vae_loss: 1.7087452411651611 dsc_loss: 1.4411643743515015
TA-VAAL iteration: 300 vae_loss: 1.4172465801239014 dsc_loss: 1.434511423110962
TA-VAAL iteration: 400 vae_loss: 1.3897442817687988 dsc_loss: 1.4238855838775635
TA-VAAL iteration: 500 vae_loss: 1.4481537342071533 dsc_loss: 1.403790831565857
TA-VAAL iteration: 600 vae_loss: 1.5068320035934448 dsc_loss: 1.3771493434906006
TA-VAAL iteration: 700 vae_loss: 1.4932595491409302 dsc_loss: 1.3684955835342407
TA-VAAL iteration: 800 vae_loss: 1.4431633949279785 dsc_loss: 1.3850809335708618
TA-VAAL iteration: 900 vae_loss: 1.4603970050811768 dsc_loss: 1.4165966510772705
TA-VAAL iteration: 1000 vae_loss: 1.5343303680419922 dsc_loss: 1.3896610736846924
TA-VAAL iteration: 1100 vae_loss: 1.6454182863235474 dsc_loss: 1.3806302547454834
TA-VAAL iteration: 1200 vae_loss: 1.4842993021011353 dsc_loss: 1.3860454559326172
TA-VAAL iteration: 1300 vae_loss: 1.4956200122833252 dsc_loss: 1.3666960000991821
TA-VAAL iteration: 1400 vae_loss: 1.5601093769073486 dsc_loss: 1.405334711074829
TA-VAAL iteration: 1500 vae_loss: 1.558209776878357 dsc_loss: 1.3954620361328125
TA-VAAL iteration: 1600 vae_loss: 1.5076874494552612 dsc_loss: 1.3825602531433105
TA-VAAL iteration: 1700 vae_loss: 1.4679312705993652 dsc_loss: 1.389033555984497
TA-VAAL iteration: 1800 vae_loss: 1.503430962562561 dsc_loss: 1.3932998180389404
TA-VAAL iteration: 1900 vae_loss: 1.456499695777893 dsc_loss: 1.394737720489502
TA-VAAL iteration: 2000 vae_loss: 1.5450477600097656 dsc_loss: 1.397231101989746
TA-VAAL iteration: 2100 vae_loss: 1.503250002861023 dsc_loss: 1.3888158798217773
TA-VAAL iteration: 2200 vae_loss: 1.499934196472168 dsc_loss: 1.3823223114013672
TA-VAAL iteration: 2300 vae_loss: 1.480041742324829 dsc_loss: 1.383164644241333
TA-VAAL iteration: 2400 vae_loss: 1.5327962636947632 dsc_loss: 1.3864901065826416
TA-VAAL iteration: 2500 vae_loss: 1.5231424570083618 dsc_loss: 1.3888185024261475
TA-VAAL iteration: 2600 vae_loss: 1.4820301532745361 dsc_loss: 1.3883564472198486
TA-VAAL iteration: 2700 vae_loss: 1.5504045486450195 dsc_loss: 1.3849810361862183
TA-VAAL iteration: 2800 vae_loss: 1.5235432386398315 dsc_loss: 1.3837001323699951
TA-VAAL iteration: 2900 vae_loss: 1.5254158973693848 dsc_loss: 1.3895055055618286
TA-VAAL iteration: 3000 vae_loss: 1.5632081031799316 dsc_loss: 1.3878109455108643
TA-VAAL iteration: 3100 vae_loss: 1.5278472900390625 dsc_loss: 1.3910170793533325
TA-VAAL iteration: 3200 vae_loss: 1.5302625894546509 dsc_loss: 1.3909448385238647
TA-VAAL iteration: 3300 vae_loss: 1.5494283437728882 dsc_loss: 1.3884871006011963
TA-VAAL iteration: 3400 vae_loss: 1.5391674041748047 dsc_loss: 1.3927714824676514
TA-VAAL iteration: 3500 vae_loss: 1.5950475931167603 dsc_loss: 1.3867614269256592
TA-VAAL iteration: 3600 vae_loss: 1.5734186172485352 dsc_loss: 1.388514757156372
TA-VAAL iteration: 3700 vae_loss: 1.5391970872879028 dsc_loss: 1.3906588554382324
TA-VAAL iteration: 3800 vae_loss: 1.5534062385559082 dsc_loss: 1.387645959854126
TA-VAAL iteration: 3900 vae_loss: 1.5693893432617188 dsc_loss: 1.3846349716186523
TA-VAAL iteration: 4000 vae_loss: 1.551818609237671 dsc_loss: 1.3870112895965576
TA-VAAL iteration: 4100 vae_loss: 1.5753521919250488 dsc_loss: 1.3844125270843506
TA-VAAL iteration: 4200 vae_loss: 1.606536626815796 dsc_loss: 1.3859357833862305
TA-VAAL iteration: 4300 vae_loss: 1.5998495817184448 dsc_loss: 1.3892323970794678
TA-VAAL iteration: 4400 vae_loss: 1.6022238731384277 dsc_loss: 1.3936525583267212
TA-VAAL iteration: 4500 vae_loss: 1.6913847923278809 dsc_loss: 1.3897420167922974
TA-VAAL iteration: 4600 vae_loss: 1.5987430810928345 dsc_loss: 1.3881633281707764
TA-VAAL iteration: 4700 vae_loss: 1.5992852449417114 dsc_loss: 1.38912832736969
TA-VAAL iteration: 4800 vae_loss: 1.5574796199798584 dsc_loss: 1.384145736694336
TA-VAAL iteration: 4900 vae_loss: 1.6220428943634033 dsc_loss: 1.3849519491195679
TA-VAAL iteration: 5000 vae_loss: 1.5954158306121826 dsc_loss: 1.39264976978302
TA-VAAL iteration: 5100 vae_loss: 1.568314552307129 dsc_loss: 1.389925479888916
TA-VAAL iteration: 5200 vae_loss: 1.6268144845962524 dsc_loss: 1.389268398284912
TA-VAAL iteration: 5300 vae_loss: 1.5902198553085327 dsc_loss: 1.3853881359100342
TA-VAAL iteration: 5400 vae_loss: 1.6366115808486938 dsc_loss: 1.386418104171753
TA-VAAL iteration: 5500 vae_loss: 1.5826473236083984 dsc_loss: 1.3878644704818726
TA-VAAL iteration: 5600 vae_loss: 1.5962895154953003 dsc_loss: 1.3904411792755127
TA-VAAL iteration: 5700 vae_loss: 1.6008884906768799 dsc_loss: 1.3867292404174805
TA-VAAL iteration: 5800 vae_loss: 1.6271106004714966 dsc_loss: 1.3947285413742065
TA-VAAL iteration: 5900 vae_loss: 1.677613377571106 dsc_loss: 1.3895121812820435
TA-VAAL iteration: 6000 vae_loss: 1.619631290435791 dsc_loss: 1.391818881034851
TA-VAAL iteration: 6100 vae_loss: 1.6194508075714111 dsc_loss: 1.3904365301132202
TA-VAAL iteration: 6200 vae_loss: 1.6424036026000977 dsc_loss: 1.3939063549041748
TA-VAAL iteration: 6300 vae_loss: 1.6758326292037964 dsc_loss: 1.3865848779678345
TA-VAAL iteration: 6400 vae_loss: 1.6757936477661133 dsc_loss: 1.3821759223937988
TA-VAAL iteration: 6500 vae_loss: 1.5947299003601074 dsc_loss: 1.388275146484375
TA-VAAL iteration: 6600 vae_loss: 1.6622636318206787 dsc_loss: 1.4024507999420166
TA-VAAL iteration: 6700 vae_loss: 1.6678335666656494 dsc_loss: 1.3896528482437134
TA-VAAL iteration: 6800 vae_loss: 1.7027912139892578 dsc_loss: 1.3959386348724365
TA-VAAL iteration: 6900 vae_loss: 1.7298460006713867 dsc_loss: 1.3849079608917236
TA-VAAL iteration: 7000 vae_loss: 1.6759963035583496 dsc_loss: 1.3894790410995483
TA-VAAL iteration: 7100 vae_loss: 1.6498275995254517 dsc_loss: 1.3865172863006592
TA-VAAL iteration: 7200 vae_loss: 1.6770095825195312 dsc_loss: 1.3898611068725586
TA-VAAL iteration: 7300 vae_loss: 1.6815321445465088 dsc_loss: 1.3889336585998535
TA-VAAL iteration: 7400 vae_loss: 1.6877937316894531 dsc_loss: 1.3996188640594482
TA-VAAL iteration: 7500 vae_loss: 1.69031822681427 dsc_loss: 1.390085220336914
TA-VAAL iteration: 7600 vae_loss: 1.8905885219573975 dsc_loss: 1.3825633525848389
TA-VAAL iteration: 7700 vae_loss: 1.761080026626587 dsc_loss: 1.3951778411865234
TA-VAAL iteration: 7800 vae_loss: 1.6446027755737305 dsc_loss: 1.3896284103393555
TA-VAAL iteration: 7900 vae_loss: 1.6815574169158936 dsc_loss: 1.3861310482025146
1800 105308 21 107020
>> Train vae and task model
epoch 0: train loss is  1.61889
epoch 10: train loss is  1.42860
epoch 20: train loss is  1.33001
epoch 30: train loss is  1.31000
epoch 40: train loss is  1.26450
epoch 50: train loss is  1.25714
epoch 60: train loss is  1.23714
epoch 70: train loss is  1.20533
epoch 80: train loss is  1.22764
epoch 90: train loss is  1.21601
epoch 100: train loss is  1.20858
epoch 110: train loss is  1.18873
epoch 120: train loss is  1.19922
 >> Test Model
Cycle 9/10 || labeled data size 1800, test loss(MAE) =  0.82738
TA-VAAL iteration: 0 vae_loss: 1.7122159004211426 dsc_loss: 1.3973400592803955
TA-VAAL iteration: 10 vae_loss: 1.506485104560852 dsc_loss: 1.4469530582427979
TA-VAAL iteration: 20 vae_loss: 1.1916451454162598 dsc_loss: 1.4691519737243652
TA-VAAL iteration: 30 vae_loss: 1.6450817584991455 dsc_loss: 1.3969498872756958
TA-VAAL iteration: 40 vae_loss: 1.703649640083313 dsc_loss: 1.3969805240631104
TA-VAAL iteration: 50 vae_loss: 2.1427831649780273 dsc_loss: 1.3800588846206665
TA-VAAL iteration: 60 vae_loss: 1.8536732196807861 dsc_loss: 1.3849737644195557
TA-VAAL iteration: 70 vae_loss: 1.7688937187194824 dsc_loss: 1.3854691982269287
TA-VAAL iteration: 80 vae_loss: 1.7625656127929688 dsc_loss: 1.2795240879058838
TA-VAAL iteration: 90 vae_loss: 1.8484774827957153 dsc_loss: 1.3925987482070923
TA-VAAL iteration: 100 vae_loss: 1.62403404712677 dsc_loss: 1.3563718795776367
TA-VAAL iteration: 200 vae_loss: 1.6540347337722778 dsc_loss: 1.4287922382354736
TA-VAAL iteration: 300 vae_loss: 1.564552903175354 dsc_loss: 1.3859574794769287
TA-VAAL iteration: 400 vae_loss: 1.4673776626586914 dsc_loss: 1.3762543201446533
TA-VAAL iteration: 500 vae_loss: 1.5762732028961182 dsc_loss: 1.391272783279419
TA-VAAL iteration: 600 vae_loss: 1.5226664543151855 dsc_loss: 1.3959718942642212
TA-VAAL iteration: 700 vae_loss: 1.511667251586914 dsc_loss: 1.4072548151016235
TA-VAAL iteration: 800 vae_loss: 1.581817626953125 dsc_loss: 1.412466049194336
TA-VAAL iteration: 900 vae_loss: 1.693636417388916 dsc_loss: 1.3916178941726685
TA-VAAL iteration: 1000 vae_loss: 1.5519555807113647 dsc_loss: 1.3781640529632568
TA-VAAL iteration: 1100 vae_loss: 1.664940595626831 dsc_loss: 1.3933619260787964
TA-VAAL iteration: 1200 vae_loss: 1.5278518199920654 dsc_loss: 1.3859559297561646
TA-VAAL iteration: 1300 vae_loss: 1.7081784009933472 dsc_loss: 1.3818873167037964
TA-VAAL iteration: 1400 vae_loss: 1.6142059564590454 dsc_loss: 1.3869969844818115
TA-VAAL iteration: 1500 vae_loss: 1.5426650047302246 dsc_loss: 1.3811721801757812
TA-VAAL iteration: 1600 vae_loss: 1.7694172859191895 dsc_loss: 1.3837156295776367
TA-VAAL iteration: 1700 vae_loss: 1.5497305393218994 dsc_loss: 1.4370239973068237
TA-VAAL iteration: 1800 vae_loss: 1.5717871189117432 dsc_loss: 1.3894808292388916
TA-VAAL iteration: 1900 vae_loss: 1.615938663482666 dsc_loss: 1.3889994621276855
TA-VAAL iteration: 2000 vae_loss: 1.7061831951141357 dsc_loss: 1.3776754140853882
TA-VAAL iteration: 2100 vae_loss: 1.5640664100646973 dsc_loss: 1.380859136581421
TA-VAAL iteration: 2200 vae_loss: 1.6124837398529053 dsc_loss: 1.3899421691894531
TA-VAAL iteration: 2300 vae_loss: 1.6298813819885254 dsc_loss: 1.3875566720962524
TA-VAAL iteration: 2400 vae_loss: 1.5408353805541992 dsc_loss: 1.3789788484573364
TA-VAAL iteration: 2500 vae_loss: 1.694383144378662 dsc_loss: 1.3857437372207642
TA-VAAL iteration: 2600 vae_loss: 1.6504207849502563 dsc_loss: 1.3822567462921143
TA-VAAL iteration: 2700 vae_loss: 1.6069594621658325 dsc_loss: 1.3949458599090576
TA-VAAL iteration: 2800 vae_loss: 1.7067458629608154 dsc_loss: 1.3933157920837402
TA-VAAL iteration: 2900 vae_loss: 1.5926852226257324 dsc_loss: 1.3846687078475952
TA-VAAL iteration: 3000 vae_loss: 1.6307094097137451 dsc_loss: 1.397965669631958
TA-VAAL iteration: 3100 vae_loss: 1.7292537689208984 dsc_loss: 1.3864840269088745
TA-VAAL iteration: 3200 vae_loss: 1.728140115737915 dsc_loss: 1.3840490579605103
TA-VAAL iteration: 3300 vae_loss: 1.6473503112792969 dsc_loss: 1.389141321182251
TA-VAAL iteration: 3400 vae_loss: 1.6376638412475586 dsc_loss: 1.3926385641098022
TA-VAAL iteration: 3500 vae_loss: 1.6720285415649414 dsc_loss: 1.3842291831970215
TA-VAAL iteration: 3600 vae_loss: 1.6443250179290771 dsc_loss: 1.3802378177642822
TA-VAAL iteration: 3700 vae_loss: 1.7157793045043945 dsc_loss: 1.3966375589370728
TA-VAAL iteration: 3800 vae_loss: 1.729524850845337 dsc_loss: 1.3941596746444702
TA-VAAL iteration: 3900 vae_loss: 1.77004873752594 dsc_loss: 1.3968002796173096
TA-VAAL iteration: 4000 vae_loss: 1.7512774467468262 dsc_loss: 1.3754146099090576
TA-VAAL iteration: 4100 vae_loss: 1.7395756244659424 dsc_loss: 1.3875892162322998
TA-VAAL iteration: 4200 vae_loss: 1.6558629274368286 dsc_loss: 1.3900041580200195
TA-VAAL iteration: 4300 vae_loss: 1.7190086841583252 dsc_loss: 1.3923676013946533
TA-VAAL iteration: 4400 vae_loss: 1.7228922843933105 dsc_loss: 1.3772621154785156
TA-VAAL iteration: 4500 vae_loss: 1.8045141696929932 dsc_loss: 1.3732805252075195
TA-VAAL iteration: 4600 vae_loss: 1.774151086807251 dsc_loss: 1.384507179260254
TA-VAAL iteration: 4700 vae_loss: 1.736797571182251 dsc_loss: 1.3911421298980713
TA-VAAL iteration: 4800 vae_loss: 1.791616678237915 dsc_loss: 1.393129587173462
TA-VAAL iteration: 4900 vae_loss: 1.7573997974395752 dsc_loss: 1.368746042251587
TA-VAAL iteration: 5000 vae_loss: 1.7180894613265991 dsc_loss: 1.3790087699890137
TA-VAAL iteration: 5100 vae_loss: 1.8462152481079102 dsc_loss: 1.3791698217391968
TA-VAAL iteration: 5200 vae_loss: 1.695552945137024 dsc_loss: 1.3829073905944824
TA-VAAL iteration: 5300 vae_loss: 1.6925569772720337 dsc_loss: 1.3825852870941162
TA-VAAL iteration: 5400 vae_loss: 1.7667226791381836 dsc_loss: 1.3782012462615967
TA-VAAL iteration: 5500 vae_loss: 1.803126573562622 dsc_loss: 1.3863108158111572
TA-VAAL iteration: 5600 vae_loss: 1.7636656761169434 dsc_loss: 1.3865699768066406
TA-VAAL iteration: 5700 vae_loss: 1.7065869569778442 dsc_loss: 1.3948678970336914
TA-VAAL iteration: 5800 vae_loss: 1.696563959121704 dsc_loss: 1.385805368423462
TA-VAAL iteration: 5900 vae_loss: 1.7461975812911987 dsc_loss: 1.3915588855743408
TA-VAAL iteration: 6000 vae_loss: 1.9016337394714355 dsc_loss: 1.3848234415054321
TA-VAAL iteration: 6100 vae_loss: 1.7928948402404785 dsc_loss: 1.3837788105010986
TA-VAAL iteration: 6200 vae_loss: 1.791172742843628 dsc_loss: 1.3921891450881958
TA-VAAL iteration: 6300 vae_loss: 1.7289034128189087 dsc_loss: 1.3904072046279907
TA-VAAL iteration: 6400 vae_loss: 1.7938201427459717 dsc_loss: 1.387563943862915
TA-VAAL iteration: 6500 vae_loss: 1.7703460454940796 dsc_loss: 1.3843774795532227
TA-VAAL iteration: 6600 vae_loss: 1.7490665912628174 dsc_loss: 1.4121222496032715
TA-VAAL iteration: 6700 vae_loss: 1.7356607913970947 dsc_loss: 1.3898539543151855
TA-VAAL iteration: 6800 vae_loss: 1.763405203819275 dsc_loss: 1.3889530897140503
TA-VAAL iteration: 6900 vae_loss: 1.7285172939300537 dsc_loss: 1.378652572631836
TA-VAAL iteration: 7000 vae_loss: 1.703810214996338 dsc_loss: 1.3926019668579102
TA-VAAL iteration: 7100 vae_loss: 1.7097318172454834 dsc_loss: 1.3873112201690674
TA-VAAL iteration: 7200 vae_loss: 1.6813738346099854 dsc_loss: 1.3847192525863647
TA-VAAL iteration: 7300 vae_loss: 1.710378646850586 dsc_loss: 1.3841800689697266
TA-VAAL iteration: 7400 vae_loss: 1.8153352737426758 dsc_loss: 1.3655222654342651
TA-VAAL iteration: 7500 vae_loss: 1.772265911102295 dsc_loss: 1.3953815698623657
TA-VAAL iteration: 7600 vae_loss: 1.8008893728256226 dsc_loss: 1.3900344371795654
TA-VAAL iteration: 7700 vae_loss: 1.7720777988433838 dsc_loss: 1.397197961807251
TA-VAAL iteration: 7800 vae_loss: 1.6694881916046143 dsc_loss: 1.3721387386322021
TA-VAAL iteration: 7900 vae_loss: 1.7591612339019775 dsc_loss: 1.3875689506530762
TA-VAAL iteration: 8000 vae_loss: 1.7425272464752197 dsc_loss: 1.3792303800582886
TA-VAAL iteration: 8100 vae_loss: 1.6873098611831665 dsc_loss: 1.3822059631347656
TA-VAAL iteration: 8200 vae_loss: 1.7386577129364014 dsc_loss: 1.380057454109192
2000 105108 21 107020
>> Train vae and task model
epoch 0: train loss is  1.58555
epoch 10: train loss is  1.44215
epoch 20: train loss is  1.32736
epoch 30: train loss is  1.27316
epoch 40: train loss is  1.26534
epoch 50: train loss is  1.23027
epoch 60: train loss is  1.23335
epoch 70: train loss is  1.20943
epoch 80: train loss is  1.18453
epoch 90: train loss is  1.15106
epoch 100: train loss is  1.15603
epoch 110: train loss is  1.14924
epoch 120: train loss is  1.14076
 >> Test Model
Cycle 10/10 || labeled data size 2000, test loss(MAE) =  0.82738
Finished.
>> Train vae and task model
epoch 0: train loss is  1.72336
epoch 10: train loss is  1.67264
epoch 20: train loss is  1.60734
epoch 30: train loss is  1.39309
epoch 40: train loss is  1.37538
epoch 50: train loss is  1.35931
epoch 60: train loss is  1.28468
epoch 70: train loss is  1.23184
epoch 80: train loss is  1.28314
epoch 90: train loss is  1.38198
epoch 100: train loss is  1.37893
epoch 110: train loss is  1.26669
epoch 120: train loss is  1.10914
 >> Test Model
Cycle 1/10 || labeled data size 200, test loss(MAE) =  0.83297
TA-VAAL iteration: 0 vae_loss: 1.7099263668060303 dsc_loss: 1.4062515497207642
TA-VAAL iteration: 10 vae_loss: 1.8964701890945435 dsc_loss: 1.373785376548767
TA-VAAL iteration: 20 vae_loss: 1.7817682027816772 dsc_loss: 1.36116361618042
TA-VAAL iteration: 30 vae_loss: 2.0654237270355225 dsc_loss: 1.388899564743042
TA-VAAL iteration: 40 vae_loss: 1.8601335287094116 dsc_loss: 1.362161636352539
TA-VAAL iteration: 50 vae_loss: 2.040346622467041 dsc_loss: 1.3715542554855347
TA-VAAL iteration: 60 vae_loss: 1.8470706939697266 dsc_loss: 1.3565666675567627
TA-VAAL iteration: 70 vae_loss: 1.737080454826355 dsc_loss: 1.3492491245269775
TA-VAAL iteration: 80 vae_loss: 1.5810320377349854 dsc_loss: 1.3593940734863281
TA-VAAL iteration: 90 vae_loss: 1.6971298456192017 dsc_loss: 1.3921582698822021
TA-VAAL iteration: 100 vae_loss: 1.5324386358261108 dsc_loss: 1.3636807203292847
TA-VAAL iteration: 200 vae_loss: 1.778059959411621 dsc_loss: 1.3492015600204468
TA-VAAL iteration: 300 vae_loss: 1.6021991968154907 dsc_loss: 1.3480513095855713
TA-VAAL iteration: 400 vae_loss: 1.5182064771652222 dsc_loss: 1.3604727983474731
TA-VAAL iteration: 500 vae_loss: 1.574476957321167 dsc_loss: 1.3374472856521606
TA-VAAL iteration: 600 vae_loss: 1.8914012908935547 dsc_loss: 1.318642258644104
TA-VAAL iteration: 700 vae_loss: 1.6820008754730225 dsc_loss: 1.323938012123108
TA-VAAL iteration: 800 vae_loss: 1.7662465572357178 dsc_loss: 1.3003429174423218
TA-VAAL iteration: 900 vae_loss: 1.9287362098693848 dsc_loss: 1.2904692888259888
TA-VAAL iteration: 1000 vae_loss: 2.5533251762390137 dsc_loss: 1.2295633554458618
TA-VAAL iteration: 1100 vae_loss: 2.0770301818847656 dsc_loss: 1.2420015335083008
TA-VAAL iteration: 1200 vae_loss: 1.9043611288070679 dsc_loss: 1.3715629577636719
TA-VAAL iteration: 1300 vae_loss: 1.7208352088928223 dsc_loss: 1.3725837469100952
TA-VAAL iteration: 1400 vae_loss: 1.9047448635101318 dsc_loss: 1.306467890739441
TA-VAAL iteration: 1500 vae_loss: 2.141049861907959 dsc_loss: 1.3883922100067139
TA-VAAL iteration: 1600 vae_loss: 2.362309694290161 dsc_loss: 1.2734415531158447
TA-VAAL iteration: 1700 vae_loss: 2.372407913208008 dsc_loss: 1.3180378675460815
TA-VAAL iteration: 1800 vae_loss: 1.9490209817886353 dsc_loss: 1.2877765893936157
TA-VAAL iteration: 1900 vae_loss: 2.2474608421325684 dsc_loss: 1.312045693397522
TA-VAAL iteration: 2000 vae_loss: 2.347637176513672 dsc_loss: 1.2699261903762817
TA-VAAL iteration: 2100 vae_loss: 2.1003472805023193 dsc_loss: 1.1766114234924316
TA-VAAL iteration: 2200 vae_loss: 2.5310754776000977 dsc_loss: 1.2076774835586548
TA-VAAL iteration: 2300 vae_loss: 2.322004795074463 dsc_loss: 1.2074731588363647
TA-VAAL iteration: 2400 vae_loss: 2.488635301589966 dsc_loss: 1.2132079601287842
TA-VAAL iteration: 2500 vae_loss: 2.3962841033935547 dsc_loss: 1.1998227834701538
TA-VAAL iteration: 2600 vae_loss: 2.4661099910736084 dsc_loss: 1.1816736459732056
TA-VAAL iteration: 2700 vae_loss: 2.3694653511047363 dsc_loss: 1.1374826431274414
TA-VAAL iteration: 2800 vae_loss: 2.9301540851593018 dsc_loss: 1.098077416419983
TA-VAAL iteration: 2900 vae_loss: 2.910271167755127 dsc_loss: 1.0657987594604492
TA-VAAL iteration: 3000 vae_loss: 2.3733201026916504 dsc_loss: 1.157900333404541
TA-VAAL iteration: 3100 vae_loss: 3.116454601287842 dsc_loss: 1.134338617324829
TA-VAAL iteration: 3200 vae_loss: 3.1204183101654053 dsc_loss: 1.1415188312530518
TA-VAAL iteration: 3300 vae_loss: 2.8229336738586426 dsc_loss: 1.1786741018295288
TA-VAAL iteration: 3400 vae_loss: 2.9871468544006348 dsc_loss: 1.1764355897903442
TA-VAAL iteration: 3500 vae_loss: 2.530839443206787 dsc_loss: 1.1682991981506348
TA-VAAL iteration: 3600 vae_loss: 2.7285921573638916 dsc_loss: 1.2667324542999268
TA-VAAL iteration: 3700 vae_loss: 2.4151663780212402 dsc_loss: 1.1643683910369873
TA-VAAL iteration: 3800 vae_loss: 2.8313162326812744 dsc_loss: 1.1545802354812622
TA-VAAL iteration: 3900 vae_loss: 2.93284273147583 dsc_loss: 1.0903234481811523
TA-VAAL iteration: 4000 vae_loss: 2.940117835998535 dsc_loss: 1.1415294408798218
TA-VAAL iteration: 4100 vae_loss: 3.0641822814941406 dsc_loss: 1.0840145349502563
TA-VAAL iteration: 4200 vae_loss: 3.191824436187744 dsc_loss: 1.0656797885894775
TA-VAAL iteration: 4300 vae_loss: 3.064563751220703 dsc_loss: 1.0917956829071045
TA-VAAL iteration: 4400 vae_loss: 3.0695478916168213 dsc_loss: 1.0465307235717773
TA-VAAL iteration: 4500 vae_loss: 3.322721481323242 dsc_loss: 1.1168723106384277
TA-VAAL iteration: 4600 vae_loss: 3.504512310028076 dsc_loss: 1.0530402660369873
TA-VAAL iteration: 4700 vae_loss: 3.318765878677368 dsc_loss: 1.1062947511672974
TA-VAAL iteration: 4800 vae_loss: 2.7479920387268066 dsc_loss: 1.0527808666229248
TA-VAAL iteration: 4900 vae_loss: 3.277698278427124 dsc_loss: 1.120849609375
TA-VAAL iteration: 5000 vae_loss: 2.948117733001709 dsc_loss: 1.058497428894043
TA-VAAL iteration: 5100 vae_loss: 2.886528491973877 dsc_loss: 1.1053500175476074
TA-VAAL iteration: 5200 vae_loss: 2.631990909576416 dsc_loss: 1.1092073917388916
TA-VAAL iteration: 5300 vae_loss: 3.2747373580932617 dsc_loss: 1.0750620365142822
TA-VAAL iteration: 5400 vae_loss: 3.856271266937256 dsc_loss: 1.041569471359253
TA-VAAL iteration: 5500 vae_loss: 4.126767158508301 dsc_loss: 0.9930254817008972
TA-VAAL iteration: 5600 vae_loss: 3.3584232330322266 dsc_loss: 0.9723324775695801
TA-VAAL iteration: 5700 vae_loss: 2.8857040405273438 dsc_loss: 0.9860848784446716
TA-VAAL iteration: 5800 vae_loss: 3.8168184757232666 dsc_loss: 1.0126365423202515
TA-VAAL iteration: 5900 vae_loss: 3.7961573600769043 dsc_loss: 1.057732105255127
TA-VAAL iteration: 6000 vae_loss: 3.7460923194885254 dsc_loss: 1.0195467472076416
TA-VAAL iteration: 6100 vae_loss: 3.3493733406066895 dsc_loss: 1.019819736480713
TA-VAAL iteration: 6200 vae_loss: 3.8167173862457275 dsc_loss: 1.0995595455169678
400 106708 518 106491
>> Train vae and task model
epoch 0: train loss is  1.68157
epoch 10: train loss is  1.60187
epoch 20: train loss is  1.43413
epoch 30: train loss is  1.38570
epoch 40: train loss is  1.29452
epoch 50: train loss is  1.28156
epoch 60: train loss is  1.35915
epoch 70: train loss is  1.22235
epoch 80: train loss is  1.21616
epoch 90: train loss is  1.13691
epoch 100: train loss is  1.08758
epoch 110: train loss is  1.08813
epoch 120: train loss is  1.11654
 >> Test Model
Cycle 2/10 || labeled data size 400, test loss(MAE) =  0.83297
TA-VAAL iteration: 0 vae_loss: 1.884665608406067 dsc_loss: 1.3871192932128906
TA-VAAL iteration: 10 vae_loss: 1.4463645219802856 dsc_loss: 1.4221608638763428
TA-VAAL iteration: 20 vae_loss: 1.5414936542510986 dsc_loss: 1.4044771194458008
TA-VAAL iteration: 30 vae_loss: 2.0331006050109863 dsc_loss: 1.4095650911331177
TA-VAAL iteration: 40 vae_loss: 1.816892147064209 dsc_loss: 1.370270848274231
TA-VAAL iteration: 50 vae_loss: 2.236767292022705 dsc_loss: 1.391190767288208
TA-VAAL iteration: 60 vae_loss: 2.2123818397521973 dsc_loss: 1.3818354606628418
TA-VAAL iteration: 70 vae_loss: 2.1195688247680664 dsc_loss: 1.4209660291671753
TA-VAAL iteration: 80 vae_loss: 1.9780240058898926 dsc_loss: 1.3551654815673828
TA-VAAL iteration: 90 vae_loss: 1.9722881317138672 dsc_loss: 1.3579026460647583
TA-VAAL iteration: 100 vae_loss: 1.926491379737854 dsc_loss: 1.4104430675506592
TA-VAAL iteration: 200 vae_loss: 1.5903443098068237 dsc_loss: 1.3641257286071777
TA-VAAL iteration: 300 vae_loss: 1.750575065612793 dsc_loss: 1.3138387203216553
TA-VAAL iteration: 400 vae_loss: 2.2559356689453125 dsc_loss: 1.3348941802978516
TA-VAAL iteration: 500 vae_loss: 1.7090458869934082 dsc_loss: 1.3291711807250977
TA-VAAL iteration: 600 vae_loss: 2.0312983989715576 dsc_loss: 1.3177390098571777
TA-VAAL iteration: 700 vae_loss: 2.1711244583129883 dsc_loss: 1.3808122873306274
TA-VAAL iteration: 800 vae_loss: 2.4781088829040527 dsc_loss: 1.3883306980133057
TA-VAAL iteration: 900 vae_loss: 2.255295991897583 dsc_loss: 1.3373979330062866
TA-VAAL iteration: 1000 vae_loss: 1.924824833869934 dsc_loss: 1.3339474201202393
TA-VAAL iteration: 1100 vae_loss: 1.8986879587173462 dsc_loss: 1.3311049938201904
TA-VAAL iteration: 1200 vae_loss: 1.9669581651687622 dsc_loss: 1.3168151378631592
TA-VAAL iteration: 1300 vae_loss: 2.2495486736297607 dsc_loss: 1.4492939710617065
TA-VAAL iteration: 1400 vae_loss: 2.1895971298217773 dsc_loss: 1.3047783374786377
TA-VAAL iteration: 1500 vae_loss: 1.7899510860443115 dsc_loss: 1.527709722518921
TA-VAAL iteration: 1600 vae_loss: 2.353731155395508 dsc_loss: 1.3614295721054077
TA-VAAL iteration: 1700 vae_loss: 2.189826488494873 dsc_loss: 1.3274728059768677
TA-VAAL iteration: 1800 vae_loss: 2.1028032302856445 dsc_loss: 1.2983343601226807
TA-VAAL iteration: 1900 vae_loss: 2.0588955879211426 dsc_loss: 1.2099552154541016
TA-VAAL iteration: 2000 vae_loss: 2.2302141189575195 dsc_loss: 1.3628437519073486
TA-VAAL iteration: 2100 vae_loss: 2.037174940109253 dsc_loss: 1.3505630493164062
TA-VAAL iteration: 2200 vae_loss: 2.254779815673828 dsc_loss: 1.3739416599273682
TA-VAAL iteration: 2300 vae_loss: 2.0132250785827637 dsc_loss: 1.342043161392212
TA-VAAL iteration: 2400 vae_loss: 2.152655601501465 dsc_loss: 1.3165498971939087
TA-VAAL iteration: 2500 vae_loss: 1.9337069988250732 dsc_loss: 1.34039306640625
TA-VAAL iteration: 2600 vae_loss: 1.2378654479980469 dsc_loss: 1.7152683734893799
TA-VAAL iteration: 2700 vae_loss: 2.0469608306884766 dsc_loss: 1.3936326503753662
TA-VAAL iteration: 2800 vae_loss: 1.8654446601867676 dsc_loss: 1.362927794456482
TA-VAAL iteration: 2900 vae_loss: 1.885987401008606 dsc_loss: 1.3904414176940918
TA-VAAL iteration: 3000 vae_loss: 1.771498680114746 dsc_loss: 1.4064593315124512
TA-VAAL iteration: 3100 vae_loss: 1.7821910381317139 dsc_loss: 1.4104019403457642
TA-VAAL iteration: 3200 vae_loss: 1.8992223739624023 dsc_loss: 1.3654292821884155
TA-VAAL iteration: 3300 vae_loss: 1.826204538345337 dsc_loss: 1.3202476501464844
TA-VAAL iteration: 3400 vae_loss: 2.0060629844665527 dsc_loss: 1.4425549507141113
TA-VAAL iteration: 3500 vae_loss: 1.8617044687271118 dsc_loss: 1.3456610441207886
TA-VAAL iteration: 3600 vae_loss: 1.898007869720459 dsc_loss: 1.3860526084899902
TA-VAAL iteration: 3700 vae_loss: 1.8732001781463623 dsc_loss: 1.2183597087860107
TA-VAAL iteration: 3800 vae_loss: 1.7642967700958252 dsc_loss: 1.1114232540130615
TA-VAAL iteration: 3900 vae_loss: 1.9831624031066895 dsc_loss: 1.336599588394165
TA-VAAL iteration: 4000 vae_loss: 1.9442591667175293 dsc_loss: 1.2005500793457031
TA-VAAL iteration: 4100 vae_loss: 1.9587322473526 dsc_loss: 1.4164440631866455
TA-VAAL iteration: 4200 vae_loss: 2.116697072982788 dsc_loss: 1.2715497016906738
TA-VAAL iteration: 4300 vae_loss: 2.288823127746582 dsc_loss: 1.3092684745788574
TA-VAAL iteration: 4400 vae_loss: 2.034011125564575 dsc_loss: 1.283158779144287
TA-VAAL iteration: 4500 vae_loss: 1.7904809713363647 dsc_loss: 0.9469023942947388
TA-VAAL iteration: 4600 vae_loss: 2.18394136428833 dsc_loss: 1.2539474964141846
TA-VAAL iteration: 4700 vae_loss: 1.765716314315796 dsc_loss: 1.2384546995162964
TA-VAAL iteration: 4800 vae_loss: 2.1162147521972656 dsc_loss: 1.3827104568481445
TA-VAAL iteration: 4900 vae_loss: 1.8094236850738525 dsc_loss: 1.2158079147338867
TA-VAAL iteration: 5000 vae_loss: 2.0962753295898438 dsc_loss: 1.2417762279510498
TA-VAAL iteration: 5100 vae_loss: 1.7484726905822754 dsc_loss: 1.2264186143875122
TA-VAAL iteration: 5200 vae_loss: 1.5493090152740479 dsc_loss: 1.0025452375411987
TA-VAAL iteration: 5300 vae_loss: 2.273272752761841 dsc_loss: 1.193393349647522
TA-VAAL iteration: 5400 vae_loss: 2.0886056423187256 dsc_loss: 1.2347702980041504
TA-VAAL iteration: 5500 vae_loss: 2.018265962600708 dsc_loss: 1.3109664916992188
TA-VAAL iteration: 5600 vae_loss: 1.9857585430145264 dsc_loss: 1.32293701171875
TA-VAAL iteration: 5700 vae_loss: 2.091918706893921 dsc_loss: 1.167886734008789
TA-VAAL iteration: 5800 vae_loss: 1.8976407051086426 dsc_loss: 1.1273366212844849
TA-VAAL iteration: 5900 vae_loss: 1.7445605993270874 dsc_loss: 0.9840483665466309
TA-VAAL iteration: 6000 vae_loss: 2.0353617668151855 dsc_loss: 1.180048942565918
TA-VAAL iteration: 6100 vae_loss: 2.183612108230591 dsc_loss: 1.1617844104766846
TA-VAAL iteration: 6200 vae_loss: 2.038494110107422 dsc_loss: 1.3068535327911377
TA-VAAL iteration: 6300 vae_loss: 2.310577392578125 dsc_loss: 1.2529046535491943
TA-VAAL iteration: 6400 vae_loss: 2.20627498626709 dsc_loss: 1.2282257080078125
600 106508 518 106625
>> Train vae and task model
epoch 0: train loss is  1.65516
epoch 10: train loss is  1.55277
epoch 20: train loss is  1.44277
epoch 30: train loss is  1.40877
epoch 40: train loss is  1.32829
epoch 50: train loss is  1.29117
epoch 60: train loss is  1.25037
epoch 70: train loss is  1.22890
epoch 80: train loss is  1.21666
epoch 90: train loss is  1.16984
epoch 100: train loss is  1.14377
epoch 110: train loss is  1.21747
epoch 120: train loss is  1.07916
 >> Test Model
Cycle 3/10 || labeled data size 600, test loss(MAE) =  0.83297
TA-VAAL iteration: 0 vae_loss: 2.0414576530456543 dsc_loss: 1.3869295120239258
TA-VAAL iteration: 10 vae_loss: 1.8497473001480103 dsc_loss: 1.4454936981201172
TA-VAAL iteration: 20 vae_loss: 1.6053065061569214 dsc_loss: 1.4529738426208496
TA-VAAL iteration: 30 vae_loss: 1.5560399293899536 dsc_loss: 1.3956732749938965
TA-VAAL iteration: 40 vae_loss: 1.6152102947235107 dsc_loss: 1.40458083152771
TA-VAAL iteration: 50 vae_loss: 1.8297008275985718 dsc_loss: 1.4543988704681396
TA-VAAL iteration: 60 vae_loss: 1.745610237121582 dsc_loss: 1.4115495681762695
TA-VAAL iteration: 70 vae_loss: 1.6733319759368896 dsc_loss: 1.3967159986495972
TA-VAAL iteration: 80 vae_loss: 1.690190315246582 dsc_loss: 1.4147827625274658
TA-VAAL iteration: 90 vae_loss: 1.5301291942596436 dsc_loss: 1.394271731376648
TA-VAAL iteration: 100 vae_loss: 1.6494061946868896 dsc_loss: 1.3908929824829102
TA-VAAL iteration: 200 vae_loss: 1.519751787185669 dsc_loss: 1.411899447441101
TA-VAAL iteration: 300 vae_loss: 1.7583541870117188 dsc_loss: 1.420665979385376
TA-VAAL iteration: 400 vae_loss: 1.567119836807251 dsc_loss: 1.3980804681777954
TA-VAAL iteration: 500 vae_loss: 1.6151846647262573 dsc_loss: 1.4031810760498047
TA-VAAL iteration: 600 vae_loss: 1.5542595386505127 dsc_loss: 1.3899863958358765
TA-VAAL iteration: 700 vae_loss: 1.586392879486084 dsc_loss: 1.3865432739257812
TA-VAAL iteration: 800 vae_loss: 1.6670312881469727 dsc_loss: 1.3931379318237305
TA-VAAL iteration: 900 vae_loss: 1.6664999723434448 dsc_loss: 1.3964629173278809
TA-VAAL iteration: 1000 vae_loss: 1.8001443147659302 dsc_loss: 1.3901114463806152
TA-VAAL iteration: 1100 vae_loss: 1.7439920902252197 dsc_loss: 1.3876290321350098
TA-VAAL iteration: 1200 vae_loss: 1.7022655010223389 dsc_loss: 1.3829538822174072
TA-VAAL iteration: 1300 vae_loss: 1.788050651550293 dsc_loss: 1.396037220954895
TA-VAAL iteration: 1400 vae_loss: 1.8046340942382812 dsc_loss: 1.3834428787231445
TA-VAAL iteration: 1500 vae_loss: 1.8547921180725098 dsc_loss: 1.390744686126709
TA-VAAL iteration: 1600 vae_loss: 1.8832809925079346 dsc_loss: 1.3884693384170532
TA-VAAL iteration: 1700 vae_loss: 1.9388833045959473 dsc_loss: 1.3871524333953857
TA-VAAL iteration: 1800 vae_loss: 1.8360753059387207 dsc_loss: 1.3998920917510986
TA-VAAL iteration: 1900 vae_loss: 2.0011849403381348 dsc_loss: 1.423048496246338
TA-VAAL iteration: 2000 vae_loss: 1.96284818649292 dsc_loss: 1.3985614776611328
TA-VAAL iteration: 2100 vae_loss: 2.057313919067383 dsc_loss: 1.3854570388793945
TA-VAAL iteration: 2200 vae_loss: 1.9905614852905273 dsc_loss: 1.3976207971572876
TA-VAAL iteration: 2300 vae_loss: 2.0338406562805176 dsc_loss: 1.3885506391525269
TA-VAAL iteration: 2400 vae_loss: 2.0779318809509277 dsc_loss: 1.3947265148162842
TA-VAAL iteration: 2500 vae_loss: 2.041625499725342 dsc_loss: 1.3940571546554565
TA-VAAL iteration: 2600 vae_loss: 2.1585283279418945 dsc_loss: 1.3820602893829346
TA-VAAL iteration: 2700 vae_loss: 2.1971564292907715 dsc_loss: 1.3812365531921387
TA-VAAL iteration: 2800 vae_loss: 2.2309343814849854 dsc_loss: 1.3979518413543701
TA-VAAL iteration: 2900 vae_loss: 2.2088122367858887 dsc_loss: 1.3884754180908203
TA-VAAL iteration: 3000 vae_loss: 2.311020851135254 dsc_loss: 1.3823407888412476
TA-VAAL iteration: 3100 vae_loss: 2.3553786277770996 dsc_loss: 1.3787645101547241
TA-VAAL iteration: 3200 vae_loss: 2.2955727577209473 dsc_loss: 1.4011726379394531
TA-VAAL iteration: 3300 vae_loss: 2.252535343170166 dsc_loss: 1.4018399715423584
TA-VAAL iteration: 3400 vae_loss: 2.4657351970672607 dsc_loss: 1.3847479820251465
TA-VAAL iteration: 3500 vae_loss: 2.613693952560425 dsc_loss: 1.3888460397720337
TA-VAAL iteration: 3600 vae_loss: 2.5387988090515137 dsc_loss: 1.3871421813964844
TA-VAAL iteration: 3700 vae_loss: 2.5209412574768066 dsc_loss: 1.3909680843353271
TA-VAAL iteration: 3800 vae_loss: 2.8012495040893555 dsc_loss: 1.4426889419555664
TA-VAAL iteration: 3900 vae_loss: 2.659346103668213 dsc_loss: 1.3843986988067627
TA-VAAL iteration: 4000 vae_loss: 2.4577035903930664 dsc_loss: 1.3844969272613525
TA-VAAL iteration: 4100 vae_loss: 2.601738691329956 dsc_loss: 1.4012809991836548
TA-VAAL iteration: 4200 vae_loss: 2.4703750610351562 dsc_loss: 1.3945822715759277
TA-VAAL iteration: 4300 vae_loss: 2.77847957611084 dsc_loss: 1.4007313251495361
TA-VAAL iteration: 4400 vae_loss: 2.6306614875793457 dsc_loss: 1.3950330018997192
TA-VAAL iteration: 4500 vae_loss: 2.6420671939849854 dsc_loss: 1.397118091583252
TA-VAAL iteration: 4600 vae_loss: 2.7132320404052734 dsc_loss: 1.37689208984375
TA-VAAL iteration: 4700 vae_loss: 2.734994888305664 dsc_loss: 1.3959816694259644
TA-VAAL iteration: 4800 vae_loss: 2.5471644401550293 dsc_loss: 1.3876097202301025
TA-VAAL iteration: 4900 vae_loss: 2.7250022888183594 dsc_loss: 1.3787896633148193
TA-VAAL iteration: 5000 vae_loss: 2.653987169265747 dsc_loss: 1.3869211673736572
TA-VAAL iteration: 5100 vae_loss: 2.7205288410186768 dsc_loss: 1.3937199115753174
TA-VAAL iteration: 5200 vae_loss: 2.7810769081115723 dsc_loss: 1.387304663658142
TA-VAAL iteration: 5300 vae_loss: 2.877591848373413 dsc_loss: 1.3906211853027344
TA-VAAL iteration: 5400 vae_loss: 2.956239700317383 dsc_loss: 1.3816663026809692
TA-VAAL iteration: 5500 vae_loss: 3.1702802181243896 dsc_loss: 1.4004931449890137
TA-VAAL iteration: 5600 vae_loss: 2.965482711791992 dsc_loss: 1.4024147987365723
TA-VAAL iteration: 5700 vae_loss: 2.895982503890991 dsc_loss: 1.3975260257720947
TA-VAAL iteration: 5800 vae_loss: 2.838538408279419 dsc_loss: 1.3876227140426636
TA-VAAL iteration: 5900 vae_loss: 2.9744296073913574 dsc_loss: 1.3919014930725098
TA-VAAL iteration: 6000 vae_loss: 3.047440528869629 dsc_loss: 1.4018632173538208
TA-VAAL iteration: 6100 vae_loss: 3.0825092792510986 dsc_loss: 1.382228970527649
TA-VAAL iteration: 6200 vae_loss: 2.972601890563965 dsc_loss: 1.3956308364868164
TA-VAAL iteration: 6300 vae_loss: 3.252556324005127 dsc_loss: 1.3945790529251099
TA-VAAL iteration: 6400 vae_loss: 3.104401111602783 dsc_loss: 1.3905370235443115
TA-VAAL iteration: 6500 vae_loss: 3.1307742595672607 dsc_loss: 1.4008913040161133
TA-VAAL iteration: 6600 vae_loss: 3.1506218910217285 dsc_loss: 1.387921929359436
TA-VAAL iteration: 6700 vae_loss: 3.092611312866211 dsc_loss: 1.3920612335205078
800 106308 381 106959
>> Train vae and task model
epoch 0: train loss is  1.66624
epoch 10: train loss is  1.51591
epoch 20: train loss is  1.16439
epoch 30: train loss is  1.09952
epoch 40: train loss is  1.05197
epoch 50: train loss is  1.02006
epoch 60: train loss is  0.98889
epoch 70: train loss is  1.05455
epoch 80: train loss is  0.96154
epoch 90: train loss is  0.95642
epoch 100: train loss is  0.92740
epoch 110: train loss is  0.88581
epoch 120: train loss is  0.93368
 >> Test Model
Cycle 4/10 || labeled data size 800, test loss(MAE) =  0.61858
TA-VAAL iteration: 0 vae_loss: 1.705369234085083 dsc_loss: 1.4012398719787598
TA-VAAL iteration: 10 vae_loss: 1.5375632047653198 dsc_loss: 1.4352025985717773
TA-VAAL iteration: 20 vae_loss: 1.6670887470245361 dsc_loss: 1.3875985145568848
TA-VAAL iteration: 30 vae_loss: 1.8359568119049072 dsc_loss: 1.417508602142334
TA-VAAL iteration: 40 vae_loss: 1.9399385452270508 dsc_loss: 1.38802170753479
TA-VAAL iteration: 50 vae_loss: 1.820685863494873 dsc_loss: 1.4151854515075684
TA-VAAL iteration: 60 vae_loss: 1.9252982139587402 dsc_loss: 1.3700840473175049
TA-VAAL iteration: 70 vae_loss: 1.9185659885406494 dsc_loss: 1.3899023532867432
TA-VAAL iteration: 80 vae_loss: 1.8570046424865723 dsc_loss: 1.4258055686950684
TA-VAAL iteration: 90 vae_loss: 1.5218380689620972 dsc_loss: 1.3967294692993164
TA-VAAL iteration: 100 vae_loss: 1.628775954246521 dsc_loss: 1.3866329193115234
TA-VAAL iteration: 200 vae_loss: 1.638973355293274 dsc_loss: 1.4052207469940186
TA-VAAL iteration: 300 vae_loss: 1.4440339803695679 dsc_loss: 1.3718894720077515
TA-VAAL iteration: 400 vae_loss: 1.4809881448745728 dsc_loss: 1.3726699352264404
TA-VAAL iteration: 500 vae_loss: 1.8457732200622559 dsc_loss: 1.4006731510162354
TA-VAAL iteration: 600 vae_loss: 1.686436414718628 dsc_loss: 1.376549482345581
TA-VAAL iteration: 700 vae_loss: 1.3881056308746338 dsc_loss: 1.3669309616088867
TA-VAAL iteration: 800 vae_loss: 1.9623901844024658 dsc_loss: 1.406497836112976
TA-VAAL iteration: 900 vae_loss: 1.3332892656326294 dsc_loss: 1.4144725799560547
TA-VAAL iteration: 1000 vae_loss: 1.535735845565796 dsc_loss: 1.3533658981323242
TA-VAAL iteration: 1100 vae_loss: 1.9147745370864868 dsc_loss: 1.4131920337677002
TA-VAAL iteration: 1200 vae_loss: 1.4751768112182617 dsc_loss: 1.4616990089416504
TA-VAAL iteration: 1300 vae_loss: 1.5268797874450684 dsc_loss: 1.3853416442871094
TA-VAAL iteration: 1400 vae_loss: 1.7277714014053345 dsc_loss: 1.405296802520752
TA-VAAL iteration: 1500 vae_loss: 1.5020239353179932 dsc_loss: 1.419778823852539
TA-VAAL iteration: 1600 vae_loss: 1.5531851053237915 dsc_loss: 1.372657299041748
TA-VAAL iteration: 1700 vae_loss: 1.727400302886963 dsc_loss: 1.4023692607879639
TA-VAAL iteration: 1800 vae_loss: 1.6137287616729736 dsc_loss: 1.3812029361724854
TA-VAAL iteration: 1900 vae_loss: 1.4448368549346924 dsc_loss: 1.379909634590149
TA-VAAL iteration: 2000 vae_loss: 1.696998119354248 dsc_loss: 1.3721625804901123
TA-VAAL iteration: 2100 vae_loss: 1.7476381063461304 dsc_loss: 1.3942739963531494
TA-VAAL iteration: 2200 vae_loss: 1.516396164894104 dsc_loss: 1.35990571975708
TA-VAAL iteration: 2300 vae_loss: 1.5948500633239746 dsc_loss: 1.3353807926177979
TA-VAAL iteration: 2400 vae_loss: 1.7804569005966187 dsc_loss: 1.3871994018554688
TA-VAAL iteration: 2500 vae_loss: 1.5559700727462769 dsc_loss: 1.4083601236343384
TA-VAAL iteration: 2600 vae_loss: 1.606083869934082 dsc_loss: 1.3619825839996338
TA-VAAL iteration: 2700 vae_loss: 1.7135518789291382 dsc_loss: 1.372781753540039
TA-VAAL iteration: 2800 vae_loss: 1.5371562242507935 dsc_loss: 1.4074032306671143
TA-VAAL iteration: 2900 vae_loss: 1.5983502864837646 dsc_loss: 1.382741928100586
TA-VAAL iteration: 3000 vae_loss: 1.8688116073608398 dsc_loss: 1.3801593780517578
TA-VAAL iteration: 3100 vae_loss: 1.5933072566986084 dsc_loss: 1.398529052734375
TA-VAAL iteration: 3200 vae_loss: 1.5769718885421753 dsc_loss: 1.3919739723205566
TA-VAAL iteration: 3300 vae_loss: 1.769753336906433 dsc_loss: 1.3576278686523438
TA-VAAL iteration: 3400 vae_loss: 1.7880918979644775 dsc_loss: 1.3884680271148682
TA-VAAL iteration: 3500 vae_loss: 1.6041998863220215 dsc_loss: 1.3833096027374268
TA-VAAL iteration: 3600 vae_loss: 1.7212767601013184 dsc_loss: 1.3340051174163818
TA-VAAL iteration: 3700 vae_loss: 1.7989189624786377 dsc_loss: 1.381895899772644
TA-VAAL iteration: 3800 vae_loss: 1.6030917167663574 dsc_loss: 1.4369558095932007
TA-VAAL iteration: 3900 vae_loss: 1.6991095542907715 dsc_loss: 1.3796486854553223
TA-VAAL iteration: 4000 vae_loss: 1.884605884552002 dsc_loss: 1.3890246152877808
TA-VAAL iteration: 4100 vae_loss: 1.6148403882980347 dsc_loss: 1.3893784284591675
TA-VAAL iteration: 4200 vae_loss: 1.672912359237671 dsc_loss: 1.385441541671753
TA-VAAL iteration: 4300 vae_loss: 1.831831693649292 dsc_loss: 1.34303879737854
TA-VAAL iteration: 4400 vae_loss: 1.7961845397949219 dsc_loss: 1.3782671689987183
TA-VAAL iteration: 4500 vae_loss: 1.732457160949707 dsc_loss: 1.3928751945495605
TA-VAAL iteration: 4600 vae_loss: 1.8189189434051514 dsc_loss: 1.3343446254730225
TA-VAAL iteration: 4700 vae_loss: 2.053016185760498 dsc_loss: 1.3943020105361938
TA-VAAL iteration: 4800 vae_loss: 1.8240255117416382 dsc_loss: 1.3902230262756348
TA-VAAL iteration: 4900 vae_loss: 1.808480978012085 dsc_loss: 1.3223347663879395
TA-VAAL iteration: 5000 vae_loss: 1.9368865489959717 dsc_loss: 1.399817943572998
TA-VAAL iteration: 5100 vae_loss: 1.8425252437591553 dsc_loss: 1.363804578781128
TA-VAAL iteration: 5200 vae_loss: 1.8833000659942627 dsc_loss: 1.3776960372924805
TA-VAAL iteration: 5300 vae_loss: 2.1214146614074707 dsc_loss: 1.3715553283691406
TA-VAAL iteration: 5400 vae_loss: 1.8806917667388916 dsc_loss: 1.3790030479431152
TA-VAAL iteration: 5500 vae_loss: 1.8406602144241333 dsc_loss: 1.413633108139038
TA-VAAL iteration: 5600 vae_loss: 2.0222887992858887 dsc_loss: 1.3375110626220703
TA-VAAL iteration: 5700 vae_loss: 2.001547336578369 dsc_loss: 1.3784725666046143
TA-VAAL iteration: 5800 vae_loss: 2.015519380569458 dsc_loss: 1.389718770980835
TA-VAAL iteration: 5900 vae_loss: 1.9915975332260132 dsc_loss: 1.3451344966888428
TA-VAAL iteration: 6000 vae_loss: 2.0436289310455322 dsc_loss: 1.3913147449493408
TA-VAAL iteration: 6100 vae_loss: 1.7120459079742432 dsc_loss: 1.4010460376739502
TA-VAAL iteration: 6200 vae_loss: 1.993558645248413 dsc_loss: 1.340324878692627
TA-VAAL iteration: 6300 vae_loss: 1.9998500347137451 dsc_loss: 1.393356204032898
TA-VAAL iteration: 6400 vae_loss: 1.8961048126220703 dsc_loss: 1.3937081098556519
TA-VAAL iteration: 6500 vae_loss: 1.9847333431243896 dsc_loss: 1.390444040298462
TA-VAAL iteration: 6600 vae_loss: 2.131206512451172 dsc_loss: 1.4075958728790283
TA-VAAL iteration: 6700 vae_loss: 1.917440414428711 dsc_loss: 1.4085248708724976
TA-VAAL iteration: 6800 vae_loss: 1.931204080581665 dsc_loss: 1.3524234294891357
TA-VAAL iteration: 6900 vae_loss: 2.3054189682006836 dsc_loss: 1.364972472190857
1000 106108 381 106959
>> Train vae and task model
epoch 0: train loss is  1.68320
epoch 10: train loss is  1.37096
epoch 20: train loss is  1.22081
epoch 30: train loss is  1.15021
epoch 40: train loss is  1.11010
epoch 50: train loss is  1.07029
epoch 60: train loss is  1.09033
epoch 70: train loss is  1.00664
epoch 80: train loss is  0.97936
epoch 90: train loss is  0.99603
epoch 100: train loss is  0.97289
epoch 110: train loss is  0.95126
epoch 120: train loss is  0.92658
 >> Test Model
Cycle 5/10 || labeled data size 1000, test loss(MAE) =  0.60452
TA-VAAL iteration: 0 vae_loss: 1.623259425163269 dsc_loss: 1.4264580011367798
TA-VAAL iteration: 10 vae_loss: 1.9335405826568604 dsc_loss: 1.3890329599380493
TA-VAAL iteration: 20 vae_loss: 1.6865146160125732 dsc_loss: 1.3657863140106201
TA-VAAL iteration: 30 vae_loss: 2.031255006790161 dsc_loss: 1.5115265846252441
TA-VAAL iteration: 40 vae_loss: 1.7504950761795044 dsc_loss: 1.3870373964309692
TA-VAAL iteration: 50 vae_loss: 1.8380906581878662 dsc_loss: 1.3705453872680664
TA-VAAL iteration: 60 vae_loss: 1.746941328048706 dsc_loss: 1.3678821325302124
TA-VAAL iteration: 70 vae_loss: 1.74407958984375 dsc_loss: 1.3985356092453003
TA-VAAL iteration: 80 vae_loss: 1.4778590202331543 dsc_loss: 1.3919274806976318
TA-VAAL iteration: 90 vae_loss: 1.6329829692840576 dsc_loss: 1.4083564281463623
TA-VAAL iteration: 100 vae_loss: 1.7361068725585938 dsc_loss: 1.3167588710784912
TA-VAAL iteration: 200 vae_loss: 1.6970871686935425 dsc_loss: 1.3891172409057617
TA-VAAL iteration: 300 vae_loss: 1.9280545711517334 dsc_loss: 1.3918683528900146
TA-VAAL iteration: 400 vae_loss: 1.7644023895263672 dsc_loss: 1.3883931636810303
TA-VAAL iteration: 500 vae_loss: 1.377240538597107 dsc_loss: 1.3647654056549072
TA-VAAL iteration: 600 vae_loss: 1.4650465250015259 dsc_loss: 1.3882596492767334
TA-VAAL iteration: 700 vae_loss: 1.6065301895141602 dsc_loss: 1.4219207763671875
TA-VAAL iteration: 800 vae_loss: 1.7684674263000488 dsc_loss: 1.3917453289031982
TA-VAAL iteration: 900 vae_loss: 1.688407301902771 dsc_loss: 1.35340416431427
TA-VAAL iteration: 1000 vae_loss: 1.5231720209121704 dsc_loss: 1.399983286857605
TA-VAAL iteration: 1100 vae_loss: 1.6126738786697388 dsc_loss: 1.387818455696106
TA-VAAL iteration: 1200 vae_loss: 1.6243860721588135 dsc_loss: 1.3854146003723145
TA-VAAL iteration: 1300 vae_loss: 1.6793136596679688 dsc_loss: 1.3804302215576172
TA-VAAL iteration: 1400 vae_loss: 1.6605945825576782 dsc_loss: 1.388291358947754
TA-VAAL iteration: 1500 vae_loss: 1.5604784488677979 dsc_loss: 1.3920972347259521
TA-VAAL iteration: 1600 vae_loss: 1.7742491960525513 dsc_loss: 1.4066317081451416
TA-VAAL iteration: 1700 vae_loss: 1.5875141620635986 dsc_loss: 1.379396915435791
TA-VAAL iteration: 1800 vae_loss: 1.5167226791381836 dsc_loss: 1.3735382556915283
TA-VAAL iteration: 1900 vae_loss: 1.5244455337524414 dsc_loss: 1.3723134994506836
TA-VAAL iteration: 2000 vae_loss: 1.6890332698822021 dsc_loss: 1.3944263458251953
TA-VAAL iteration: 2100 vae_loss: 1.6610499620437622 dsc_loss: 1.3861260414123535
TA-VAAL iteration: 2200 vae_loss: 1.6560003757476807 dsc_loss: 1.384699821472168
TA-VAAL iteration: 2300 vae_loss: 1.7187862396240234 dsc_loss: 1.371166467666626
TA-VAAL iteration: 2400 vae_loss: 1.8111616373062134 dsc_loss: 1.3962666988372803
TA-VAAL iteration: 2500 vae_loss: 1.7717305421829224 dsc_loss: 1.3738373517990112
TA-VAAL iteration: 2600 vae_loss: 1.5085914134979248 dsc_loss: 1.378570318222046
TA-VAAL iteration: 2700 vae_loss: 1.6558228731155396 dsc_loss: 1.3841350078582764
TA-VAAL iteration: 2800 vae_loss: 1.7596155405044556 dsc_loss: 1.3888356685638428
TA-VAAL iteration: 2900 vae_loss: 1.7309954166412354 dsc_loss: 1.3901139497756958
TA-VAAL iteration: 3000 vae_loss: 1.6654210090637207 dsc_loss: 1.375699520111084
TA-VAAL iteration: 3100 vae_loss: 1.7204792499542236 dsc_loss: 1.3709914684295654
TA-VAAL iteration: 3200 vae_loss: 1.6984100341796875 dsc_loss: 1.3868499994277954
TA-VAAL iteration: 3300 vae_loss: 1.687100887298584 dsc_loss: 1.384971022605896
TA-VAAL iteration: 3400 vae_loss: 1.6434276103973389 dsc_loss: 1.3921003341674805
TA-VAAL iteration: 3500 vae_loss: 1.622727632522583 dsc_loss: 1.3771870136260986
TA-VAAL iteration: 3600 vae_loss: 1.794519066810608 dsc_loss: 1.3872096538543701
TA-VAAL iteration: 3700 vae_loss: 1.7717161178588867 dsc_loss: 1.374680995941162
TA-VAAL iteration: 3800 vae_loss: 1.6975144147872925 dsc_loss: 1.3748259544372559
TA-VAAL iteration: 3900 vae_loss: 1.7034519910812378 dsc_loss: 1.3847850561141968
TA-VAAL iteration: 4000 vae_loss: 1.8378279209136963 dsc_loss: 1.3814783096313477
TA-VAAL iteration: 4100 vae_loss: 1.8602347373962402 dsc_loss: 1.3833560943603516
TA-VAAL iteration: 4200 vae_loss: 1.707323431968689 dsc_loss: 1.374558925628662
TA-VAAL iteration: 4300 vae_loss: 1.7634103298187256 dsc_loss: 1.3826501369476318
TA-VAAL iteration: 4400 vae_loss: 1.7448785305023193 dsc_loss: 1.3886454105377197
TA-VAAL iteration: 4500 vae_loss: 1.770725131034851 dsc_loss: 1.392194151878357
TA-VAAL iteration: 4600 vae_loss: 1.7317891120910645 dsc_loss: 1.3965007066726685
TA-VAAL iteration: 4700 vae_loss: 1.8268344402313232 dsc_loss: 1.3850233554840088
TA-VAAL iteration: 4800 vae_loss: 1.858715534210205 dsc_loss: 1.3894476890563965
TA-VAAL iteration: 4900 vae_loss: 1.800227165222168 dsc_loss: 1.3775830268859863
TA-VAAL iteration: 5000 vae_loss: 1.73636794090271 dsc_loss: 1.3819963932037354
TA-VAAL iteration: 5100 vae_loss: 1.786050796508789 dsc_loss: 1.3938555717468262
TA-VAAL iteration: 5200 vae_loss: 1.8618026971817017 dsc_loss: 1.3662523031234741
TA-VAAL iteration: 5300 vae_loss: 1.7555162906646729 dsc_loss: 1.3779066801071167
TA-VAAL iteration: 5400 vae_loss: 1.716451644897461 dsc_loss: 1.3775033950805664
TA-VAAL iteration: 5500 vae_loss: 1.704750418663025 dsc_loss: 1.4032034873962402
TA-VAAL iteration: 5600 vae_loss: 1.7433371543884277 dsc_loss: 1.3995305299758911
TA-VAAL iteration: 5700 vae_loss: 1.7991185188293457 dsc_loss: 1.367996096611023
TA-VAAL iteration: 5800 vae_loss: 1.7579511404037476 dsc_loss: 1.3846807479858398
TA-VAAL iteration: 5900 vae_loss: 1.668967366218567 dsc_loss: 1.3695350885391235
TA-VAAL iteration: 6000 vae_loss: 1.760132074356079 dsc_loss: 1.3782166242599487
TA-VAAL iteration: 6100 vae_loss: 1.749704360961914 dsc_loss: 1.34958815574646
TA-VAAL iteration: 6200 vae_loss: 1.8493216037750244 dsc_loss: 1.3907983303070068
TA-VAAL iteration: 6300 vae_loss: 1.7416752576828003 dsc_loss: 1.3729243278503418
TA-VAAL iteration: 6400 vae_loss: 1.7325265407562256 dsc_loss: 1.3850393295288086
TA-VAAL iteration: 6500 vae_loss: 1.7377095222473145 dsc_loss: 1.372058629989624
TA-VAAL iteration: 6600 vae_loss: 1.7241902351379395 dsc_loss: 1.38525390625
TA-VAAL iteration: 6700 vae_loss: 1.7649140357971191 dsc_loss: 1.358168601989746
TA-VAAL iteration: 6800 vae_loss: 1.6965441703796387 dsc_loss: 1.3759617805480957
TA-VAAL iteration: 6900 vae_loss: 1.7406154870986938 dsc_loss: 1.3789691925048828
TA-VAAL iteration: 7000 vae_loss: 1.7134058475494385 dsc_loss: 1.3880928754806519
TA-VAAL iteration: 7100 vae_loss: 1.764068841934204 dsc_loss: 1.400535225868225
TA-VAAL iteration: 7200 vae_loss: 1.709073543548584 dsc_loss: 1.3742690086364746
1200 105908 229 107106
>> Train vae and task model
epoch 0: train loss is  1.62636
epoch 10: train loss is  1.54182
epoch 20: train loss is  1.39688
epoch 30: train loss is  1.32956
epoch 40: train loss is  1.30706
epoch 50: train loss is  1.28597
epoch 60: train loss is  1.26684
epoch 70: train loss is  1.22151
epoch 80: train loss is  1.21994
epoch 90: train loss is  1.21810
epoch 100: train loss is  1.21497
epoch 110: train loss is  1.22182
epoch 120: train loss is  1.14834
 >> Test Model
Cycle 6/10 || labeled data size 1200, test loss(MAE) =  0.83297
TA-VAAL iteration: 0 vae_loss: 1.6742497682571411 dsc_loss: 1.405077338218689
TA-VAAL iteration: 10 vae_loss: 1.7071025371551514 dsc_loss: 1.4561585187911987
TA-VAAL iteration: 20 vae_loss: 1.3957661390304565 dsc_loss: 1.411200761795044
TA-VAAL iteration: 30 vae_loss: 1.6144764423370361 dsc_loss: 1.387031078338623
TA-VAAL iteration: 40 vae_loss: 1.8884843587875366 dsc_loss: 1.4310190677642822
TA-VAAL iteration: 50 vae_loss: 1.915270447731018 dsc_loss: 1.4061000347137451
TA-VAAL iteration: 60 vae_loss: 1.8800078630447388 dsc_loss: 1.4029830694198608
TA-VAAL iteration: 70 vae_loss: 1.7840476036071777 dsc_loss: 1.4144718647003174
TA-VAAL iteration: 80 vae_loss: 1.6283522844314575 dsc_loss: 1.4122185707092285
TA-VAAL iteration: 90 vae_loss: 1.7740230560302734 dsc_loss: 1.3988875150680542
TA-VAAL iteration: 100 vae_loss: 1.6528539657592773 dsc_loss: 1.3944735527038574
TA-VAAL iteration: 200 vae_loss: 1.5790822505950928 dsc_loss: 1.3721367120742798
TA-VAAL iteration: 300 vae_loss: 1.5741477012634277 dsc_loss: 1.3852202892303467
TA-VAAL iteration: 400 vae_loss: 1.4997166395187378 dsc_loss: 1.3926265239715576
TA-VAAL iteration: 500 vae_loss: 1.535222053527832 dsc_loss: 1.375342607498169
TA-VAAL iteration: 600 vae_loss: 1.4948269128799438 dsc_loss: 1.3794972896575928
TA-VAAL iteration: 700 vae_loss: 1.5523253679275513 dsc_loss: 1.402575135231018
TA-VAAL iteration: 800 vae_loss: 1.561396598815918 dsc_loss: 1.39310622215271
TA-VAAL iteration: 900 vae_loss: 1.5271871089935303 dsc_loss: 1.3897267580032349
TA-VAAL iteration: 1000 vae_loss: 1.494983434677124 dsc_loss: 1.3679838180541992
TA-VAAL iteration: 1100 vae_loss: 1.605924367904663 dsc_loss: 1.4011082649230957
TA-VAAL iteration: 1200 vae_loss: 1.6440316438674927 dsc_loss: 1.3903937339782715
TA-VAAL iteration: 1300 vae_loss: 1.5865391492843628 dsc_loss: 1.3853950500488281
TA-VAAL iteration: 1400 vae_loss: 1.7340999841690063 dsc_loss: 1.4087278842926025
TA-VAAL iteration: 1500 vae_loss: 1.475993275642395 dsc_loss: 1.4137873649597168
TA-VAAL iteration: 1600 vae_loss: 1.6776554584503174 dsc_loss: 1.3803337812423706
TA-VAAL iteration: 1700 vae_loss: 1.547936201095581 dsc_loss: 1.3867127895355225
TA-VAAL iteration: 1800 vae_loss: 1.61893892288208 dsc_loss: 1.3782345056533813
TA-VAAL iteration: 1900 vae_loss: 1.5955181121826172 dsc_loss: 1.381425380706787
TA-VAAL iteration: 2000 vae_loss: 1.660094976425171 dsc_loss: 1.3895467519760132
TA-VAAL iteration: 2100 vae_loss: 1.5319675207138062 dsc_loss: 1.388784646987915
TA-VAAL iteration: 2200 vae_loss: 1.6164662837982178 dsc_loss: 1.3851983547210693
TA-VAAL iteration: 2300 vae_loss: 1.6345627307891846 dsc_loss: 1.38883376121521
TA-VAAL iteration: 2400 vae_loss: 1.628918170928955 dsc_loss: 1.3874239921569824
TA-VAAL iteration: 2500 vae_loss: 1.5378623008728027 dsc_loss: 1.383885383605957
TA-VAAL iteration: 2600 vae_loss: 1.61670982837677 dsc_loss: 1.3855562210083008
TA-VAAL iteration: 2700 vae_loss: 1.6679654121398926 dsc_loss: 1.3905701637268066
TA-VAAL iteration: 2800 vae_loss: 1.651130199432373 dsc_loss: 1.3855845928192139
TA-VAAL iteration: 2900 vae_loss: 1.592896580696106 dsc_loss: 1.3820087909698486
TA-VAAL iteration: 3000 vae_loss: 1.7907401323318481 dsc_loss: 1.3948675394058228
TA-VAAL iteration: 3100 vae_loss: 1.6358444690704346 dsc_loss: 1.385373830795288
TA-VAAL iteration: 3200 vae_loss: 1.686095118522644 dsc_loss: 1.3844248056411743
TA-VAAL iteration: 3300 vae_loss: 1.6423734426498413 dsc_loss: 1.3844159841537476
TA-VAAL iteration: 3400 vae_loss: 1.74784517288208 dsc_loss: 1.3927133083343506
TA-VAAL iteration: 3500 vae_loss: 1.7065316438674927 dsc_loss: 1.3807625770568848
TA-VAAL iteration: 3600 vae_loss: 1.7021318674087524 dsc_loss: 1.3841004371643066
TA-VAAL iteration: 3700 vae_loss: 1.6243451833724976 dsc_loss: 1.3839499950408936
TA-VAAL iteration: 3800 vae_loss: 1.7408015727996826 dsc_loss: 1.3849310874938965
TA-VAAL iteration: 3900 vae_loss: 1.6767529249191284 dsc_loss: 1.3844372034072876
TA-VAAL iteration: 4000 vae_loss: 1.767669916152954 dsc_loss: 1.3887696266174316
TA-VAAL iteration: 4100 vae_loss: 1.7340847253799438 dsc_loss: 1.3809144496917725
TA-VAAL iteration: 4200 vae_loss: 1.7398757934570312 dsc_loss: 1.386418104171753
TA-VAAL iteration: 4300 vae_loss: 1.8358893394470215 dsc_loss: 1.3942657709121704
TA-VAAL iteration: 4400 vae_loss: 1.6563639640808105 dsc_loss: 1.3702380657196045
TA-VAAL iteration: 4500 vae_loss: 1.7516460418701172 dsc_loss: 1.3873813152313232
TA-VAAL iteration: 4600 vae_loss: 1.7713088989257812 dsc_loss: 1.3861461877822876
TA-VAAL iteration: 4700 vae_loss: 1.713073968887329 dsc_loss: 1.3879563808441162
TA-VAAL iteration: 4800 vae_loss: 1.6830832958221436 dsc_loss: 1.3777923583984375
TA-VAAL iteration: 4900 vae_loss: 1.7407286167144775 dsc_loss: 1.3897396326065063
TA-VAAL iteration: 5000 vae_loss: 1.731248378753662 dsc_loss: 1.38417387008667
TA-VAAL iteration: 5100 vae_loss: 1.7173711061477661 dsc_loss: 1.3866949081420898
TA-VAAL iteration: 5200 vae_loss: 1.6739948987960815 dsc_loss: 1.389458417892456
TA-VAAL iteration: 5300 vae_loss: 1.804187297821045 dsc_loss: 1.3917458057403564
TA-VAAL iteration: 5400 vae_loss: 1.7791160345077515 dsc_loss: 1.3815487623214722
TA-VAAL iteration: 5500 vae_loss: 1.804713487625122 dsc_loss: 1.3842979669570923
TA-VAAL iteration: 5600 vae_loss: 1.8658514022827148 dsc_loss: 1.389699935913086
TA-VAAL iteration: 5700 vae_loss: 1.8084821701049805 dsc_loss: 1.3846049308776855
TA-VAAL iteration: 5800 vae_loss: 1.8071613311767578 dsc_loss: 1.3854402303695679
TA-VAAL iteration: 5900 vae_loss: 1.7676886320114136 dsc_loss: 1.3757963180541992
TA-VAAL iteration: 6000 vae_loss: 1.8774902820587158 dsc_loss: 1.3852341175079346
TA-VAAL iteration: 6100 vae_loss: 1.832707166671753 dsc_loss: 1.3877129554748535
TA-VAAL iteration: 6200 vae_loss: 1.8189849853515625 dsc_loss: 1.3865320682525635
TA-VAAL iteration: 6300 vae_loss: 1.7745418548583984 dsc_loss: 1.368496060371399
TA-VAAL iteration: 6400 vae_loss: 1.885243535041809 dsc_loss: 1.4041061401367188
TA-VAAL iteration: 6500 vae_loss: 1.7401947975158691 dsc_loss: 1.390390157699585
TA-VAAL iteration: 6600 vae_loss: 1.784698247909546 dsc_loss: 1.3822963237762451
TA-VAAL iteration: 6700 vae_loss: 1.6945044994354248 dsc_loss: 1.3778955936431885
TA-VAAL iteration: 6800 vae_loss: 1.8499135971069336 dsc_loss: 1.395756721496582
TA-VAAL iteration: 6900 vae_loss: 1.7453405857086182 dsc_loss: 1.3850959539413452
TA-VAAL iteration: 7000 vae_loss: 1.7406328916549683 dsc_loss: 1.3874096870422363
TA-VAAL iteration: 7100 vae_loss: 1.74632728099823 dsc_loss: 1.3848307132720947
TA-VAAL iteration: 7200 vae_loss: 1.764927625656128 dsc_loss: 1.388249397277832
TA-VAAL iteration: 7300 vae_loss: 1.7803502082824707 dsc_loss: 1.3828524351119995
TA-VAAL iteration: 7400 vae_loss: 1.725898027420044 dsc_loss: 1.382044792175293
1400 105708 229 107106
>> Train vae and task model
epoch 0: train loss is  1.62548
epoch 10: train loss is  1.47835
epoch 20: train loss is  1.36450
epoch 30: train loss is  1.36015
epoch 40: train loss is  1.29845
epoch 50: train loss is  1.23821
epoch 60: train loss is  1.25331
epoch 70: train loss is  1.24933
epoch 80: train loss is  1.23441
epoch 90: train loss is  1.22934
epoch 100: train loss is  1.19316
epoch 110: train loss is  1.18940
epoch 120: train loss is  1.13941
 >> Test Model
Cycle 7/10 || labeled data size 1400, test loss(MAE) =  0.83297
TA-VAAL iteration: 0 vae_loss: 1.7874712944030762 dsc_loss: 1.3912469148635864
TA-VAAL iteration: 10 vae_loss: 2.0469374656677246 dsc_loss: 1.4260106086730957
TA-VAAL iteration: 20 vae_loss: 2.0706090927124023 dsc_loss: 1.4372464418411255
TA-VAAL iteration: 30 vae_loss: 1.78187894821167 dsc_loss: 1.3704458475112915
TA-VAAL iteration: 40 vae_loss: 2.1785378456115723 dsc_loss: 1.3825395107269287
TA-VAAL iteration: 50 vae_loss: 2.1664881706237793 dsc_loss: 1.407083511352539
TA-VAAL iteration: 60 vae_loss: 2.0274882316589355 dsc_loss: 1.4222321510314941
TA-VAAL iteration: 70 vae_loss: 1.7781856060028076 dsc_loss: 1.3937640190124512
TA-VAAL iteration: 80 vae_loss: 1.8424808979034424 dsc_loss: 1.4265921115875244
TA-VAAL iteration: 90 vae_loss: 1.799190878868103 dsc_loss: 1.3996533155441284
TA-VAAL iteration: 100 vae_loss: 1.630412220954895 dsc_loss: 1.3866369724273682
TA-VAAL iteration: 200 vae_loss: 1.6480754613876343 dsc_loss: 1.4499294757843018
TA-VAAL iteration: 300 vae_loss: 1.71384596824646 dsc_loss: 1.3779172897338867
TA-VAAL iteration: 400 vae_loss: 1.7237913608551025 dsc_loss: 1.4211721420288086
TA-VAAL iteration: 500 vae_loss: 1.659368634223938 dsc_loss: 1.41501784324646
TA-VAAL iteration: 600 vae_loss: 1.6127564907073975 dsc_loss: 1.3825621604919434
TA-VAAL iteration: 700 vae_loss: 1.8583862781524658 dsc_loss: 1.3831316232681274
TA-VAAL iteration: 800 vae_loss: 1.5939149856567383 dsc_loss: 1.3955698013305664
TA-VAAL iteration: 900 vae_loss: 1.816972017288208 dsc_loss: 1.3946940898895264
TA-VAAL iteration: 1000 vae_loss: 1.651480793952942 dsc_loss: 1.3979777097702026
TA-VAAL iteration: 1100 vae_loss: 1.5082676410675049 dsc_loss: 1.387281894683838
TA-VAAL iteration: 1200 vae_loss: 1.5534380674362183 dsc_loss: 1.3910787105560303
TA-VAAL iteration: 1300 vae_loss: 1.4376790523529053 dsc_loss: 1.4116160869598389
TA-VAAL iteration: 1400 vae_loss: 1.7170838117599487 dsc_loss: 1.3760364055633545
TA-VAAL iteration: 1500 vae_loss: 1.620140552520752 dsc_loss: 1.3999254703521729
TA-VAAL iteration: 1600 vae_loss: 1.7201669216156006 dsc_loss: 1.422158122062683
TA-VAAL iteration: 1700 vae_loss: 1.5630061626434326 dsc_loss: 1.3802528381347656
TA-VAAL iteration: 1800 vae_loss: 1.8741443157196045 dsc_loss: 1.399547815322876
TA-VAAL iteration: 1900 vae_loss: 1.6644471883773804 dsc_loss: 1.3887454271316528
TA-VAAL iteration: 2000 vae_loss: 1.7561936378479004 dsc_loss: 1.391545295715332
TA-VAAL iteration: 2100 vae_loss: 1.511174201965332 dsc_loss: 1.3877370357513428
TA-VAAL iteration: 2200 vae_loss: 1.6815719604492188 dsc_loss: 1.3895621299743652
TA-VAAL iteration: 2300 vae_loss: 1.6543736457824707 dsc_loss: 1.381961464881897
TA-VAAL iteration: 2400 vae_loss: 1.6353983879089355 dsc_loss: 1.3887807130813599
TA-VAAL iteration: 2500 vae_loss: 1.6881940364837646 dsc_loss: 1.3988993167877197
TA-VAAL iteration: 2600 vae_loss: 1.5240123271942139 dsc_loss: 1.3895103931427002
TA-VAAL iteration: 2700 vae_loss: 1.5504494905471802 dsc_loss: 1.4069923162460327
TA-VAAL iteration: 2800 vae_loss: 1.4879924058914185 dsc_loss: 1.3885343074798584
TA-VAAL iteration: 2900 vae_loss: 1.5470502376556396 dsc_loss: 1.3885966539382935
TA-VAAL iteration: 3000 vae_loss: 1.7370835542678833 dsc_loss: 1.3840395212173462
TA-VAAL iteration: 3100 vae_loss: 1.6729421615600586 dsc_loss: 1.3807740211486816
TA-VAAL iteration: 3200 vae_loss: 1.6278951168060303 dsc_loss: 1.3892955780029297
TA-VAAL iteration: 3300 vae_loss: 1.7671552896499634 dsc_loss: 1.3904550075531006
TA-VAAL iteration: 3400 vae_loss: 1.6689509153366089 dsc_loss: 1.3856604099273682
TA-VAAL iteration: 3500 vae_loss: 1.635830283164978 dsc_loss: 1.3872499465942383
TA-VAAL iteration: 3600 vae_loss: 1.632946252822876 dsc_loss: 1.3905432224273682
TA-VAAL iteration: 3700 vae_loss: 1.6006336212158203 dsc_loss: 1.3942313194274902
TA-VAAL iteration: 3800 vae_loss: 1.560382604598999 dsc_loss: 1.3965507745742798
TA-VAAL iteration: 3900 vae_loss: 1.555418610572815 dsc_loss: 1.38871431350708
TA-VAAL iteration: 4000 vae_loss: 1.6250081062316895 dsc_loss: 1.384387493133545
TA-VAAL iteration: 4100 vae_loss: 1.6184977293014526 dsc_loss: 1.3872616291046143
TA-VAAL iteration: 4200 vae_loss: 1.7250473499298096 dsc_loss: 1.3879914283752441
TA-VAAL iteration: 4300 vae_loss: 1.6034902334213257 dsc_loss: 1.3860256671905518
TA-VAAL iteration: 4400 vae_loss: 1.6208724975585938 dsc_loss: 1.389897346496582
TA-VAAL iteration: 4500 vae_loss: 1.6854825019836426 dsc_loss: 1.387024998664856
TA-VAAL iteration: 4600 vae_loss: 1.62908136844635 dsc_loss: 1.3858985900878906
TA-VAAL iteration: 4700 vae_loss: 1.6316190958023071 dsc_loss: 1.3829799890518188
TA-VAAL iteration: 4800 vae_loss: 1.6335927248001099 dsc_loss: 1.3889268636703491
TA-VAAL iteration: 4900 vae_loss: 1.5546661615371704 dsc_loss: 1.3909814357757568
TA-VAAL iteration: 5000 vae_loss: 1.5704842805862427 dsc_loss: 1.3874410390853882
TA-VAAL iteration: 5100 vae_loss: 1.6162515878677368 dsc_loss: 1.3860926628112793
TA-VAAL iteration: 5200 vae_loss: 1.6121569871902466 dsc_loss: 1.3860986232757568
TA-VAAL iteration: 5300 vae_loss: 1.6897642612457275 dsc_loss: 1.3869987726211548
TA-VAAL iteration: 5400 vae_loss: 1.58670973777771 dsc_loss: 1.38665771484375
TA-VAAL iteration: 5500 vae_loss: 1.637645959854126 dsc_loss: 1.3891963958740234
TA-VAAL iteration: 5600 vae_loss: 1.6594300270080566 dsc_loss: 1.3909012079238892
TA-VAAL iteration: 5700 vae_loss: 1.6429601907730103 dsc_loss: 1.388000726699829
TA-VAAL iteration: 5800 vae_loss: 1.5711051225662231 dsc_loss: 1.3820507526397705
TA-VAAL iteration: 5900 vae_loss: 1.5590229034423828 dsc_loss: 1.395828366279602
TA-VAAL iteration: 6000 vae_loss: 1.5843126773834229 dsc_loss: 1.3875458240509033
TA-VAAL iteration: 6100 vae_loss: 1.567440390586853 dsc_loss: 1.385277509689331
TA-VAAL iteration: 6200 vae_loss: 1.605973720550537 dsc_loss: 1.3881365060806274
TA-VAAL iteration: 6300 vae_loss: 1.6224521398544312 dsc_loss: 1.3844962120056152
TA-VAAL iteration: 6400 vae_loss: 1.6377382278442383 dsc_loss: 1.3872694969177246
TA-VAAL iteration: 6500 vae_loss: 1.596860408782959 dsc_loss: 1.3862881660461426
TA-VAAL iteration: 6600 vae_loss: 1.6048312187194824 dsc_loss: 1.3889925479888916
TA-VAAL iteration: 6700 vae_loss: 1.6163015365600586 dsc_loss: 1.3872942924499512
TA-VAAL iteration: 6800 vae_loss: 1.6140557527542114 dsc_loss: 1.3886404037475586
TA-VAAL iteration: 6900 vae_loss: 1.6293327808380127 dsc_loss: 1.3832385540008545
TA-VAAL iteration: 7000 vae_loss: 1.5605459213256836 dsc_loss: 1.3886219263076782
TA-VAAL iteration: 7100 vae_loss: 1.5797024965286255 dsc_loss: 1.3890049457550049
TA-VAAL iteration: 7200 vae_loss: 1.5601146221160889 dsc_loss: 1.386852741241455
TA-VAAL iteration: 7300 vae_loss: 1.6159400939941406 dsc_loss: 1.3884527683258057
TA-VAAL iteration: 7400 vae_loss: 1.5330909490585327 dsc_loss: 1.3878121376037598
TA-VAAL iteration: 7500 vae_loss: 1.6159085035324097 dsc_loss: 1.387601613998413
TA-VAAL iteration: 7600 vae_loss: 1.5301071405410767 dsc_loss: 1.3834354877471924
TA-VAAL iteration: 7700 vae_loss: 1.6117885112762451 dsc_loss: 1.386502981185913
1600 105508 229 107106
>> Train vae and task model
epoch 0: train loss is  1.61454
epoch 10: train loss is  1.48374
epoch 20: train loss is  1.38209
epoch 30: train loss is  1.32181
epoch 40: train loss is  1.28086
epoch 50: train loss is  1.27605
epoch 60: train loss is  1.22738
epoch 70: train loss is  1.24017
epoch 80: train loss is  1.19397
epoch 90: train loss is  1.21833
epoch 100: train loss is  1.19045
epoch 110: train loss is  1.17295
epoch 120: train loss is  1.16034
 >> Test Model
Cycle 8/10 || labeled data size 1600, test loss(MAE) =  0.83297
TA-VAAL iteration: 0 vae_loss: 1.834762692451477 dsc_loss: 1.387021541595459
TA-VAAL iteration: 10 vae_loss: 1.5804486274719238 dsc_loss: 1.3886208534240723
TA-VAAL iteration: 20 vae_loss: 1.3710851669311523 dsc_loss: 1.4021104574203491
TA-VAAL iteration: 30 vae_loss: 1.5258893966674805 dsc_loss: 1.3996448516845703
TA-VAAL iteration: 40 vae_loss: 1.8401825428009033 dsc_loss: 1.402360439300537
TA-VAAL iteration: 50 vae_loss: 1.6047519445419312 dsc_loss: 1.4140803813934326
TA-VAAL iteration: 60 vae_loss: 1.8691943883895874 dsc_loss: 1.3855277299880981
TA-VAAL iteration: 70 vae_loss: 1.861371397972107 dsc_loss: 1.4165806770324707
TA-VAAL iteration: 80 vae_loss: 1.7548621892929077 dsc_loss: 1.3798599243164062
TA-VAAL iteration: 90 vae_loss: 1.7835217714309692 dsc_loss: 1.3837374448776245
TA-VAAL iteration: 100 vae_loss: 1.6930394172668457 dsc_loss: 1.411719799041748
TA-VAAL iteration: 200 vae_loss: 1.6141468286514282 dsc_loss: 1.3924696445465088
TA-VAAL iteration: 300 vae_loss: 1.5814685821533203 dsc_loss: 1.3777930736541748
TA-VAAL iteration: 400 vae_loss: 1.4848129749298096 dsc_loss: 1.3899974822998047
TA-VAAL iteration: 500 vae_loss: 1.4340969324111938 dsc_loss: 1.4069921970367432
TA-VAAL iteration: 600 vae_loss: 1.4938222169876099 dsc_loss: 1.3938870429992676
TA-VAAL iteration: 700 vae_loss: 1.4881523847579956 dsc_loss: 1.3706212043762207
TA-VAAL iteration: 800 vae_loss: 1.4937065839767456 dsc_loss: 1.3792200088500977
TA-VAAL iteration: 900 vae_loss: 1.4769866466522217 dsc_loss: 1.3930034637451172
TA-VAAL iteration: 1000 vae_loss: 1.5125802755355835 dsc_loss: 1.3802084922790527
TA-VAAL iteration: 1100 vae_loss: 1.5092267990112305 dsc_loss: 1.3882989883422852
TA-VAAL iteration: 1200 vae_loss: 1.5146381855010986 dsc_loss: 1.390586256980896
TA-VAAL iteration: 1300 vae_loss: 1.6514023542404175 dsc_loss: 1.4041006565093994
TA-VAAL iteration: 1400 vae_loss: 1.6873548030853271 dsc_loss: 1.390482783317566
TA-VAAL iteration: 1500 vae_loss: 1.6030142307281494 dsc_loss: 1.3885549306869507
TA-VAAL iteration: 1600 vae_loss: 1.6953691244125366 dsc_loss: 1.3749735355377197
TA-VAAL iteration: 1700 vae_loss: 1.7867257595062256 dsc_loss: 1.393622875213623
TA-VAAL iteration: 1800 vae_loss: 1.7828214168548584 dsc_loss: 1.3682032823562622
TA-VAAL iteration: 1900 vae_loss: 1.6966230869293213 dsc_loss: 1.3851783275604248
TA-VAAL iteration: 2000 vae_loss: 1.6161699295043945 dsc_loss: 1.3869330883026123
TA-VAAL iteration: 2100 vae_loss: 1.664756178855896 dsc_loss: 1.38728666305542
TA-VAAL iteration: 2200 vae_loss: 1.7108052968978882 dsc_loss: 1.3965696096420288
TA-VAAL iteration: 2300 vae_loss: 1.6958794593811035 dsc_loss: 1.3735743761062622
TA-VAAL iteration: 2400 vae_loss: 1.7355268001556396 dsc_loss: 1.3787965774536133
TA-VAAL iteration: 2500 vae_loss: 1.7618296146392822 dsc_loss: 1.3832480907440186
TA-VAAL iteration: 2600 vae_loss: 1.759263038635254 dsc_loss: 1.3943969011306763
TA-VAAL iteration: 2700 vae_loss: 1.7416839599609375 dsc_loss: 1.3912206888198853
TA-VAAL iteration: 2800 vae_loss: 2.033618450164795 dsc_loss: 1.394392490386963
TA-VAAL iteration: 2900 vae_loss: 1.9457628726959229 dsc_loss: 1.3734612464904785
TA-VAAL iteration: 3000 vae_loss: 1.6676021814346313 dsc_loss: 1.3478809595108032
TA-VAAL iteration: 3100 vae_loss: 1.932584524154663 dsc_loss: 1.3781318664550781
TA-VAAL iteration: 3200 vae_loss: 1.9570128917694092 dsc_loss: 1.3895124197006226
TA-VAAL iteration: 3300 vae_loss: 1.9105243682861328 dsc_loss: 1.3596802949905396
TA-VAAL iteration: 3400 vae_loss: 1.9339083433151245 dsc_loss: 1.350722074508667
TA-VAAL iteration: 3500 vae_loss: 2.048220157623291 dsc_loss: 1.3899738788604736
TA-VAAL iteration: 3600 vae_loss: 1.843538522720337 dsc_loss: 1.3531122207641602
TA-VAAL iteration: 3700 vae_loss: 1.8862175941467285 dsc_loss: 1.3777039051055908
TA-VAAL iteration: 3800 vae_loss: 1.8588200807571411 dsc_loss: 1.3913209438323975
TA-VAAL iteration: 3900 vae_loss: 1.8419278860092163 dsc_loss: 1.3878819942474365
TA-VAAL iteration: 4000 vae_loss: 1.9543712139129639 dsc_loss: 1.3914158344268799
TA-VAAL iteration: 4100 vae_loss: 1.935948371887207 dsc_loss: 1.3927022218704224
TA-VAAL iteration: 4200 vae_loss: 1.7078875303268433 dsc_loss: 1.3710787296295166
TA-VAAL iteration: 4300 vae_loss: 1.8634370565414429 dsc_loss: 1.3894695043563843
TA-VAAL iteration: 4400 vae_loss: 2.0319368839263916 dsc_loss: 1.4209493398666382
TA-VAAL iteration: 4500 vae_loss: 1.8305339813232422 dsc_loss: 1.3976221084594727
TA-VAAL iteration: 4600 vae_loss: 1.9691280126571655 dsc_loss: 1.3463366031646729
TA-VAAL iteration: 4700 vae_loss: 1.9414966106414795 dsc_loss: 1.4170007705688477
TA-VAAL iteration: 4800 vae_loss: 1.9161418676376343 dsc_loss: 1.3836172819137573
TA-VAAL iteration: 4900 vae_loss: 2.043490409851074 dsc_loss: 1.3750354051589966
TA-VAAL iteration: 5000 vae_loss: 2.055969715118408 dsc_loss: 1.3428003787994385
TA-VAAL iteration: 5100 vae_loss: 2.059938669204712 dsc_loss: 1.3268680572509766
TA-VAAL iteration: 5200 vae_loss: 2.2396352291107178 dsc_loss: 1.3715705871582031
TA-VAAL iteration: 5300 vae_loss: 1.8932181596755981 dsc_loss: 1.3933207988739014
TA-VAAL iteration: 5400 vae_loss: 1.9867757558822632 dsc_loss: 1.3645708560943604
TA-VAAL iteration: 5500 vae_loss: 1.9611574411392212 dsc_loss: 1.3580026626586914
TA-VAAL iteration: 5600 vae_loss: 1.8651344776153564 dsc_loss: 1.4031023979187012
TA-VAAL iteration: 5700 vae_loss: 2.134385347366333 dsc_loss: 1.3785006999969482
TA-VAAL iteration: 5800 vae_loss: 2.203249216079712 dsc_loss: 1.3868142366409302
TA-VAAL iteration: 5900 vae_loss: 2.1110856533050537 dsc_loss: 1.4398932456970215
TA-VAAL iteration: 6000 vae_loss: 1.9843937158584595 dsc_loss: 1.3968507051467896
TA-VAAL iteration: 6100 vae_loss: 1.9368228912353516 dsc_loss: 1.3752329349517822
TA-VAAL iteration: 6200 vae_loss: 2.043701410293579 dsc_loss: 1.3956623077392578
TA-VAAL iteration: 6300 vae_loss: 1.9951145648956299 dsc_loss: 1.3432648181915283
TA-VAAL iteration: 6400 vae_loss: 2.0493242740631104 dsc_loss: 1.368406057357788
TA-VAAL iteration: 6500 vae_loss: 2.009406089782715 dsc_loss: 1.376844882965088
TA-VAAL iteration: 6600 vae_loss: 2.125584125518799 dsc_loss: 1.3571056127548218
TA-VAAL iteration: 6700 vae_loss: 2.374688148498535 dsc_loss: 1.3855783939361572
TA-VAAL iteration: 6800 vae_loss: 2.306203842163086 dsc_loss: 1.3916913270950317
TA-VAAL iteration: 6900 vae_loss: 2.0380592346191406 dsc_loss: 1.347000241279602
TA-VAAL iteration: 7000 vae_loss: 1.9833178520202637 dsc_loss: 1.4004658460617065
TA-VAAL iteration: 7100 vae_loss: 2.0526816844940186 dsc_loss: 1.4011800289154053
TA-VAAL iteration: 7200 vae_loss: 2.039393901824951 dsc_loss: 1.364689588546753
TA-VAAL iteration: 7300 vae_loss: 2.211059808731079 dsc_loss: 1.3814303874969482
TA-VAAL iteration: 7400 vae_loss: 2.1758997440338135 dsc_loss: 1.3899670839309692
TA-VAAL iteration: 7500 vae_loss: 1.8508590459823608 dsc_loss: 1.3809854984283447
TA-VAAL iteration: 7600 vae_loss: 1.9679758548736572 dsc_loss: 1.4129382371902466
TA-VAAL iteration: 7700 vae_loss: 2.3200063705444336 dsc_loss: 1.4010645151138306
TA-VAAL iteration: 7800 vae_loss: 2.1511805057525635 dsc_loss: 1.3684009313583374
TA-VAAL iteration: 7900 vae_loss: 2.212923526763916 dsc_loss: 1.384675145149231
1800 105308 229 107106
>> Train vae and task model
epoch 0: train loss is  1.66100
epoch 10: train loss is  1.23808
epoch 20: train loss is  1.14066
epoch 30: train loss is  1.13439
epoch 40: train loss is  1.08495
epoch 50: train loss is  1.07438
epoch 60: train loss is  1.02650
epoch 70: train loss is  1.03045
epoch 80: train loss is  1.02997
epoch 90: train loss is  1.02729
epoch 100: train loss is  0.96587
epoch 110: train loss is  1.05708
epoch 120: train loss is  0.95627
 >> Test Model
Cycle 9/10 || labeled data size 1800, test loss(MAE) =  0.58632
TA-VAAL iteration: 0 vae_loss: 1.7793028354644775 dsc_loss: 1.3982033729553223
TA-VAAL iteration: 10 vae_loss: 1.8624211549758911 dsc_loss: 1.3977770805358887
TA-VAAL iteration: 20 vae_loss: 1.6415772438049316 dsc_loss: 1.332045555114746
TA-VAAL iteration: 30 vae_loss: 1.7468422651290894 dsc_loss: 1.3786622285842896
TA-VAAL iteration: 40 vae_loss: 1.833648920059204 dsc_loss: 1.4114956855773926
TA-VAAL iteration: 50 vae_loss: 1.8831989765167236 dsc_loss: 1.3732503652572632
TA-VAAL iteration: 60 vae_loss: 1.7098052501678467 dsc_loss: 1.466341257095337
TA-VAAL iteration: 70 vae_loss: 1.7179553508758545 dsc_loss: 1.3866790533065796
TA-VAAL iteration: 80 vae_loss: 1.9147554636001587 dsc_loss: 1.4309186935424805
TA-VAAL iteration: 90 vae_loss: 1.570090889930725 dsc_loss: 1.433635950088501
TA-VAAL iteration: 100 vae_loss: 1.6770837306976318 dsc_loss: 1.3761929273605347
TA-VAAL iteration: 200 vae_loss: 1.6509629487991333 dsc_loss: 1.4383175373077393
TA-VAAL iteration: 300 vae_loss: 1.6115336418151855 dsc_loss: 1.3733561038970947
TA-VAAL iteration: 400 vae_loss: 1.6586730480194092 dsc_loss: 1.3904271125793457
TA-VAAL iteration: 500 vae_loss: 1.5662883520126343 dsc_loss: 1.3879477977752686
TA-VAAL iteration: 600 vae_loss: 1.6746888160705566 dsc_loss: 1.362637996673584
TA-VAAL iteration: 700 vae_loss: 1.6311376094818115 dsc_loss: 1.4014378786087036
TA-VAAL iteration: 800 vae_loss: 1.4436579942703247 dsc_loss: 1.404000997543335
TA-VAAL iteration: 900 vae_loss: 1.6857235431671143 dsc_loss: 1.403433084487915
TA-VAAL iteration: 1000 vae_loss: 1.7692229747772217 dsc_loss: 1.4198414087295532
TA-VAAL iteration: 1100 vae_loss: 1.664324164390564 dsc_loss: 1.42055344581604
TA-VAAL iteration: 1200 vae_loss: 1.7127435207366943 dsc_loss: 1.3862285614013672
TA-VAAL iteration: 1300 vae_loss: 1.6626441478729248 dsc_loss: 1.4072009325027466
TA-VAAL iteration: 1400 vae_loss: 1.6076644659042358 dsc_loss: 1.3939303159713745
TA-VAAL iteration: 1500 vae_loss: 1.451416254043579 dsc_loss: 1.3769749402999878
TA-VAAL iteration: 1600 vae_loss: 1.5290113687515259 dsc_loss: 1.380641222000122
TA-VAAL iteration: 1700 vae_loss: 1.5498074293136597 dsc_loss: 1.3809309005737305
TA-VAAL iteration: 1800 vae_loss: 1.651179552078247 dsc_loss: 1.3856385946273804
TA-VAAL iteration: 1900 vae_loss: 1.7316362857818604 dsc_loss: 1.3838814496994019
TA-VAAL iteration: 2000 vae_loss: 1.6325907707214355 dsc_loss: 1.386375069618225
TA-VAAL iteration: 2100 vae_loss: 1.643226981163025 dsc_loss: 1.392000436782837
TA-VAAL iteration: 2200 vae_loss: 1.6074122190475464 dsc_loss: 1.3859553337097168
TA-VAAL iteration: 2300 vae_loss: 1.6176892518997192 dsc_loss: 1.394931435585022
TA-VAAL iteration: 2400 vae_loss: 1.5237178802490234 dsc_loss: 1.394921064376831
TA-VAAL iteration: 2500 vae_loss: 1.5449453592300415 dsc_loss: 1.3884605169296265
TA-VAAL iteration: 2600 vae_loss: 1.5948054790496826 dsc_loss: 1.3775804042816162
TA-VAAL iteration: 2700 vae_loss: 1.6552902460098267 dsc_loss: 1.3837237358093262
TA-VAAL iteration: 2800 vae_loss: 1.686194896697998 dsc_loss: 1.3859667778015137
TA-VAAL iteration: 2900 vae_loss: 1.6297550201416016 dsc_loss: 1.3841650485992432
TA-VAAL iteration: 3000 vae_loss: 1.7880417108535767 dsc_loss: 1.3907182216644287
TA-VAAL iteration: 3100 vae_loss: 1.6431529521942139 dsc_loss: 1.3880653381347656
TA-VAAL iteration: 3200 vae_loss: 1.57953941822052 dsc_loss: 1.4016083478927612
TA-VAAL iteration: 3300 vae_loss: 1.5615144968032837 dsc_loss: 1.3918867111206055
TA-VAAL iteration: 3400 vae_loss: 1.630704641342163 dsc_loss: 1.387062668800354
TA-VAAL iteration: 3500 vae_loss: 1.6190112829208374 dsc_loss: 1.3662567138671875
TA-VAAL iteration: 3600 vae_loss: 1.6787880659103394 dsc_loss: 1.3812439441680908
TA-VAAL iteration: 3700 vae_loss: 1.697473168373108 dsc_loss: 1.3874074220657349
TA-VAAL iteration: 3800 vae_loss: 1.668892741203308 dsc_loss: 1.3830454349517822
TA-VAAL iteration: 3900 vae_loss: 1.7612310647964478 dsc_loss: 1.3763099908828735
TA-VAAL iteration: 4000 vae_loss: 1.6546313762664795 dsc_loss: 1.3892910480499268
TA-VAAL iteration: 4100 vae_loss: 1.6534239053726196 dsc_loss: 1.4122841358184814
TA-VAAL iteration: 4200 vae_loss: 1.623981237411499 dsc_loss: 1.388405203819275
TA-VAAL iteration: 4300 vae_loss: 1.7152132987976074 dsc_loss: 1.3837389945983887
TA-VAAL iteration: 4400 vae_loss: 1.5967817306518555 dsc_loss: 1.3701097965240479
TA-VAAL iteration: 4500 vae_loss: 1.7281990051269531 dsc_loss: 1.3797860145568848
TA-VAAL iteration: 4600 vae_loss: 1.7254579067230225 dsc_loss: 1.3834480047225952
TA-VAAL iteration: 4700 vae_loss: 1.7189843654632568 dsc_loss: 1.389738917350769
TA-VAAL iteration: 4800 vae_loss: 1.757705569267273 dsc_loss: 1.3716660737991333
TA-VAAL iteration: 4900 vae_loss: 1.7329941987991333 dsc_loss: 1.3787716627120972
TA-VAAL iteration: 5000 vae_loss: 1.7407376766204834 dsc_loss: 1.3990399837493896
TA-VAAL iteration: 5100 vae_loss: 1.6541948318481445 dsc_loss: 1.3854901790618896
TA-VAAL iteration: 5200 vae_loss: 1.6984057426452637 dsc_loss: 1.3981354236602783
TA-VAAL iteration: 5300 vae_loss: 1.6760042905807495 dsc_loss: 1.3930082321166992
TA-VAAL iteration: 5400 vae_loss: 1.7148334980010986 dsc_loss: 1.3868751525878906
TA-VAAL iteration: 5500 vae_loss: 1.7939039468765259 dsc_loss: 1.363943099975586
TA-VAAL iteration: 5600 vae_loss: 1.7993371486663818 dsc_loss: 1.3802930116653442
TA-VAAL iteration: 5700 vae_loss: 1.7880947589874268 dsc_loss: 1.388677716255188
TA-VAAL iteration: 5800 vae_loss: 1.7991561889648438 dsc_loss: 1.3848376274108887
TA-VAAL iteration: 5900 vae_loss: 1.8114840984344482 dsc_loss: 1.3798129558563232
TA-VAAL iteration: 6000 vae_loss: 1.784186840057373 dsc_loss: 1.383976936340332
TA-VAAL iteration: 6100 vae_loss: 1.7750588655471802 dsc_loss: 1.4108803272247314
TA-VAAL iteration: 6200 vae_loss: 1.7247045040130615 dsc_loss: 1.3894978761672974
TA-VAAL iteration: 6300 vae_loss: 1.759941816329956 dsc_loss: 1.3841874599456787
TA-VAAL iteration: 6400 vae_loss: 1.8706283569335938 dsc_loss: 1.3671280145645142
TA-VAAL iteration: 6500 vae_loss: 1.7966591119766235 dsc_loss: 1.3798182010650635
TA-VAAL iteration: 6600 vae_loss: 1.7497793436050415 dsc_loss: 1.3902456760406494
TA-VAAL iteration: 6700 vae_loss: 1.7316755056381226 dsc_loss: 1.3840055465698242
TA-VAAL iteration: 6800 vae_loss: 1.8818442821502686 dsc_loss: 1.3789639472961426
TA-VAAL iteration: 6900 vae_loss: 1.7615305185317993 dsc_loss: 1.3827435970306396
TA-VAAL iteration: 7000 vae_loss: 1.7984362840652466 dsc_loss: 1.4127938747406006
TA-VAAL iteration: 7100 vae_loss: 1.8042385578155518 dsc_loss: 1.3912687301635742
TA-VAAL iteration: 7200 vae_loss: 1.8629387617111206 dsc_loss: 1.3860701322555542
TA-VAAL iteration: 7300 vae_loss: 1.8005015850067139 dsc_loss: 1.358994722366333
TA-VAAL iteration: 7400 vae_loss: 1.8730249404907227 dsc_loss: 1.3833787441253662
TA-VAAL iteration: 7500 vae_loss: 1.8280506134033203 dsc_loss: 1.3745399713516235
TA-VAAL iteration: 7600 vae_loss: 1.8610529899597168 dsc_loss: 1.3923892974853516
TA-VAAL iteration: 7700 vae_loss: 1.8858485221862793 dsc_loss: 1.3724459409713745
TA-VAAL iteration: 7800 vae_loss: 1.8551194667816162 dsc_loss: 1.3757051229476929
TA-VAAL iteration: 7900 vae_loss: 1.8756036758422852 dsc_loss: 1.3998520374298096
TA-VAAL iteration: 8000 vae_loss: 1.896506428718567 dsc_loss: 1.381883144378662
TA-VAAL iteration: 8100 vae_loss: 1.8747459650039673 dsc_loss: 1.3972339630126953
TA-VAAL iteration: 8200 vae_loss: 1.8744945526123047 dsc_loss: 1.3944371938705444
2000 105108 71 107106
>> Train vae and task model
epoch 0: train loss is  1.65819
epoch 10: train loss is  1.48660
epoch 20: train loss is  1.41369
epoch 30: train loss is  1.37576
epoch 40: train loss is  1.36399
epoch 50: train loss is  1.30096
epoch 60: train loss is  1.31680
epoch 70: train loss is  1.31106
epoch 80: train loss is  1.26321
epoch 90: train loss is  1.27043
epoch 100: train loss is  1.25914
epoch 110: train loss is  1.25552
epoch 120: train loss is  1.24549
 >> Test Model
Cycle 10/10 || labeled data size 2000, test loss(MAE) =  0.83297
Finished.
>> Train vae and task model
epoch 0: train loss is  1.50205
epoch 10: train loss is  1.46157
epoch 20: train loss is  1.43813
epoch 30: train loss is  1.50434
epoch 40: train loss is  1.27829
epoch 50: train loss is  1.21287
epoch 60: train loss is  1.13698
epoch 70: train loss is  1.16348
epoch 80: train loss is  1.10435
epoch 90: train loss is  1.10980
epoch 100: train loss is  1.06483
epoch 110: train loss is  1.01223
epoch 120: train loss is  1.01220
 >> Test Model
Cycle 1/10 || labeled data size 200, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.867480993270874 dsc_loss: 1.3885107040405273
TA-VAAL iteration: 10 vae_loss: 1.7292509078979492 dsc_loss: 1.369960904121399
TA-VAAL iteration: 20 vae_loss: 1.6862750053405762 dsc_loss: 1.3989975452423096
TA-VAAL iteration: 30 vae_loss: 1.7216275930404663 dsc_loss: 1.395037055015564
TA-VAAL iteration: 40 vae_loss: 1.5960031747817993 dsc_loss: 1.372530460357666
TA-VAAL iteration: 50 vae_loss: 1.7297180891036987 dsc_loss: 1.3845391273498535
TA-VAAL iteration: 60 vae_loss: 1.6750235557556152 dsc_loss: 1.363846778869629
TA-VAAL iteration: 70 vae_loss: 1.6237537860870361 dsc_loss: 1.3862272500991821
TA-VAAL iteration: 80 vae_loss: 1.5749919414520264 dsc_loss: 1.381763219833374
TA-VAAL iteration: 90 vae_loss: 1.5793931484222412 dsc_loss: 1.3895330429077148
TA-VAAL iteration: 100 vae_loss: 1.5185860395431519 dsc_loss: 1.361544132232666
TA-VAAL iteration: 200 vae_loss: 1.4993526935577393 dsc_loss: 1.3714957237243652
TA-VAAL iteration: 300 vae_loss: 1.8923066854476929 dsc_loss: 1.3683123588562012
TA-VAAL iteration: 400 vae_loss: 1.6563769578933716 dsc_loss: 1.3904119729995728
TA-VAAL iteration: 500 vae_loss: 1.7638328075408936 dsc_loss: 1.229614019393921
TA-VAAL iteration: 600 vae_loss: 1.8523825407028198 dsc_loss: 1.2826356887817383
TA-VAAL iteration: 700 vae_loss: 1.7793350219726562 dsc_loss: 1.315002202987671
TA-VAAL iteration: 800 vae_loss: 1.7109880447387695 dsc_loss: 1.3337488174438477
TA-VAAL iteration: 900 vae_loss: 1.9563608169555664 dsc_loss: 1.3017641305923462
TA-VAAL iteration: 1000 vae_loss: 2.0433363914489746 dsc_loss: 1.3289203643798828
TA-VAAL iteration: 1100 vae_loss: 1.9223520755767822 dsc_loss: 1.4333587884902954
TA-VAAL iteration: 1200 vae_loss: 1.8655486106872559 dsc_loss: 1.276390552520752
TA-VAAL iteration: 1300 vae_loss: 1.925605297088623 dsc_loss: 1.327817678451538
TA-VAAL iteration: 1400 vae_loss: 1.8182203769683838 dsc_loss: 1.2064129114151
TA-VAAL iteration: 1500 vae_loss: 2.090386390686035 dsc_loss: 1.3516901731491089
TA-VAAL iteration: 1600 vae_loss: 1.8479177951812744 dsc_loss: 1.327620267868042
TA-VAAL iteration: 1700 vae_loss: 2.1317391395568848 dsc_loss: 1.2474589347839355
TA-VAAL iteration: 1800 vae_loss: 1.901369571685791 dsc_loss: 1.2497049570083618
TA-VAAL iteration: 1900 vae_loss: 2.012946844100952 dsc_loss: 1.3041468858718872
TA-VAAL iteration: 2000 vae_loss: 2.4869463443756104 dsc_loss: 1.2447521686553955
TA-VAAL iteration: 2100 vae_loss: 2.3785910606384277 dsc_loss: 1.2422325611114502
TA-VAAL iteration: 2200 vae_loss: 2.286973237991333 dsc_loss: 1.1940265893936157
TA-VAAL iteration: 2300 vae_loss: 2.367799997329712 dsc_loss: 1.0373504161834717
TA-VAAL iteration: 2400 vae_loss: 2.581022024154663 dsc_loss: 1.189457654953003
TA-VAAL iteration: 2500 vae_loss: 2.5493311882019043 dsc_loss: 1.3068344593048096
TA-VAAL iteration: 2600 vae_loss: 2.062004327774048 dsc_loss: 1.1860857009887695
TA-VAAL iteration: 2700 vae_loss: 2.23935604095459 dsc_loss: 1.138321876525879
TA-VAAL iteration: 2800 vae_loss: 2.8162386417388916 dsc_loss: 1.1857575178146362
TA-VAAL iteration: 2900 vae_loss: 2.7711052894592285 dsc_loss: 1.1981265544891357
TA-VAAL iteration: 3000 vae_loss: 2.152575731277466 dsc_loss: 1.1765222549438477
TA-VAAL iteration: 3100 vae_loss: 2.054711103439331 dsc_loss: 1.2686197757720947
TA-VAAL iteration: 3200 vae_loss: 2.7692952156066895 dsc_loss: 1.145538330078125
TA-VAAL iteration: 3300 vae_loss: 2.3855202198028564 dsc_loss: 1.157222032546997
TA-VAAL iteration: 3400 vae_loss: 2.3775479793548584 dsc_loss: 1.1335657835006714
TA-VAAL iteration: 3500 vae_loss: 2.9413094520568848 dsc_loss: 1.3699281215667725
TA-VAAL iteration: 3600 vae_loss: 2.91510009765625 dsc_loss: 1.348921298980713
TA-VAAL iteration: 3700 vae_loss: 2.6660654544830322 dsc_loss: 1.082899570465088
TA-VAAL iteration: 3800 vae_loss: 3.0523831844329834 dsc_loss: 0.9953488111495972
TA-VAAL iteration: 3900 vae_loss: 4.228033542633057 dsc_loss: 1.5533456802368164
TA-VAAL iteration: 4000 vae_loss: 3.391031265258789 dsc_loss: 1.1972723007202148
TA-VAAL iteration: 4100 vae_loss: 2.9259228706359863 dsc_loss: 1.0282535552978516
TA-VAAL iteration: 4200 vae_loss: 2.8668394088745117 dsc_loss: 1.0302553176879883
TA-VAAL iteration: 4300 vae_loss: 2.9597764015197754 dsc_loss: 1.3223545551300049
TA-VAAL iteration: 4400 vae_loss: 3.4324381351470947 dsc_loss: 0.9310729503631592
TA-VAAL iteration: 4500 vae_loss: 2.9289052486419678 dsc_loss: 1.1480529308319092
TA-VAAL iteration: 4600 vae_loss: 3.791546583175659 dsc_loss: 0.8845475912094116
TA-VAAL iteration: 4700 vae_loss: 2.8557562828063965 dsc_loss: 1.2147928476333618
TA-VAAL iteration: 4800 vae_loss: 2.601863384246826 dsc_loss: 1.2729275226593018
TA-VAAL iteration: 4900 vae_loss: 2.2563180923461914 dsc_loss: 1.2098710536956787
TA-VAAL iteration: 5000 vae_loss: 3.183150291442871 dsc_loss: 1.0070898532867432
TA-VAAL iteration: 5100 vae_loss: 2.8933253288269043 dsc_loss: 1.0535320043563843
TA-VAAL iteration: 5200 vae_loss: 3.0562682151794434 dsc_loss: 1.1027848720550537
TA-VAAL iteration: 5300 vae_loss: 2.1761293411254883 dsc_loss: 1.3016668558120728
TA-VAAL iteration: 5400 vae_loss: 2.1206393241882324 dsc_loss: 1.3373990058898926
TA-VAAL iteration: 5500 vae_loss: 2.758089065551758 dsc_loss: 1.3922755718231201
TA-VAAL iteration: 5600 vae_loss: 2.003704786300659 dsc_loss: 1.2448499202728271
TA-VAAL iteration: 5700 vae_loss: 1.9502623081207275 dsc_loss: 1.3064382076263428
TA-VAAL iteration: 5800 vae_loss: 2.906475782394409 dsc_loss: 1.1632893085479736
TA-VAAL iteration: 5900 vae_loss: 2.7450814247131348 dsc_loss: 1.1314501762390137
TA-VAAL iteration: 6000 vae_loss: 2.786693572998047 dsc_loss: 1.1609324216842651
TA-VAAL iteration: 6100 vae_loss: 2.8866641521453857 dsc_loss: 1.1957225799560547
TA-VAAL iteration: 6200 vae_loss: 2.823439836502075 dsc_loss: 1.0495439767837524
400 106708 854 106969
>> Train vae and task model
epoch 0: train loss is  1.45994
epoch 10: train loss is  1.38915
epoch 20: train loss is  1.31084
epoch 30: train loss is  1.23601
epoch 40: train loss is  1.08898
epoch 50: train loss is  1.07193
epoch 60: train loss is  1.03437
epoch 70: train loss is  1.04711
epoch 80: train loss is  1.04118
epoch 90: train loss is  0.94694
epoch 100: train loss is  0.92777
epoch 110: train loss is  0.95431
epoch 120: train loss is  0.89031
 >> Test Model
Cycle 2/10 || labeled data size 400, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.7080789804458618 dsc_loss: 1.3996753692626953
TA-VAAL iteration: 10 vae_loss: 1.4984562397003174 dsc_loss: 1.3905303478240967
TA-VAAL iteration: 20 vae_loss: 1.6456553936004639 dsc_loss: 1.3513121604919434
TA-VAAL iteration: 30 vae_loss: 1.7628226280212402 dsc_loss: 1.3553634881973267
TA-VAAL iteration: 40 vae_loss: 2.5160973072052 dsc_loss: 1.4413247108459473
TA-VAAL iteration: 50 vae_loss: 2.2914562225341797 dsc_loss: 1.411971092224121
TA-VAAL iteration: 60 vae_loss: 2.673119306564331 dsc_loss: 1.396249771118164
TA-VAAL iteration: 70 vae_loss: 2.2536895275115967 dsc_loss: 1.446467399597168
TA-VAAL iteration: 80 vae_loss: 2.1328086853027344 dsc_loss: 1.3798869848251343
TA-VAAL iteration: 90 vae_loss: 1.9009279012680054 dsc_loss: 1.3490347862243652
TA-VAAL iteration: 100 vae_loss: 1.9879945516586304 dsc_loss: 1.343338966369629
TA-VAAL iteration: 200 vae_loss: 2.123476505279541 dsc_loss: 1.3424581289291382
TA-VAAL iteration: 300 vae_loss: 1.95994234085083 dsc_loss: 1.3542494773864746
TA-VAAL iteration: 400 vae_loss: 1.7532782554626465 dsc_loss: 1.4049124717712402
TA-VAAL iteration: 500 vae_loss: 1.6719424724578857 dsc_loss: 1.3902792930603027
TA-VAAL iteration: 600 vae_loss: 1.7322185039520264 dsc_loss: 1.3834826946258545
TA-VAAL iteration: 700 vae_loss: 1.7041723728179932 dsc_loss: 1.413944959640503
TA-VAAL iteration: 800 vae_loss: 1.7272818088531494 dsc_loss: 1.3668313026428223
TA-VAAL iteration: 900 vae_loss: 1.8278858661651611 dsc_loss: 1.3815131187438965
TA-VAAL iteration: 1000 vae_loss: 1.7818164825439453 dsc_loss: 1.3587603569030762
TA-VAAL iteration: 1100 vae_loss: 1.9382474422454834 dsc_loss: 1.3653106689453125
TA-VAAL iteration: 1200 vae_loss: 1.778765082359314 dsc_loss: 1.3730438947677612
TA-VAAL iteration: 1300 vae_loss: 1.8753210306167603 dsc_loss: 1.368432879447937
TA-VAAL iteration: 1400 vae_loss: 1.8747161626815796 dsc_loss: 1.3962653875350952
TA-VAAL iteration: 1500 vae_loss: 1.6677985191345215 dsc_loss: 1.313675045967102
TA-VAAL iteration: 1600 vae_loss: 1.834101915359497 dsc_loss: 1.3557984828948975
TA-VAAL iteration: 1700 vae_loss: 1.810254693031311 dsc_loss: 1.3392298221588135
TA-VAAL iteration: 1800 vae_loss: 1.7957347631454468 dsc_loss: 1.3983124494552612
TA-VAAL iteration: 1900 vae_loss: 1.6165382862091064 dsc_loss: 1.360865592956543
TA-VAAL iteration: 2000 vae_loss: 1.9365015029907227 dsc_loss: 1.410658836364746
TA-VAAL iteration: 2100 vae_loss: 1.8375476598739624 dsc_loss: 1.3965644836425781
TA-VAAL iteration: 2200 vae_loss: 1.6736451387405396 dsc_loss: 1.3433266878128052
TA-VAAL iteration: 2300 vae_loss: 1.5183864831924438 dsc_loss: 1.3686437606811523
TA-VAAL iteration: 2400 vae_loss: 1.58311128616333 dsc_loss: 1.3522043228149414
TA-VAAL iteration: 2500 vae_loss: 1.668251633644104 dsc_loss: 1.4007784128189087
TA-VAAL iteration: 2600 vae_loss: 1.5066441297531128 dsc_loss: 1.3793513774871826
TA-VAAL iteration: 2700 vae_loss: 1.5588210821151733 dsc_loss: 1.396885633468628
TA-VAAL iteration: 2800 vae_loss: 1.6557388305664062 dsc_loss: 1.369030475616455
TA-VAAL iteration: 2900 vae_loss: 1.4095922708511353 dsc_loss: 1.376015543937683
TA-VAAL iteration: 3000 vae_loss: 1.4118947982788086 dsc_loss: 1.3623595237731934
TA-VAAL iteration: 3100 vae_loss: 1.4722564220428467 dsc_loss: 1.3286488056182861
TA-VAAL iteration: 3200 vae_loss: 1.5756142139434814 dsc_loss: 1.4087414741516113
TA-VAAL iteration: 3300 vae_loss: 1.5042363405227661 dsc_loss: 1.3833609819412231
TA-VAAL iteration: 3400 vae_loss: 1.8987705707550049 dsc_loss: 1.3779866695404053
TA-VAAL iteration: 3500 vae_loss: 1.6994280815124512 dsc_loss: 1.3506760597229004
TA-VAAL iteration: 3600 vae_loss: 1.3885669708251953 dsc_loss: 1.3380458354949951
TA-VAAL iteration: 3700 vae_loss: 2.0740773677825928 dsc_loss: 1.2969591617584229
TA-VAAL iteration: 3800 vae_loss: 1.719526767730713 dsc_loss: 1.277092695236206
TA-VAAL iteration: 3900 vae_loss: 1.7890326976776123 dsc_loss: 1.398813247680664
TA-VAAL iteration: 4000 vae_loss: 1.7835074663162231 dsc_loss: 1.3754692077636719
TA-VAAL iteration: 4100 vae_loss: 2.064953088760376 dsc_loss: 1.3881012201309204
TA-VAAL iteration: 4200 vae_loss: 2.1496074199676514 dsc_loss: 1.3940232992172241
TA-VAAL iteration: 4300 vae_loss: 1.6697413921356201 dsc_loss: 1.3059053421020508
TA-VAAL iteration: 4400 vae_loss: 2.162388563156128 dsc_loss: 1.3358889818191528
TA-VAAL iteration: 4500 vae_loss: 1.890088438987732 dsc_loss: 1.2490854263305664
TA-VAAL iteration: 4600 vae_loss: 1.695467472076416 dsc_loss: 1.3899238109588623
TA-VAAL iteration: 4700 vae_loss: 1.742255449295044 dsc_loss: 1.3797523975372314
TA-VAAL iteration: 4800 vae_loss: 1.9766329526901245 dsc_loss: 1.4097418785095215
TA-VAAL iteration: 4900 vae_loss: 3.2570037841796875 dsc_loss: 1.4124000072479248
TA-VAAL iteration: 5000 vae_loss: 2.1130614280700684 dsc_loss: 1.3271749019622803
TA-VAAL iteration: 5100 vae_loss: 1.6415332555770874 dsc_loss: 1.332763433456421
TA-VAAL iteration: 5200 vae_loss: 1.8519906997680664 dsc_loss: 1.275278091430664
TA-VAAL iteration: 5300 vae_loss: 2.138033390045166 dsc_loss: 1.383943796157837
TA-VAAL iteration: 5400 vae_loss: 1.5428744554519653 dsc_loss: 1.4317586421966553
TA-VAAL iteration: 5500 vae_loss: 1.7437682151794434 dsc_loss: 1.362291932106018
TA-VAAL iteration: 5600 vae_loss: 2.009536027908325 dsc_loss: 1.4042911529541016
TA-VAAL iteration: 5700 vae_loss: 1.7742390632629395 dsc_loss: 1.2673234939575195
TA-VAAL iteration: 5800 vae_loss: 1.7423596382141113 dsc_loss: 1.2927409410476685
TA-VAAL iteration: 5900 vae_loss: 1.8280587196350098 dsc_loss: 1.3066937923431396
TA-VAAL iteration: 6000 vae_loss: 1.6843197345733643 dsc_loss: 1.3408548831939697
TA-VAAL iteration: 6100 vae_loss: 1.8584520816802979 dsc_loss: 1.301276683807373
TA-VAAL iteration: 6200 vae_loss: 1.9526901245117188 dsc_loss: 1.4368128776550293
TA-VAAL iteration: 6300 vae_loss: 1.9916810989379883 dsc_loss: 1.3491268157958984
TA-VAAL iteration: 6400 vae_loss: 2.1244430541992188 dsc_loss: 1.413457989692688
600 106508 100 106969
>> Train vae and task model
epoch 0: train loss is  1.61414
epoch 10: train loss is  1.48935
epoch 20: train loss is  1.35238
epoch 30: train loss is  1.33680
epoch 40: train loss is  1.35432
epoch 50: train loss is  1.29900
epoch 60: train loss is  1.29414
epoch 70: train loss is  1.28402
epoch 80: train loss is  1.22800
epoch 90: train loss is  1.18087
epoch 100: train loss is  1.15378
epoch 110: train loss is  1.20503
epoch 120: train loss is  1.17442
 >> Test Model
Cycle 3/10 || labeled data size 600, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.7568426132202148 dsc_loss: 1.398041009902954
TA-VAAL iteration: 10 vae_loss: 2.3040237426757812 dsc_loss: 1.4257707595825195
TA-VAAL iteration: 20 vae_loss: 2.3203535079956055 dsc_loss: 1.4414310455322266
TA-VAAL iteration: 30 vae_loss: 2.114035129547119 dsc_loss: 1.4012154340744019
TA-VAAL iteration: 40 vae_loss: 2.0413103103637695 dsc_loss: 1.3811038732528687
TA-VAAL iteration: 50 vae_loss: 2.017632007598877 dsc_loss: 1.4000422954559326
TA-VAAL iteration: 60 vae_loss: 1.9672136306762695 dsc_loss: 1.3758397102355957
TA-VAAL iteration: 70 vae_loss: 1.9943746328353882 dsc_loss: 1.3931405544281006
TA-VAAL iteration: 80 vae_loss: 2.0250730514526367 dsc_loss: 1.4122308492660522
TA-VAAL iteration: 90 vae_loss: 1.952737808227539 dsc_loss: 1.3954095840454102
TA-VAAL iteration: 100 vae_loss: 1.9304828643798828 dsc_loss: 1.3625634908676147
TA-VAAL iteration: 200 vae_loss: 1.6004979610443115 dsc_loss: 1.3695075511932373
TA-VAAL iteration: 300 vae_loss: 1.5768632888793945 dsc_loss: 1.3744441270828247
TA-VAAL iteration: 400 vae_loss: 1.5983169078826904 dsc_loss: 1.3583767414093018
TA-VAAL iteration: 500 vae_loss: 1.649863839149475 dsc_loss: 1.3478199243545532
TA-VAAL iteration: 600 vae_loss: 1.565751075744629 dsc_loss: 1.3537027835845947
TA-VAAL iteration: 700 vae_loss: 1.5632935762405396 dsc_loss: 1.3510595560073853
TA-VAAL iteration: 800 vae_loss: 1.6173458099365234 dsc_loss: 1.3522796630859375
TA-VAAL iteration: 900 vae_loss: 1.725474238395691 dsc_loss: 1.3369340896606445
TA-VAAL iteration: 1000 vae_loss: 1.8094722032546997 dsc_loss: 1.3088278770446777
TA-VAAL iteration: 1100 vae_loss: 1.9981262683868408 dsc_loss: 1.3296759128570557
TA-VAAL iteration: 1200 vae_loss: 1.878220796585083 dsc_loss: 1.3251583576202393
TA-VAAL iteration: 1300 vae_loss: 1.7772445678710938 dsc_loss: 1.3432209491729736
TA-VAAL iteration: 1400 vae_loss: 1.8342887163162231 dsc_loss: 1.3042263984680176
TA-VAAL iteration: 1500 vae_loss: 1.851426601409912 dsc_loss: 1.3679556846618652
TA-VAAL iteration: 1600 vae_loss: 1.8584964275360107 dsc_loss: 1.2437868118286133
TA-VAAL iteration: 1700 vae_loss: 1.8537383079528809 dsc_loss: 1.2371039390563965
TA-VAAL iteration: 1800 vae_loss: 1.8924031257629395 dsc_loss: 1.2475470304489136
TA-VAAL iteration: 1900 vae_loss: 1.9449939727783203 dsc_loss: 1.3402671813964844
TA-VAAL iteration: 2000 vae_loss: 2.0272867679595947 dsc_loss: 1.2937469482421875
TA-VAAL iteration: 2100 vae_loss: 2.1029889583587646 dsc_loss: 1.2565648555755615
TA-VAAL iteration: 2200 vae_loss: 1.864189624786377 dsc_loss: 1.2189033031463623
TA-VAAL iteration: 2300 vae_loss: 1.7636113166809082 dsc_loss: 1.2154412269592285
TA-VAAL iteration: 2400 vae_loss: 2.0979602336883545 dsc_loss: 1.197379469871521
TA-VAAL iteration: 2500 vae_loss: 1.8942675590515137 dsc_loss: 1.2414991855621338
TA-VAAL iteration: 2600 vae_loss: 1.8814119100570679 dsc_loss: 1.2844488620758057
TA-VAAL iteration: 2700 vae_loss: 2.1108052730560303 dsc_loss: 1.1671688556671143
TA-VAAL iteration: 2800 vae_loss: 2.719822406768799 dsc_loss: 1.3909846544265747
TA-VAAL iteration: 2900 vae_loss: 1.74079430103302 dsc_loss: 1.2439244985580444
TA-VAAL iteration: 3000 vae_loss: 2.019453525543213 dsc_loss: 1.2273414134979248
TA-VAAL iteration: 3100 vae_loss: 2.0342154502868652 dsc_loss: 1.2732280492782593
TA-VAAL iteration: 3200 vae_loss: 1.7117059230804443 dsc_loss: 1.4021532535552979
TA-VAAL iteration: 3300 vae_loss: 1.952909231185913 dsc_loss: 1.2008039951324463
TA-VAAL iteration: 3400 vae_loss: 1.9985482692718506 dsc_loss: 1.2268545627593994
TA-VAAL iteration: 3500 vae_loss: 2.1906161308288574 dsc_loss: 1.3029589653015137
TA-VAAL iteration: 3600 vae_loss: 2.7148890495300293 dsc_loss: 1.3620641231536865
TA-VAAL iteration: 3700 vae_loss: 2.0795235633850098 dsc_loss: 1.158780574798584
TA-VAAL iteration: 3800 vae_loss: 1.8417892456054688 dsc_loss: 1.2051900625228882
TA-VAAL iteration: 3900 vae_loss: 1.8853117227554321 dsc_loss: 1.2651052474975586
TA-VAAL iteration: 4000 vae_loss: 1.8897873163223267 dsc_loss: 1.2946821451187134
TA-VAAL iteration: 4100 vae_loss: 1.6442105770111084 dsc_loss: 1.3810009956359863
TA-VAAL iteration: 4200 vae_loss: 1.8891619443893433 dsc_loss: 1.2691385746002197
TA-VAAL iteration: 4300 vae_loss: 1.9375684261322021 dsc_loss: 1.3495862483978271
TA-VAAL iteration: 4400 vae_loss: 2.3133227825164795 dsc_loss: 1.4877651929855347
TA-VAAL iteration: 4500 vae_loss: 1.9939234256744385 dsc_loss: 1.4590988159179688
TA-VAAL iteration: 4600 vae_loss: 1.9120405912399292 dsc_loss: 1.381201982498169
TA-VAAL iteration: 4700 vae_loss: 1.5405776500701904 dsc_loss: 1.3963377475738525
TA-VAAL iteration: 4800 vae_loss: 1.9511815309524536 dsc_loss: 1.381213665008545
TA-VAAL iteration: 4900 vae_loss: 1.7096112966537476 dsc_loss: 1.386286973953247
TA-VAAL iteration: 5000 vae_loss: 1.733733892440796 dsc_loss: 1.3492735624313354
TA-VAAL iteration: 5100 vae_loss: 1.612453579902649 dsc_loss: 1.364485740661621
TA-VAAL iteration: 5200 vae_loss: 1.7328643798828125 dsc_loss: 1.377047061920166
TA-VAAL iteration: 5300 vae_loss: 1.6417649984359741 dsc_loss: 1.3956254720687866
TA-VAAL iteration: 5400 vae_loss: 1.79948091506958 dsc_loss: 1.3680282831192017
TA-VAAL iteration: 5500 vae_loss: 2.1081953048706055 dsc_loss: 1.4028904438018799
TA-VAAL iteration: 5600 vae_loss: 1.872046947479248 dsc_loss: 1.3667516708374023
TA-VAAL iteration: 5700 vae_loss: 1.8678584098815918 dsc_loss: 1.3519370555877686
TA-VAAL iteration: 5800 vae_loss: 2.028480291366577 dsc_loss: 1.3595902919769287
TA-VAAL iteration: 5900 vae_loss: 2.0158467292785645 dsc_loss: 1.320039987564087
TA-VAAL iteration: 6000 vae_loss: 2.2508649826049805 dsc_loss: 1.3602516651153564
TA-VAAL iteration: 6100 vae_loss: 2.045555353164673 dsc_loss: 1.358121395111084
TA-VAAL iteration: 6200 vae_loss: 2.0037589073181152 dsc_loss: 1.3255501985549927
TA-VAAL iteration: 6300 vae_loss: 1.9026119709014893 dsc_loss: 1.331756830215454
TA-VAAL iteration: 6400 vae_loss: 1.8542749881744385 dsc_loss: 1.3742923736572266
TA-VAAL iteration: 6500 vae_loss: 1.8050721883773804 dsc_loss: 1.3200771808624268
TA-VAAL iteration: 6600 vae_loss: 1.9269963502883911 dsc_loss: 1.3394076824188232
TA-VAAL iteration: 6700 vae_loss: 1.747786045074463 dsc_loss: 1.290639877319336
800 106308 100 106969
>> Train vae and task model
epoch 0: train loss is  1.59281
epoch 10: train loss is  1.44714
epoch 20: train loss is  1.38036
epoch 30: train loss is  1.29008
epoch 40: train loss is  1.31357
epoch 50: train loss is  1.25198
epoch 60: train loss is  1.22231
epoch 70: train loss is  1.20638
epoch 80: train loss is  1.15429
epoch 90: train loss is  1.16872
epoch 100: train loss is  1.09567
epoch 110: train loss is  1.07731
epoch 120: train loss is  1.10146
 >> Test Model
Cycle 4/10 || labeled data size 800, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.8114943504333496 dsc_loss: 1.394312858581543
TA-VAAL iteration: 10 vae_loss: 2.173853874206543 dsc_loss: 1.4136731624603271
TA-VAAL iteration: 20 vae_loss: 2.107149362564087 dsc_loss: 1.3664402961730957
TA-VAAL iteration: 30 vae_loss: 1.8516817092895508 dsc_loss: 1.4035476446151733
TA-VAAL iteration: 40 vae_loss: 2.1888866424560547 dsc_loss: 1.4508531093597412
TA-VAAL iteration: 50 vae_loss: 2.398620128631592 dsc_loss: 1.407670497894287
TA-VAAL iteration: 60 vae_loss: 2.2197866439819336 dsc_loss: 1.4023808240890503
TA-VAAL iteration: 70 vae_loss: 2.1733481884002686 dsc_loss: 1.3945643901824951
TA-VAAL iteration: 80 vae_loss: 2.0044116973876953 dsc_loss: 1.392653226852417
TA-VAAL iteration: 90 vae_loss: 1.91014564037323 dsc_loss: 1.3609553575515747
TA-VAAL iteration: 100 vae_loss: 1.9801284074783325 dsc_loss: 1.3734729290008545
TA-VAAL iteration: 200 vae_loss: 1.6930959224700928 dsc_loss: 1.4229291677474976
TA-VAAL iteration: 300 vae_loss: 1.6261632442474365 dsc_loss: 1.4187746047973633
TA-VAAL iteration: 400 vae_loss: 1.946772575378418 dsc_loss: 1.3810415267944336
TA-VAAL iteration: 500 vae_loss: 1.6672545671463013 dsc_loss: 1.40028977394104
TA-VAAL iteration: 600 vae_loss: 1.8976919651031494 dsc_loss: 1.381467580795288
TA-VAAL iteration: 700 vae_loss: 1.8319416046142578 dsc_loss: 1.4040035009384155
TA-VAAL iteration: 800 vae_loss: 1.6722642183303833 dsc_loss: 1.3760221004486084
TA-VAAL iteration: 900 vae_loss: 1.7450194358825684 dsc_loss: 1.4444530010223389
TA-VAAL iteration: 1000 vae_loss: 1.792304515838623 dsc_loss: 1.3891706466674805
TA-VAAL iteration: 1100 vae_loss: 1.8104603290557861 dsc_loss: 1.3716843128204346
TA-VAAL iteration: 1200 vae_loss: 1.8518259525299072 dsc_loss: 1.4079066514968872
TA-VAAL iteration: 1300 vae_loss: 1.8519916534423828 dsc_loss: 1.3578393459320068
TA-VAAL iteration: 1400 vae_loss: 1.9405471086502075 dsc_loss: 1.353835105895996
TA-VAAL iteration: 1500 vae_loss: 1.8473020792007446 dsc_loss: 1.3471899032592773
TA-VAAL iteration: 1600 vae_loss: 1.9560520648956299 dsc_loss: 1.3835127353668213
TA-VAAL iteration: 1700 vae_loss: 1.9146519899368286 dsc_loss: 1.3786736726760864
TA-VAAL iteration: 1800 vae_loss: 1.833681344985962 dsc_loss: 1.386947751045227
TA-VAAL iteration: 1900 vae_loss: 1.8459538221359253 dsc_loss: 1.3880890607833862
TA-VAAL iteration: 2000 vae_loss: 1.8164316415786743 dsc_loss: 1.392768383026123
TA-VAAL iteration: 2100 vae_loss: 1.8019007444381714 dsc_loss: 1.355654001235962
TA-VAAL iteration: 2200 vae_loss: 1.8933990001678467 dsc_loss: 1.4122642278671265
TA-VAAL iteration: 2300 vae_loss: 1.8332667350769043 dsc_loss: 1.3584805727005005
TA-VAAL iteration: 2400 vae_loss: 1.8123433589935303 dsc_loss: 1.3213438987731934
TA-VAAL iteration: 2500 vae_loss: 1.9388132095336914 dsc_loss: 1.428722620010376
TA-VAAL iteration: 2600 vae_loss: 1.7404510974884033 dsc_loss: 1.3877592086791992
TA-VAAL iteration: 2700 vae_loss: 1.8848505020141602 dsc_loss: 1.3540735244750977
TA-VAAL iteration: 2800 vae_loss: 1.866258978843689 dsc_loss: 1.3922044038772583
TA-VAAL iteration: 2900 vae_loss: 1.746199369430542 dsc_loss: 1.3956530094146729
TA-VAAL iteration: 3000 vae_loss: 1.9424784183502197 dsc_loss: 1.3746318817138672
TA-VAAL iteration: 3100 vae_loss: 1.8538578748703003 dsc_loss: 1.381908655166626
TA-VAAL iteration: 3200 vae_loss: 1.739465355873108 dsc_loss: 1.3903753757476807
TA-VAAL iteration: 3300 vae_loss: 1.9268972873687744 dsc_loss: 1.3937063217163086
TA-VAAL iteration: 3400 vae_loss: 1.778396725654602 dsc_loss: 1.3578132390975952
TA-VAAL iteration: 3500 vae_loss: 1.8016749620437622 dsc_loss: 1.4144179821014404
TA-VAAL iteration: 3600 vae_loss: 1.8962125778198242 dsc_loss: 1.3730812072753906
TA-VAAL iteration: 3700 vae_loss: 1.8516919612884521 dsc_loss: 1.3388464450836182
TA-VAAL iteration: 3800 vae_loss: 1.8630032539367676 dsc_loss: 1.4163018465042114
TA-VAAL iteration: 3900 vae_loss: 1.7190197706222534 dsc_loss: 1.4020217657089233
TA-VAAL iteration: 4000 vae_loss: 2.034090042114258 dsc_loss: 1.322195291519165
TA-VAAL iteration: 4100 vae_loss: 1.7059130668640137 dsc_loss: 1.4166791439056396
TA-VAAL iteration: 4200 vae_loss: 1.8903734683990479 dsc_loss: 1.3828554153442383
TA-VAAL iteration: 4300 vae_loss: 1.7281275987625122 dsc_loss: 1.3767573833465576
TA-VAAL iteration: 4400 vae_loss: 1.7100532054901123 dsc_loss: 1.3796645402908325
TA-VAAL iteration: 4500 vae_loss: 1.8606395721435547 dsc_loss: 1.3942556381225586
TA-VAAL iteration: 4600 vae_loss: 1.8479951620101929 dsc_loss: 1.3851876258850098
TA-VAAL iteration: 4700 vae_loss: 1.7658395767211914 dsc_loss: 1.2939410209655762
TA-VAAL iteration: 4800 vae_loss: 1.8071364164352417 dsc_loss: 1.3964591026306152
TA-VAAL iteration: 4900 vae_loss: 1.8501993417739868 dsc_loss: 1.3438782691955566
TA-VAAL iteration: 5000 vae_loss: 1.6933881044387817 dsc_loss: 1.2926671504974365
TA-VAAL iteration: 5100 vae_loss: 1.8185362815856934 dsc_loss: 1.4069199562072754
TA-VAAL iteration: 5200 vae_loss: 1.9193148612976074 dsc_loss: 1.4085636138916016
TA-VAAL iteration: 5300 vae_loss: 1.6674222946166992 dsc_loss: 1.3528400659561157
TA-VAAL iteration: 5400 vae_loss: 1.8193724155426025 dsc_loss: 1.3816113471984863
TA-VAAL iteration: 5500 vae_loss: 2.0212178230285645 dsc_loss: 1.4021289348602295
TA-VAAL iteration: 5600 vae_loss: 1.8188302516937256 dsc_loss: 1.380041241645813
TA-VAAL iteration: 5700 vae_loss: 1.751255989074707 dsc_loss: 1.3710472583770752
TA-VAAL iteration: 5800 vae_loss: 1.9039807319641113 dsc_loss: 1.3886555433273315
TA-VAAL iteration: 5900 vae_loss: 2.0578038692474365 dsc_loss: 1.3957715034484863
TA-VAAL iteration: 6000 vae_loss: 2.142568349838257 dsc_loss: 1.3701751232147217
TA-VAAL iteration: 6100 vae_loss: 1.9838923215866089 dsc_loss: 1.4269787073135376
TA-VAAL iteration: 6200 vae_loss: 1.8511090278625488 dsc_loss: 1.334657907485962
TA-VAAL iteration: 6300 vae_loss: 1.7370176315307617 dsc_loss: 1.3597424030303955
TA-VAAL iteration: 6400 vae_loss: 1.6937215328216553 dsc_loss: 1.3976823091506958
TA-VAAL iteration: 6500 vae_loss: 1.7113146781921387 dsc_loss: 1.3796002864837646
TA-VAAL iteration: 6600 vae_loss: 1.7312970161437988 dsc_loss: 1.3759677410125732
TA-VAAL iteration: 6700 vae_loss: 1.8406028747558594 dsc_loss: 1.3912078142166138
TA-VAAL iteration: 6800 vae_loss: 1.7919529676437378 dsc_loss: 1.397674798965454
TA-VAAL iteration: 6900 vae_loss: 1.8198903799057007 dsc_loss: 1.3632493019104004
1000 106108 100 106969
>> Train vae and task model
epoch 0: train loss is  1.52223
epoch 10: train loss is  1.35817
epoch 20: train loss is  1.29395
epoch 30: train loss is  1.24556
epoch 40: train loss is  1.21194
epoch 50: train loss is  1.13697
epoch 60: train loss is  1.14418
epoch 70: train loss is  1.13440
epoch 80: train loss is  1.08276
epoch 90: train loss is  1.05361
epoch 100: train loss is  1.09948
epoch 110: train loss is  1.06637
epoch 120: train loss is  1.03405
 >> Test Model
Cycle 5/10 || labeled data size 1000, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.630969524383545 dsc_loss: 1.4201438426971436
TA-VAAL iteration: 10 vae_loss: 1.2084323167800903 dsc_loss: 1.4554139375686646
TA-VAAL iteration: 20 vae_loss: 1.2070386409759521 dsc_loss: 1.528223991394043
TA-VAAL iteration: 30 vae_loss: 1.8667234182357788 dsc_loss: 1.4350535869598389
TA-VAAL iteration: 40 vae_loss: 1.8347729444503784 dsc_loss: 1.5211853981018066
TA-VAAL iteration: 50 vae_loss: 2.104945182800293 dsc_loss: 1.3988585472106934
TA-VAAL iteration: 60 vae_loss: 2.235065460205078 dsc_loss: 1.4495539665222168
TA-VAAL iteration: 70 vae_loss: 2.1099753379821777 dsc_loss: 1.4273722171783447
TA-VAAL iteration: 80 vae_loss: 1.7391809225082397 dsc_loss: 1.3901560306549072
TA-VAAL iteration: 90 vae_loss: 1.7519817352294922 dsc_loss: 1.3906044960021973
TA-VAAL iteration: 100 vae_loss: 1.7209514379501343 dsc_loss: 1.3997831344604492
TA-VAAL iteration: 200 vae_loss: 1.6111390590667725 dsc_loss: 1.5465936660766602
TA-VAAL iteration: 300 vae_loss: 1.7419663667678833 dsc_loss: 1.4445980787277222
TA-VAAL iteration: 400 vae_loss: 1.5957149267196655 dsc_loss: 1.391258716583252
TA-VAAL iteration: 500 vae_loss: 1.4613981246948242 dsc_loss: 1.409407377243042
TA-VAAL iteration: 600 vae_loss: 1.5149307250976562 dsc_loss: 1.4271466732025146
TA-VAAL iteration: 700 vae_loss: 1.5972497463226318 dsc_loss: 1.3923050165176392
TA-VAAL iteration: 800 vae_loss: 1.6876558065414429 dsc_loss: 1.414461612701416
TA-VAAL iteration: 900 vae_loss: 1.6146048307418823 dsc_loss: 1.4419827461242676
TA-VAAL iteration: 1000 vae_loss: 1.5189731121063232 dsc_loss: 1.391860008239746
TA-VAAL iteration: 1100 vae_loss: 1.5997260808944702 dsc_loss: 1.379863977432251
TA-VAAL iteration: 1200 vae_loss: 1.6476911306381226 dsc_loss: 1.3909932374954224
TA-VAAL iteration: 1300 vae_loss: 1.6852726936340332 dsc_loss: 1.394012451171875
TA-VAAL iteration: 1400 vae_loss: 1.6141552925109863 dsc_loss: 1.3711587190628052
TA-VAAL iteration: 1500 vae_loss: 1.5043762922286987 dsc_loss: 1.3738813400268555
TA-VAAL iteration: 1600 vae_loss: 1.5157361030578613 dsc_loss: 1.415091872215271
TA-VAAL iteration: 1700 vae_loss: 1.5835756063461304 dsc_loss: 1.4038898944854736
TA-VAAL iteration: 1800 vae_loss: 1.7011077404022217 dsc_loss: 1.4076745510101318
TA-VAAL iteration: 1900 vae_loss: 1.5140117406845093 dsc_loss: 1.3837897777557373
TA-VAAL iteration: 2000 vae_loss: 1.5488173961639404 dsc_loss: 1.3957619667053223
TA-VAAL iteration: 2100 vae_loss: 1.5579888820648193 dsc_loss: 1.3823350667953491
TA-VAAL iteration: 2200 vae_loss: 1.6845948696136475 dsc_loss: 1.43812894821167
TA-VAAL iteration: 2300 vae_loss: 1.5644099712371826 dsc_loss: 1.3534554243087769
TA-VAAL iteration: 2400 vae_loss: 1.507551670074463 dsc_loss: 1.3908765316009521
TA-VAAL iteration: 2500 vae_loss: 1.6500880718231201 dsc_loss: 1.3998208045959473
TA-VAAL iteration: 2600 vae_loss: 1.648653507232666 dsc_loss: 1.4041821956634521
TA-VAAL iteration: 2700 vae_loss: 1.6819725036621094 dsc_loss: 1.3626716136932373
TA-VAAL iteration: 2800 vae_loss: 1.5792146921157837 dsc_loss: 1.3752479553222656
TA-VAAL iteration: 2900 vae_loss: 1.7216076850891113 dsc_loss: 1.3928618431091309
TA-VAAL iteration: 3000 vae_loss: 1.6140096187591553 dsc_loss: 1.3788926601409912
TA-VAAL iteration: 3100 vae_loss: 1.5857778787612915 dsc_loss: 1.3852579593658447
TA-VAAL iteration: 3200 vae_loss: 1.5920186042785645 dsc_loss: 1.393002986907959
TA-VAAL iteration: 3300 vae_loss: 1.6299097537994385 dsc_loss: 1.402820348739624
TA-VAAL iteration: 3400 vae_loss: 1.7364343404769897 dsc_loss: 1.3684523105621338
TA-VAAL iteration: 3500 vae_loss: 1.6129150390625 dsc_loss: 1.364255428314209
TA-VAAL iteration: 3600 vae_loss: 1.5903242826461792 dsc_loss: 1.3903160095214844
TA-VAAL iteration: 3700 vae_loss: 1.7845810651779175 dsc_loss: 1.4003040790557861
TA-VAAL iteration: 3800 vae_loss: 1.6430985927581787 dsc_loss: 1.3292763233184814
TA-VAAL iteration: 3900 vae_loss: 1.6100223064422607 dsc_loss: 1.3787617683410645
TA-VAAL iteration: 4000 vae_loss: 1.5699918270111084 dsc_loss: 1.407319188117981
TA-VAAL iteration: 4100 vae_loss: 1.793676495552063 dsc_loss: 1.414971113204956
TA-VAAL iteration: 4200 vae_loss: 1.6043850183486938 dsc_loss: 1.3613402843475342
TA-VAAL iteration: 4300 vae_loss: 1.7151294946670532 dsc_loss: 1.369673490524292
TA-VAAL iteration: 4400 vae_loss: 1.6506458520889282 dsc_loss: 1.4078874588012695
TA-VAAL iteration: 4500 vae_loss: 1.7516604661941528 dsc_loss: 1.3837034702301025
TA-VAAL iteration: 4600 vae_loss: 1.6493333578109741 dsc_loss: 1.347374439239502
TA-VAAL iteration: 4700 vae_loss: 1.693893551826477 dsc_loss: 1.3330814838409424
TA-VAAL iteration: 4800 vae_loss: 1.7124474048614502 dsc_loss: 1.394904613494873
TA-VAAL iteration: 4900 vae_loss: 1.781029224395752 dsc_loss: 1.3919328451156616
TA-VAAL iteration: 5000 vae_loss: 1.668796181678772 dsc_loss: 1.3592863082885742
TA-VAAL iteration: 5100 vae_loss: 1.545579195022583 dsc_loss: 1.3631281852722168
TA-VAAL iteration: 5200 vae_loss: 1.615201711654663 dsc_loss: 1.4131414890289307
TA-VAAL iteration: 5300 vae_loss: 1.6966992616653442 dsc_loss: 1.3742172718048096
TA-VAAL iteration: 5400 vae_loss: 1.6755485534667969 dsc_loss: 1.3672001361846924
TA-VAAL iteration: 5500 vae_loss: 1.7634928226470947 dsc_loss: 1.3709001541137695
TA-VAAL iteration: 5600 vae_loss: 1.773852825164795 dsc_loss: 1.4069544076919556
TA-VAAL iteration: 5700 vae_loss: 1.7024726867675781 dsc_loss: 1.3872560262680054
TA-VAAL iteration: 5800 vae_loss: 1.7677509784698486 dsc_loss: 1.3699374198913574
TA-VAAL iteration: 5900 vae_loss: 1.7934699058532715 dsc_loss: 1.3509290218353271
TA-VAAL iteration: 6000 vae_loss: 1.7586677074432373 dsc_loss: 1.4220958948135376
TA-VAAL iteration: 6100 vae_loss: 1.8468010425567627 dsc_loss: 1.4492439031600952
TA-VAAL iteration: 6200 vae_loss: 1.6820871829986572 dsc_loss: 1.3780248165130615
TA-VAAL iteration: 6300 vae_loss: 1.6843817234039307 dsc_loss: 1.3553941249847412
TA-VAAL iteration: 6400 vae_loss: 1.6899052858352661 dsc_loss: 1.3901575803756714
TA-VAAL iteration: 6500 vae_loss: 1.7359920740127563 dsc_loss: 1.3992323875427246
TA-VAAL iteration: 6600 vae_loss: 1.8274439573287964 dsc_loss: 1.355154037475586
TA-VAAL iteration: 6700 vae_loss: 1.7644901275634766 dsc_loss: 1.3784366846084595
TA-VAAL iteration: 6800 vae_loss: 1.7489013671875 dsc_loss: 1.3997995853424072
TA-VAAL iteration: 6900 vae_loss: 1.6251071691513062 dsc_loss: 1.4326252937316895
TA-VAAL iteration: 7000 vae_loss: 1.7684043645858765 dsc_loss: 1.3939127922058105
TA-VAAL iteration: 7100 vae_loss: 1.7123374938964844 dsc_loss: 1.3453476428985596
TA-VAAL iteration: 7200 vae_loss: 1.86212956905365 dsc_loss: 1.3782262802124023
1200 105908 100 107099
>> Train vae and task model
epoch 0: train loss is  1.48824
epoch 10: train loss is  1.31847
epoch 20: train loss is  1.24742
epoch 30: train loss is  1.23645
epoch 40: train loss is  1.21697
epoch 50: train loss is  1.17473
epoch 60: train loss is  1.14964
epoch 70: train loss is  1.09108
epoch 80: train loss is  1.08049
epoch 90: train loss is  1.03973
epoch 100: train loss is  1.00944
epoch 110: train loss is  0.99558
epoch 120: train loss is  0.97246
 >> Test Model
Cycle 6/10 || labeled data size 1200, test loss(MAE) =  0.68797
TA-VAAL iteration: 0 vae_loss: 1.7863655090332031 dsc_loss: 1.392136812210083
TA-VAAL iteration: 10 vae_loss: 1.8235126733779907 dsc_loss: 1.400892972946167
TA-VAAL iteration: 20 vae_loss: 1.8219984769821167 dsc_loss: 1.414985179901123
TA-VAAL iteration: 30 vae_loss: 1.8227734565734863 dsc_loss: 1.4094104766845703
TA-VAAL iteration: 40 vae_loss: 1.6784560680389404 dsc_loss: 1.448789119720459
TA-VAAL iteration: 50 vae_loss: 1.6688239574432373 dsc_loss: 1.4144737720489502
TA-VAAL iteration: 60 vae_loss: 1.7148398160934448 dsc_loss: 1.3734771013259888
TA-VAAL iteration: 70 vae_loss: 1.6415544748306274 dsc_loss: 1.4290640354156494
TA-VAAL iteration: 80 vae_loss: 1.838220238685608 dsc_loss: 1.3893100023269653
TA-VAAL iteration: 90 vae_loss: 1.7518731355667114 dsc_loss: 1.4056780338287354
TA-VAAL iteration: 100 vae_loss: 1.733742356300354 dsc_loss: 1.385218620300293
TA-VAAL iteration: 200 vae_loss: 1.5104538202285767 dsc_loss: 1.3979686498641968
TA-VAAL iteration: 300 vae_loss: 1.4638234376907349 dsc_loss: 1.3690634965896606
TA-VAAL iteration: 400 vae_loss: 1.3948756456375122 dsc_loss: 1.3777128458023071
TA-VAAL iteration: 500 vae_loss: 1.5428847074508667 dsc_loss: 1.3833335638046265
TA-VAAL iteration: 600 vae_loss: 1.643288493156433 dsc_loss: 1.3959872722625732
TA-VAAL iteration: 700 vae_loss: 1.5539524555206299 dsc_loss: 1.3880207538604736
TA-VAAL iteration: 800 vae_loss: 1.7921128273010254 dsc_loss: 1.395369291305542
TA-VAAL iteration: 900 vae_loss: 1.6645573377609253 dsc_loss: 1.3907471895217896
TA-VAAL iteration: 1000 vae_loss: 1.6769828796386719 dsc_loss: 1.3850269317626953
TA-VAAL iteration: 1100 vae_loss: 1.590150237083435 dsc_loss: 1.3851563930511475
TA-VAAL iteration: 1200 vae_loss: 1.7473187446594238 dsc_loss: 1.3718223571777344
TA-VAAL iteration: 1300 vae_loss: 1.594055414199829 dsc_loss: 1.4049159288406372
TA-VAAL iteration: 1400 vae_loss: 1.613073706626892 dsc_loss: 1.377801537513733
TA-VAAL iteration: 1500 vae_loss: 1.6946803331375122 dsc_loss: 1.3721296787261963
TA-VAAL iteration: 1600 vae_loss: 1.6980420351028442 dsc_loss: 1.3914005756378174
TA-VAAL iteration: 1700 vae_loss: 1.5694763660430908 dsc_loss: 1.3986825942993164
TA-VAAL iteration: 1800 vae_loss: 1.6503957509994507 dsc_loss: 1.3707866668701172
TA-VAAL iteration: 1900 vae_loss: 1.7329790592193604 dsc_loss: 1.3915059566497803
TA-VAAL iteration: 2000 vae_loss: 1.6855857372283936 dsc_loss: 1.3691511154174805
TA-VAAL iteration: 2100 vae_loss: 1.688990831375122 dsc_loss: 1.391392469406128
TA-VAAL iteration: 2200 vae_loss: 1.6290252208709717 dsc_loss: 1.3756320476531982
TA-VAAL iteration: 2300 vae_loss: 1.813559651374817 dsc_loss: 1.3879950046539307
TA-VAAL iteration: 2400 vae_loss: 1.8001680374145508 dsc_loss: 1.3860119581222534
TA-VAAL iteration: 2500 vae_loss: 1.8410544395446777 dsc_loss: 1.3823477029800415
TA-VAAL iteration: 2600 vae_loss: 1.7209181785583496 dsc_loss: 1.3808844089508057
TA-VAAL iteration: 2700 vae_loss: 1.84908926486969 dsc_loss: 1.394840955734253
TA-VAAL iteration: 2800 vae_loss: 1.8533209562301636 dsc_loss: 1.3932015895843506
TA-VAAL iteration: 2900 vae_loss: 1.8527920246124268 dsc_loss: 1.3851208686828613
TA-VAAL iteration: 3000 vae_loss: 1.7747132778167725 dsc_loss: 1.3726202249526978
TA-VAAL iteration: 3100 vae_loss: 1.9292323589324951 dsc_loss: 1.3730502128601074
TA-VAAL iteration: 3200 vae_loss: 1.9074130058288574 dsc_loss: 1.3940494060516357
TA-VAAL iteration: 3300 vae_loss: 1.8304022550582886 dsc_loss: 1.380924940109253
TA-VAAL iteration: 3400 vae_loss: 1.9156711101531982 dsc_loss: 1.3683676719665527
TA-VAAL iteration: 3500 vae_loss: 1.8496854305267334 dsc_loss: 1.3784737586975098
TA-VAAL iteration: 3600 vae_loss: 1.8738620281219482 dsc_loss: 1.3859069347381592
TA-VAAL iteration: 3700 vae_loss: 1.8059502840042114 dsc_loss: 1.3715786933898926
TA-VAAL iteration: 3800 vae_loss: 2.056684732437134 dsc_loss: 1.4045424461364746
TA-VAAL iteration: 3900 vae_loss: 2.1005640029907227 dsc_loss: 1.3839218616485596
TA-VAAL iteration: 4000 vae_loss: 1.955102801322937 dsc_loss: 1.3919754028320312
TA-VAAL iteration: 4100 vae_loss: 1.8383790254592896 dsc_loss: 1.3704547882080078
TA-VAAL iteration: 4200 vae_loss: 1.8925758600234985 dsc_loss: 1.3813821077346802
TA-VAAL iteration: 4300 vae_loss: 2.0159997940063477 dsc_loss: 1.3908802270889282
TA-VAAL iteration: 4400 vae_loss: 1.9191474914550781 dsc_loss: 1.3777445554733276
TA-VAAL iteration: 4500 vae_loss: 1.9678316116333008 dsc_loss: 1.3811604976654053
TA-VAAL iteration: 4600 vae_loss: 1.9261976480484009 dsc_loss: 1.3977105617523193
TA-VAAL iteration: 4700 vae_loss: 2.022210121154785 dsc_loss: 1.38558030128479
TA-VAAL iteration: 4800 vae_loss: 2.0250015258789062 dsc_loss: 1.3793423175811768
TA-VAAL iteration: 4900 vae_loss: 2.0244052410125732 dsc_loss: 1.380061388015747
TA-VAAL iteration: 5000 vae_loss: 2.030165672302246 dsc_loss: 1.3730957508087158
TA-VAAL iteration: 5100 vae_loss: 2.075950860977173 dsc_loss: 1.40714693069458
TA-VAAL iteration: 5200 vae_loss: 1.9774878025054932 dsc_loss: 1.368152141571045
TA-VAAL iteration: 5300 vae_loss: 2.0737497806549072 dsc_loss: 1.3643803596496582
TA-VAAL iteration: 5400 vae_loss: 2.0806243419647217 dsc_loss: 1.39247727394104
TA-VAAL iteration: 5500 vae_loss: 2.099626064300537 dsc_loss: 1.3874125480651855
TA-VAAL iteration: 5600 vae_loss: 2.1040658950805664 dsc_loss: 1.370729684829712
TA-VAAL iteration: 5700 vae_loss: 2.068665027618408 dsc_loss: 1.4010498523712158
TA-VAAL iteration: 5800 vae_loss: 2.1558406352996826 dsc_loss: 1.3723676204681396
TA-VAAL iteration: 5900 vae_loss: 2.177424907684326 dsc_loss: 1.407181978225708
TA-VAAL iteration: 6000 vae_loss: 2.149975538253784 dsc_loss: 1.3743952512741089
TA-VAAL iteration: 6100 vae_loss: 2.1297333240509033 dsc_loss: 1.3858391046524048
TA-VAAL iteration: 6200 vae_loss: 2.307664394378662 dsc_loss: 1.3828184604644775
TA-VAAL iteration: 6300 vae_loss: 2.2951512336730957 dsc_loss: 1.3593471050262451
TA-VAAL iteration: 6400 vae_loss: 2.3092212677001953 dsc_loss: 1.3839049339294434
TA-VAAL iteration: 6500 vae_loss: 2.287309408187866 dsc_loss: 1.4004405736923218
TA-VAAL iteration: 6600 vae_loss: 2.2891488075256348 dsc_loss: 1.3877408504486084
TA-VAAL iteration: 6700 vae_loss: 2.2707414627075195 dsc_loss: 1.384783148765564
TA-VAAL iteration: 6800 vae_loss: 2.3063480854034424 dsc_loss: 1.3674001693725586
TA-VAAL iteration: 6900 vae_loss: 2.2592973709106445 dsc_loss: 1.3826342821121216
TA-VAAL iteration: 7000 vae_loss: 2.29693865776062 dsc_loss: 1.3930528163909912
TA-VAAL iteration: 7100 vae_loss: 2.365363121032715 dsc_loss: 1.3837625980377197
TA-VAAL iteration: 7200 vae_loss: 2.265991449356079 dsc_loss: 1.3552913665771484
TA-VAAL iteration: 7300 vae_loss: 2.264674663543701 dsc_loss: 1.3917479515075684
TA-VAAL iteration: 7400 vae_loss: 2.385713815689087 dsc_loss: 1.3977848291397095
1400 105708 100 107099
>> Train vae and task model
epoch 0: train loss is  1.50831
epoch 10: train loss is  1.36272
epoch 20: train loss is  1.27031
epoch 30: train loss is  1.22148
epoch 40: train loss is  1.23849
epoch 50: train loss is  1.17207
epoch 60: train loss is  1.17666
epoch 70: train loss is  1.11880
epoch 80: train loss is  1.11065
epoch 90: train loss is  1.08645
epoch 100: train loss is  1.08426
epoch 110: train loss is  1.06620
epoch 120: train loss is  1.05750
 >> Test Model
Cycle 7/10 || labeled data size 1400, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.6991257667541504 dsc_loss: 1.4005802869796753
TA-VAAL iteration: 10 vae_loss: 1.1367541551589966 dsc_loss: 1.4641716480255127
TA-VAAL iteration: 20 vae_loss: 1.4512231349945068 dsc_loss: 1.4970637559890747
TA-VAAL iteration: 30 vae_loss: 2.101670980453491 dsc_loss: 1.405953288078308
TA-VAAL iteration: 40 vae_loss: 1.7551591396331787 dsc_loss: 1.3861994743347168
TA-VAAL iteration: 50 vae_loss: 1.7997746467590332 dsc_loss: 1.3936665058135986
TA-VAAL iteration: 60 vae_loss: 1.8699736595153809 dsc_loss: 1.3791589736938477
TA-VAAL iteration: 70 vae_loss: 1.9083513021469116 dsc_loss: 1.4990497827529907
TA-VAAL iteration: 80 vae_loss: 1.7439095973968506 dsc_loss: 1.4307396411895752
TA-VAAL iteration: 90 vae_loss: 1.8031582832336426 dsc_loss: 1.382354974746704
TA-VAAL iteration: 100 vae_loss: 1.8718502521514893 dsc_loss: 1.4376051425933838
TA-VAAL iteration: 200 vae_loss: 1.210237979888916 dsc_loss: 1.4209476709365845
TA-VAAL iteration: 300 vae_loss: 1.5667120218276978 dsc_loss: 1.3788106441497803
TA-VAAL iteration: 400 vae_loss: 1.380823016166687 dsc_loss: 1.416372299194336
TA-VAAL iteration: 500 vae_loss: 1.6187118291854858 dsc_loss: 1.3848780393600464
TA-VAAL iteration: 600 vae_loss: 1.3635921478271484 dsc_loss: 1.4002797603607178
TA-VAAL iteration: 700 vae_loss: 1.5691334009170532 dsc_loss: 1.3762325048446655
TA-VAAL iteration: 800 vae_loss: 1.386253833770752 dsc_loss: 1.3561893701553345
TA-VAAL iteration: 900 vae_loss: 1.5550785064697266 dsc_loss: 1.39155912399292
TA-VAAL iteration: 1000 vae_loss: 1.487972378730774 dsc_loss: 1.3823647499084473
TA-VAAL iteration: 1100 vae_loss: 1.5359715223312378 dsc_loss: 1.4166992902755737
TA-VAAL iteration: 1200 vae_loss: 1.6622077226638794 dsc_loss: 1.3991118669509888
TA-VAAL iteration: 1300 vae_loss: 1.4951140880584717 dsc_loss: 1.3915560245513916
TA-VAAL iteration: 1400 vae_loss: 1.5268354415893555 dsc_loss: 1.3906302452087402
TA-VAAL iteration: 1500 vae_loss: 1.4745560884475708 dsc_loss: 1.3889009952545166
TA-VAAL iteration: 1600 vae_loss: 1.6157885789871216 dsc_loss: 1.3892141580581665
TA-VAAL iteration: 1700 vae_loss: 1.5168726444244385 dsc_loss: 1.385216236114502
TA-VAAL iteration: 1800 vae_loss: 1.5353617668151855 dsc_loss: 1.375910997390747
TA-VAAL iteration: 1900 vae_loss: 1.4752020835876465 dsc_loss: 1.3692562580108643
TA-VAAL iteration: 2000 vae_loss: 1.5494173765182495 dsc_loss: 1.3860702514648438
TA-VAAL iteration: 2100 vae_loss: 1.459731936454773 dsc_loss: 1.3896489143371582
TA-VAAL iteration: 2200 vae_loss: 1.5015900135040283 dsc_loss: 1.3913779258728027
TA-VAAL iteration: 2300 vae_loss: 1.6854833364486694 dsc_loss: 1.3999673128128052
TA-VAAL iteration: 2400 vae_loss: 1.4886780977249146 dsc_loss: 1.3984721899032593
TA-VAAL iteration: 2500 vae_loss: 1.5106347799301147 dsc_loss: 1.4150972366333008
TA-VAAL iteration: 2600 vae_loss: 1.5016635656356812 dsc_loss: 1.4035022258758545
TA-VAAL iteration: 2700 vae_loss: 1.5712820291519165 dsc_loss: 1.3826594352722168
TA-VAAL iteration: 2800 vae_loss: 1.488435983657837 dsc_loss: 1.3894912004470825
TA-VAAL iteration: 2900 vae_loss: 1.5548083782196045 dsc_loss: 1.3720247745513916
TA-VAAL iteration: 3000 vae_loss: 1.5509843826293945 dsc_loss: 1.381551742553711
TA-VAAL iteration: 3100 vae_loss: 1.529653787612915 dsc_loss: 1.3876469135284424
TA-VAAL iteration: 3200 vae_loss: 1.4942065477371216 dsc_loss: 1.3869349956512451
TA-VAAL iteration: 3300 vae_loss: 1.563988447189331 dsc_loss: 1.3862462043762207
TA-VAAL iteration: 3400 vae_loss: 1.5290628671646118 dsc_loss: 1.3899625539779663
TA-VAAL iteration: 3500 vae_loss: 1.5783754587173462 dsc_loss: 1.3872461318969727
TA-VAAL iteration: 3600 vae_loss: 1.5310962200164795 dsc_loss: 1.4060804843902588
TA-VAAL iteration: 3700 vae_loss: 1.5252424478530884 dsc_loss: 1.389711856842041
TA-VAAL iteration: 3800 vae_loss: 1.6331725120544434 dsc_loss: 1.3876327276229858
TA-VAAL iteration: 3900 vae_loss: 1.5116900205612183 dsc_loss: 1.384366750717163
TA-VAAL iteration: 4000 vae_loss: 1.566269874572754 dsc_loss: 1.3837988376617432
TA-VAAL iteration: 4100 vae_loss: 1.5285308361053467 dsc_loss: 1.3823143243789673
TA-VAAL iteration: 4200 vae_loss: 1.614452600479126 dsc_loss: 1.4127488136291504
TA-VAAL iteration: 4300 vae_loss: 1.6192383766174316 dsc_loss: 1.3786907196044922
TA-VAAL iteration: 4400 vae_loss: 1.5713495016098022 dsc_loss: 1.3850657939910889
TA-VAAL iteration: 4500 vae_loss: 1.557074785232544 dsc_loss: 1.3900020122528076
TA-VAAL iteration: 4600 vae_loss: 1.5461597442626953 dsc_loss: 1.3893754482269287
TA-VAAL iteration: 4700 vae_loss: 1.5495158433914185 dsc_loss: 1.4153656959533691
TA-VAAL iteration: 4800 vae_loss: 1.5223568677902222 dsc_loss: 1.3920013904571533
TA-VAAL iteration: 4900 vae_loss: 1.713811993598938 dsc_loss: 1.3935215473175049
TA-VAAL iteration: 5000 vae_loss: 1.5509305000305176 dsc_loss: 1.3811204433441162
TA-VAAL iteration: 5100 vae_loss: 1.5755606889724731 dsc_loss: 1.3817057609558105
TA-VAAL iteration: 5200 vae_loss: 1.4481353759765625 dsc_loss: 1.3814228773117065
TA-VAAL iteration: 5300 vae_loss: 1.578426718711853 dsc_loss: 1.3659180402755737
TA-VAAL iteration: 5400 vae_loss: 1.5602748394012451 dsc_loss: 1.3740239143371582
TA-VAAL iteration: 5500 vae_loss: 1.5947527885437012 dsc_loss: 1.381322979927063
TA-VAAL iteration: 5600 vae_loss: 1.5465044975280762 dsc_loss: 1.386833906173706
TA-VAAL iteration: 5700 vae_loss: 1.6121177673339844 dsc_loss: 1.3915679454803467
TA-VAAL iteration: 5800 vae_loss: 1.5988174676895142 dsc_loss: 1.4048981666564941
TA-VAAL iteration: 5900 vae_loss: 1.5887682437896729 dsc_loss: 1.3923726081848145
TA-VAAL iteration: 6000 vae_loss: 1.5984735488891602 dsc_loss: 1.3939838409423828
TA-VAAL iteration: 6100 vae_loss: 1.5692623853683472 dsc_loss: 1.3865861892700195
TA-VAAL iteration: 6200 vae_loss: 1.7529314756393433 dsc_loss: 1.3844079971313477
TA-VAAL iteration: 6300 vae_loss: 1.5876203775405884 dsc_loss: 1.357303261756897
TA-VAAL iteration: 6400 vae_loss: 1.6472187042236328 dsc_loss: 1.3871638774871826
TA-VAAL iteration: 6500 vae_loss: 1.5878989696502686 dsc_loss: 1.3817172050476074
TA-VAAL iteration: 6600 vae_loss: 1.6866652965545654 dsc_loss: 1.376459002494812
TA-VAAL iteration: 6700 vae_loss: 1.6309239864349365 dsc_loss: 1.3854718208312988
TA-VAAL iteration: 6800 vae_loss: 1.6205157041549683 dsc_loss: 1.3806872367858887
TA-VAAL iteration: 6900 vae_loss: 1.6506646871566772 dsc_loss: 1.4097306728363037
TA-VAAL iteration: 7000 vae_loss: 1.6071805953979492 dsc_loss: 1.3976032733917236
TA-VAAL iteration: 7100 vae_loss: 1.6685514450073242 dsc_loss: 1.386199712753296
TA-VAAL iteration: 7200 vae_loss: 1.6035956144332886 dsc_loss: 1.3844022750854492
TA-VAAL iteration: 7300 vae_loss: 1.6778026819229126 dsc_loss: 1.3805540800094604
TA-VAAL iteration: 7400 vae_loss: 1.5513441562652588 dsc_loss: 1.3796577453613281
TA-VAAL iteration: 7500 vae_loss: 1.6818230152130127 dsc_loss: 1.3950653076171875
TA-VAAL iteration: 7600 vae_loss: 1.595839262008667 dsc_loss: 1.3674341440200806
TA-VAAL iteration: 7700 vae_loss: 1.6033321619033813 dsc_loss: 1.3845175504684448
1600 105508 100 107099
>> Train vae and task model
epoch 0: train loss is  1.48586
epoch 10: train loss is  1.33119
epoch 20: train loss is  1.26925
epoch 30: train loss is  1.18787
epoch 40: train loss is  1.18052
epoch 50: train loss is  1.15912
epoch 60: train loss is  1.14671
epoch 70: train loss is  1.10183
epoch 80: train loss is  1.07921
epoch 90: train loss is  1.09802
epoch 100: train loss is  1.07504
epoch 110: train loss is  1.08742
epoch 120: train loss is  1.08590
 >> Test Model
Cycle 8/10 || labeled data size 1600, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.7396564483642578 dsc_loss: 1.3967556953430176
TA-VAAL iteration: 10 vae_loss: 1.6443170309066772 dsc_loss: 1.3134346008300781
TA-VAAL iteration: 20 vae_loss: 1.554049015045166 dsc_loss: 1.513124942779541
TA-VAAL iteration: 30 vae_loss: 1.6908522844314575 dsc_loss: 1.3798736333847046
TA-VAAL iteration: 40 vae_loss: 1.7513682842254639 dsc_loss: 1.3930213451385498
TA-VAAL iteration: 50 vae_loss: 1.9686386585235596 dsc_loss: 1.4115647077560425
TA-VAAL iteration: 60 vae_loss: 1.7060184478759766 dsc_loss: 1.356654167175293
TA-VAAL iteration: 70 vae_loss: 1.707836627960205 dsc_loss: 1.4606778621673584
TA-VAAL iteration: 80 vae_loss: 1.9742796421051025 dsc_loss: 1.3270022869110107
TA-VAAL iteration: 90 vae_loss: 1.936737298965454 dsc_loss: 1.433834195137024
TA-VAAL iteration: 100 vae_loss: 1.902003288269043 dsc_loss: 1.378006935119629
TA-VAAL iteration: 200 vae_loss: 1.8133478164672852 dsc_loss: 1.386672854423523
TA-VAAL iteration: 300 vae_loss: 1.6473464965820312 dsc_loss: 1.393012523651123
TA-VAAL iteration: 400 vae_loss: 1.5749891996383667 dsc_loss: 1.3997701406478882
TA-VAAL iteration: 500 vae_loss: 1.564499020576477 dsc_loss: 1.3956286907196045
TA-VAAL iteration: 600 vae_loss: 1.5636515617370605 dsc_loss: 1.3799023628234863
TA-VAAL iteration: 700 vae_loss: 1.592564582824707 dsc_loss: 1.3903850317001343
TA-VAAL iteration: 800 vae_loss: 1.5411194562911987 dsc_loss: 1.4073004722595215
TA-VAAL iteration: 900 vae_loss: 1.7244700193405151 dsc_loss: 1.4010345935821533
TA-VAAL iteration: 1000 vae_loss: 1.5496952533721924 dsc_loss: 1.391451358795166
TA-VAAL iteration: 1100 vae_loss: 1.5801312923431396 dsc_loss: 1.3936680555343628
TA-VAAL iteration: 1200 vae_loss: 1.6233632564544678 dsc_loss: 1.3877513408660889
TA-VAAL iteration: 1300 vae_loss: 1.5783997774124146 dsc_loss: 1.3953644037246704
TA-VAAL iteration: 1400 vae_loss: 1.6554065942764282 dsc_loss: 1.3903447389602661
TA-VAAL iteration: 1500 vae_loss: 1.6000734567642212 dsc_loss: 1.3858410120010376
TA-VAAL iteration: 1600 vae_loss: 1.5706180334091187 dsc_loss: 1.3897733688354492
TA-VAAL iteration: 1700 vae_loss: 1.5726348161697388 dsc_loss: 1.3826098442077637
TA-VAAL iteration: 1800 vae_loss: 1.5928122997283936 dsc_loss: 1.38954496383667
TA-VAAL iteration: 1900 vae_loss: 1.5866169929504395 dsc_loss: 1.4013702869415283
TA-VAAL iteration: 2000 vae_loss: 1.6711666584014893 dsc_loss: 1.393113613128662
TA-VAAL iteration: 2100 vae_loss: 1.6858662366867065 dsc_loss: 1.3853487968444824
TA-VAAL iteration: 2200 vae_loss: 1.6628438234329224 dsc_loss: 1.3921427726745605
TA-VAAL iteration: 2300 vae_loss: 1.6267633438110352 dsc_loss: 1.3847315311431885
TA-VAAL iteration: 2400 vae_loss: 1.6076527833938599 dsc_loss: 1.3933533430099487
TA-VAAL iteration: 2500 vae_loss: 1.6344261169433594 dsc_loss: 1.3913520574569702
TA-VAAL iteration: 2600 vae_loss: 1.6237438917160034 dsc_loss: 1.3855855464935303
TA-VAAL iteration: 2700 vae_loss: 1.6470887660980225 dsc_loss: 1.3813823461532593
TA-VAAL iteration: 2800 vae_loss: 1.716160535812378 dsc_loss: 1.3881547451019287
TA-VAAL iteration: 2900 vae_loss: 1.7188622951507568 dsc_loss: 1.3896559476852417
TA-VAAL iteration: 3000 vae_loss: 1.7132627964019775 dsc_loss: 1.3937878608703613
TA-VAAL iteration: 3100 vae_loss: 1.7049349546432495 dsc_loss: 1.393304467201233
TA-VAAL iteration: 3200 vae_loss: 1.7161059379577637 dsc_loss: 1.387730598449707
TA-VAAL iteration: 3300 vae_loss: 1.7168503999710083 dsc_loss: 1.396926760673523
TA-VAAL iteration: 3400 vae_loss: 1.7069220542907715 dsc_loss: 1.3912084102630615
TA-VAAL iteration: 3500 vae_loss: 1.7516319751739502 dsc_loss: 1.388787031173706
TA-VAAL iteration: 3600 vae_loss: 1.7750003337860107 dsc_loss: 1.3846255540847778
TA-VAAL iteration: 3700 vae_loss: 1.7464491128921509 dsc_loss: 1.3826223611831665
TA-VAAL iteration: 3800 vae_loss: 1.776838779449463 dsc_loss: 1.3853449821472168
TA-VAAL iteration: 3900 vae_loss: 1.760804533958435 dsc_loss: 1.3867459297180176
TA-VAAL iteration: 4000 vae_loss: 1.7913775444030762 dsc_loss: 1.392427682876587
TA-VAAL iteration: 4100 vae_loss: 1.7484583854675293 dsc_loss: 1.3862557411193848
TA-VAAL iteration: 4200 vae_loss: 1.7747752666473389 dsc_loss: 1.38363516330719
TA-VAAL iteration: 4300 vae_loss: 1.7912592887878418 dsc_loss: 1.3967597484588623
TA-VAAL iteration: 4400 vae_loss: 1.7941386699676514 dsc_loss: 1.3914339542388916
TA-VAAL iteration: 4500 vae_loss: 1.8294954299926758 dsc_loss: 1.3842899799346924
TA-VAAL iteration: 4600 vae_loss: 1.8015451431274414 dsc_loss: 1.3811538219451904
TA-VAAL iteration: 4700 vae_loss: 1.7510170936584473 dsc_loss: 1.3869117498397827
TA-VAAL iteration: 4800 vae_loss: 1.8122501373291016 dsc_loss: 1.3930001258850098
TA-VAAL iteration: 4900 vae_loss: 1.8053691387176514 dsc_loss: 1.3899692296981812
TA-VAAL iteration: 5000 vae_loss: 1.7944602966308594 dsc_loss: 1.3918159008026123
TA-VAAL iteration: 5100 vae_loss: 1.7854294776916504 dsc_loss: 1.3948800563812256
TA-VAAL iteration: 5200 vae_loss: 1.887756586074829 dsc_loss: 1.3919951915740967
TA-VAAL iteration: 5300 vae_loss: 1.8175597190856934 dsc_loss: 1.3915011882781982
TA-VAAL iteration: 5400 vae_loss: 1.937597632408142 dsc_loss: 1.3921843767166138
TA-VAAL iteration: 5500 vae_loss: 1.832829236984253 dsc_loss: 1.3973910808563232
TA-VAAL iteration: 5600 vae_loss: 1.9309380054473877 dsc_loss: 1.389264702796936
TA-VAAL iteration: 5700 vae_loss: 1.9196593761444092 dsc_loss: 1.3904449939727783
TA-VAAL iteration: 5800 vae_loss: 1.827423095703125 dsc_loss: 1.3941218852996826
TA-VAAL iteration: 5900 vae_loss: 1.7807689905166626 dsc_loss: 1.3991928100585938
TA-VAAL iteration: 6000 vae_loss: 1.8554627895355225 dsc_loss: 1.3894929885864258
TA-VAAL iteration: 6100 vae_loss: 1.9309048652648926 dsc_loss: 1.3857219219207764
TA-VAAL iteration: 6200 vae_loss: 1.9674692153930664 dsc_loss: 1.3857498168945312
TA-VAAL iteration: 6300 vae_loss: 2.0416550636291504 dsc_loss: 1.3905515670776367
TA-VAAL iteration: 6400 vae_loss: 1.9664034843444824 dsc_loss: 1.3831207752227783
TA-VAAL iteration: 6500 vae_loss: 1.9647397994995117 dsc_loss: 1.3798108100891113
TA-VAAL iteration: 6600 vae_loss: 1.9337224960327148 dsc_loss: 1.3857585191726685
TA-VAAL iteration: 6700 vae_loss: 2.0809013843536377 dsc_loss: 1.3931840658187866
TA-VAAL iteration: 6800 vae_loss: 1.9520223140716553 dsc_loss: 1.387580156326294
TA-VAAL iteration: 6900 vae_loss: 1.9981755018234253 dsc_loss: 1.3883485794067383
TA-VAAL iteration: 7000 vae_loss: 1.942724347114563 dsc_loss: 1.3856468200683594
TA-VAAL iteration: 7100 vae_loss: 1.9784730672836304 dsc_loss: 1.395039677619934
TA-VAAL iteration: 7200 vae_loss: 2.0022671222686768 dsc_loss: 1.3909344673156738
TA-VAAL iteration: 7300 vae_loss: 1.9783540964126587 dsc_loss: 1.3829548358917236
TA-VAAL iteration: 7400 vae_loss: 2.0529356002807617 dsc_loss: 1.3908716440200806
TA-VAAL iteration: 7500 vae_loss: 2.088585376739502 dsc_loss: 1.3902462720870972
TA-VAAL iteration: 7600 vae_loss: 1.977067470550537 dsc_loss: 1.3913995027542114
TA-VAAL iteration: 7700 vae_loss: 2.006765842437744 dsc_loss: 1.3881217241287231
TA-VAAL iteration: 7800 vae_loss: 2.0655808448791504 dsc_loss: 1.3872181177139282
TA-VAAL iteration: 7900 vae_loss: 2.124868869781494 dsc_loss: 1.3895703554153442
1800 105308 100 107099
>> Train vae and task model
epoch 0: train loss is  1.55174
epoch 10: train loss is  1.39240
epoch 20: train loss is  1.36753
epoch 30: train loss is  1.32469
epoch 40: train loss is  1.33202
epoch 50: train loss is  1.23833
epoch 60: train loss is  1.23059
epoch 70: train loss is  1.23941
epoch 80: train loss is  1.24996
epoch 90: train loss is  1.23510
epoch 100: train loss is  1.18587
epoch 110: train loss is  1.18072
epoch 120: train loss is  1.14002
 >> Test Model
Cycle 9/10 || labeled data size 1800, test loss(MAE) =  0.72258
TA-VAAL iteration: 0 vae_loss: 1.740840196609497 dsc_loss: 1.40303373336792
TA-VAAL iteration: 10 vae_loss: 1.7623614072799683 dsc_loss: 1.366112232208252
TA-VAAL iteration: 20 vae_loss: 1.867629051208496 dsc_loss: 1.4435951709747314
TA-VAAL iteration: 30 vae_loss: 2.2138659954071045 dsc_loss: 1.453162431716919
TA-VAAL iteration: 40 vae_loss: 2.1387455463409424 dsc_loss: 1.4363977909088135
TA-VAAL iteration: 50 vae_loss: 1.8573224544525146 dsc_loss: 1.47767174243927
TA-VAAL iteration: 60 vae_loss: 1.878030776977539 dsc_loss: 1.4389700889587402
TA-VAAL iteration: 70 vae_loss: 1.6140867471694946 dsc_loss: 1.4515380859375
TA-VAAL iteration: 80 vae_loss: 1.801367998123169 dsc_loss: 1.3831539154052734
TA-VAAL iteration: 90 vae_loss: 1.7595053911209106 dsc_loss: 1.5547846555709839
TA-VAAL iteration: 100 vae_loss: 1.476729154586792 dsc_loss: 1.4649968147277832
TA-VAAL iteration: 200 vae_loss: 1.587135672569275 dsc_loss: 1.3879594802856445
TA-VAAL iteration: 300 vae_loss: 1.5105935335159302 dsc_loss: 1.3420741558074951
TA-VAAL iteration: 400 vae_loss: 1.5256332159042358 dsc_loss: 1.381213665008545
TA-VAAL iteration: 500 vae_loss: 1.4985086917877197 dsc_loss: 1.2872288227081299
TA-VAAL iteration: 600 vae_loss: 1.3960078954696655 dsc_loss: 1.3818554878234863
TA-VAAL iteration: 700 vae_loss: 1.7369892597198486 dsc_loss: 1.4333624839782715
TA-VAAL iteration: 800 vae_loss: 1.517853856086731 dsc_loss: 1.4455605745315552
TA-VAAL iteration: 900 vae_loss: 1.538550853729248 dsc_loss: 1.3642290830612183
TA-VAAL iteration: 1000 vae_loss: 1.601772427558899 dsc_loss: 1.4398815631866455
TA-VAAL iteration: 1100 vae_loss: 1.3700425624847412 dsc_loss: 1.2825353145599365
TA-VAAL iteration: 1200 vae_loss: 1.6210187673568726 dsc_loss: 1.4655276536941528
TA-VAAL iteration: 1300 vae_loss: 1.5788583755493164 dsc_loss: 1.3860225677490234
TA-VAAL iteration: 1400 vae_loss: 1.5774121284484863 dsc_loss: 1.3145737648010254
TA-VAAL iteration: 1500 vae_loss: 1.5904639959335327 dsc_loss: 1.3166592121124268
TA-VAAL iteration: 1600 vae_loss: 1.5589971542358398 dsc_loss: 1.4263203144073486
TA-VAAL iteration: 1700 vae_loss: 1.6060584783554077 dsc_loss: 1.403262972831726
TA-VAAL iteration: 1800 vae_loss: 1.5855932235717773 dsc_loss: 1.3808512687683105
TA-VAAL iteration: 1900 vae_loss: 1.6209945678710938 dsc_loss: 1.4768425226211548
TA-VAAL iteration: 2000 vae_loss: 1.434880256652832 dsc_loss: 1.2189217805862427
TA-VAAL iteration: 2100 vae_loss: 1.6453831195831299 dsc_loss: 1.3752186298370361
TA-VAAL iteration: 2200 vae_loss: 1.4195572137832642 dsc_loss: 1.3010585308074951
TA-VAAL iteration: 2300 vae_loss: 1.698441982269287 dsc_loss: 1.3612031936645508
TA-VAAL iteration: 2400 vae_loss: 1.5758440494537354 dsc_loss: 1.3618825674057007
TA-VAAL iteration: 2500 vae_loss: 1.5296212434768677 dsc_loss: 1.3608232736587524
TA-VAAL iteration: 2600 vae_loss: 1.601230263710022 dsc_loss: 1.3168878555297852
TA-VAAL iteration: 2700 vae_loss: 1.623261570930481 dsc_loss: 1.417172908782959
TA-VAAL iteration: 2800 vae_loss: 1.5038121938705444 dsc_loss: 1.4283045530319214
TA-VAAL iteration: 2900 vae_loss: 1.508239984512329 dsc_loss: 1.390056848526001
TA-VAAL iteration: 3000 vae_loss: 1.5794720649719238 dsc_loss: 1.4664922952651978
TA-VAAL iteration: 3100 vae_loss: 1.8857650756835938 dsc_loss: 1.3389500379562378
TA-VAAL iteration: 3200 vae_loss: 1.5672121047973633 dsc_loss: 1.399623155593872
TA-VAAL iteration: 3300 vae_loss: 1.5306496620178223 dsc_loss: 1.4190667867660522
TA-VAAL iteration: 3400 vae_loss: 1.44028902053833 dsc_loss: 1.2795300483703613
TA-VAAL iteration: 3500 vae_loss: 1.9499971866607666 dsc_loss: 1.4298717975616455
TA-VAAL iteration: 3600 vae_loss: 1.5767707824707031 dsc_loss: 1.423370361328125
TA-VAAL iteration: 3700 vae_loss: 1.5992178916931152 dsc_loss: 1.4154635667800903
TA-VAAL iteration: 3800 vae_loss: 1.5617492198944092 dsc_loss: 1.418001413345337
TA-VAAL iteration: 3900 vae_loss: 1.6716456413269043 dsc_loss: 1.443694829940796
TA-VAAL iteration: 4000 vae_loss: 1.4869965314865112 dsc_loss: 1.2746961116790771
TA-VAAL iteration: 4100 vae_loss: 1.6150572299957275 dsc_loss: 1.4332709312438965
TA-VAAL iteration: 4200 vae_loss: 1.6586955785751343 dsc_loss: 1.4551156759262085
TA-VAAL iteration: 4300 vae_loss: 1.541783332824707 dsc_loss: 1.287440538406372
TA-VAAL iteration: 4400 vae_loss: 1.5420902967453003 dsc_loss: 1.323709487915039
TA-VAAL iteration: 4500 vae_loss: 1.6420652866363525 dsc_loss: 1.4027788639068604
TA-VAAL iteration: 4600 vae_loss: 1.7749210596084595 dsc_loss: 1.3765369653701782
TA-VAAL iteration: 4700 vae_loss: 1.6445293426513672 dsc_loss: 1.3924882411956787
TA-VAAL iteration: 4800 vae_loss: 1.612837791442871 dsc_loss: 1.4177289009094238
TA-VAAL iteration: 4900 vae_loss: 1.4157408475875854 dsc_loss: 1.1068956851959229
TA-VAAL iteration: 5000 vae_loss: 1.6574357748031616 dsc_loss: 1.4185384511947632
TA-VAAL iteration: 5100 vae_loss: 1.5613764524459839 dsc_loss: 1.3549072742462158
TA-VAAL iteration: 5200 vae_loss: 1.5567400455474854 dsc_loss: 1.3564457893371582
TA-VAAL iteration: 5300 vae_loss: 1.674727201461792 dsc_loss: 1.4506428241729736
TA-VAAL iteration: 5400 vae_loss: 1.6014295816421509 dsc_loss: 1.3768045902252197
TA-VAAL iteration: 5500 vae_loss: 1.5712063312530518 dsc_loss: 1.3189005851745605
TA-VAAL iteration: 5600 vae_loss: 1.5973855257034302 dsc_loss: 1.417281985282898
TA-VAAL iteration: 5700 vae_loss: 1.6339890956878662 dsc_loss: 1.3756405115127563
TA-VAAL iteration: 5800 vae_loss: 1.6339483261108398 dsc_loss: 1.3957140445709229
TA-VAAL iteration: 5900 vae_loss: 1.8258103132247925 dsc_loss: 1.4157533645629883
TA-VAAL iteration: 6000 vae_loss: 1.5259023904800415 dsc_loss: 1.2603321075439453
TA-VAAL iteration: 6100 vae_loss: 1.5882648229599 dsc_loss: 1.3834221363067627
TA-VAAL iteration: 6200 vae_loss: 1.631363868713379 dsc_loss: 1.3902912139892578
TA-VAAL iteration: 6300 vae_loss: 1.7316535711288452 dsc_loss: 1.2758910655975342
TA-VAAL iteration: 6400 vae_loss: 1.7084715366363525 dsc_loss: 1.343785285949707
TA-VAAL iteration: 6500 vae_loss: 1.735978364944458 dsc_loss: 1.3984416723251343
TA-VAAL iteration: 6600 vae_loss: 1.6527197360992432 dsc_loss: 1.4478484392166138
TA-VAAL iteration: 6700 vae_loss: 1.6539900302886963 dsc_loss: 1.3769078254699707
TA-VAAL iteration: 6800 vae_loss: 1.7954463958740234 dsc_loss: 1.464759111404419
TA-VAAL iteration: 6900 vae_loss: 1.5981523990631104 dsc_loss: 1.2226595878601074
TA-VAAL iteration: 7000 vae_loss: 1.7075271606445312 dsc_loss: 1.4269704818725586
TA-VAAL iteration: 7100 vae_loss: 1.7151933908462524 dsc_loss: 1.4137043952941895
TA-VAAL iteration: 7200 vae_loss: 1.6426434516906738 dsc_loss: 1.2898707389831543
TA-VAAL iteration: 7300 vae_loss: 1.6867146492004395 dsc_loss: 1.361910343170166
TA-VAAL iteration: 7400 vae_loss: 1.6517266035079956 dsc_loss: 1.4380366802215576
TA-VAAL iteration: 7500 vae_loss: 1.7268060445785522 dsc_loss: 1.3864800930023193
TA-VAAL iteration: 7600 vae_loss: 1.6306723356246948 dsc_loss: 1.4512224197387695
TA-VAAL iteration: 7700 vae_loss: 1.740572214126587 dsc_loss: 1.3771501779556274
TA-VAAL iteration: 7800 vae_loss: 1.3099994659423828 dsc_loss: 1.0953315496444702
TA-VAAL iteration: 7900 vae_loss: 1.6657540798187256 dsc_loss: 1.3878960609436035
TA-VAAL iteration: 8000 vae_loss: 1.6092381477355957 dsc_loss: 1.285306692123413
TA-VAAL iteration: 8100 vae_loss: 1.6195873022079468 dsc_loss: 1.342908501625061
TA-VAAL iteration: 8200 vae_loss: 1.724915623664856 dsc_loss: 1.3998130559921265
2000 105108 100 107099
>> Train vae and task model
epoch 0: train loss is  1.54646
epoch 10: train loss is  1.39602
epoch 20: train loss is  1.33900
epoch 30: train loss is  1.31243
epoch 40: train loss is  1.30637
epoch 50: train loss is  1.25006
epoch 60: train loss is  1.22252
epoch 70: train loss is  1.23243
epoch 80: train loss is  1.23112
epoch 90: train loss is  1.20241
epoch 100: train loss is  1.18335
epoch 110: train loss is  1.18725
epoch 120: train loss is  1.16387
 >> Test Model
Cycle 10/10 || labeled data size 2000, test loss(MAE) =  0.72258
Finished.
