>> Train vae and task model
epoch 20, vae loss is 0.057871803641319275
epoch 40, vae loss is 0.05082477256655693
epoch 60, vae loss is 0.03625068441033363
epoch 80, vae loss is 0.0342441201210022
epoch 100, vae loss is 0.03355076536536217
epoch 0:  train loss is 8.336463451385498, train roc is  0.5031, train_prc:  0.5169
epoch 20:  train loss is 8.251698970794678, train roc is  0.5592, train_prc:  0.4629
epoch 40:  train loss is 8.111162066459656, train roc is  0.5580, train_prc:  0.4387
epoch 60:  train loss is 8.029446840286255, train roc is  0.5651, train_prc:  0.4434
epoch 80:  train loss is 7.963167667388916, train roc is  0.5642, train_prc:  0.4429
 >> Test Model
Cycle 1/5 || labeled data size 256, test roc =  0.6217, test prc =  0.2588
VAAL iteration: 0 vae_loss: 1.4845207929611206 dsc_loss: 1.4034228324890137
VAAL iteration: 100 vae_loss: 1.4847804307937622 dsc_loss: 1.3864102363586426
VAAL iteration: 200 vae_loss: 1.5917452573776245 dsc_loss: 1.386650562286377
VAAL iteration: 300 vae_loss: 1.5353381633758545 dsc_loss: 1.3855329751968384
VAAL iteration: 400 vae_loss: 1.4966243505477905 dsc_loss: 1.3837010860443115
VAAL iteration: 500 vae_loss: 1.8465572595596313 dsc_loss: 1.3899874687194824
VAAL iteration: 600 vae_loss: 1.61451256275177 dsc_loss: 1.381173014640808
VAAL iteration: 700 vae_loss: 1.6508100032806396 dsc_loss: 1.3844342231750488
VAAL iteration: 800 vae_loss: 1.6149851083755493 dsc_loss: 1.3838675022125244
VAAL iteration: 900 vae_loss: 1.6088627576828003 dsc_loss: 1.3871606588363647
VAAL iteration: 1000 vae_loss: 1.840712308883667 dsc_loss: 1.386040449142456
VAAL iteration: 1100 vae_loss: 1.623661756515503 dsc_loss: 1.378096580505371
VAAL iteration: 1200 vae_loss: 1.7400332689285278 dsc_loss: 1.3848769664764404
VAAL iteration: 1300 vae_loss: 1.7760593891143799 dsc_loss: 1.3832918405532837
VAAL iteration: 1400 vae_loss: 1.76616632938385 dsc_loss: 1.3855760097503662
VAAL iteration: 1500 vae_loss: 1.9830601215362549 dsc_loss: 1.3901952505111694
VAAL iteration: 1600 vae_loss: 1.6774238348007202 dsc_loss: 1.3873835802078247
VAAL iteration: 1700 vae_loss: 1.6554651260375977 dsc_loss: 1.3873248100280762
VAAL iteration: 1800 vae_loss: 1.7387208938598633 dsc_loss: 1.3863950967788696
VAAL iteration: 1900 vae_loss: 1.7545301914215088 dsc_loss: 1.3860905170440674
VAAL iteration: 2000 vae_loss: 1.799696445465088 dsc_loss: 1.3851029872894287
VAAL iteration: 2100 vae_loss: 1.8448930978775024 dsc_loss: 1.3841965198516846
VAAL iteration: 2200 vae_loss: 1.855727195739746 dsc_loss: 1.38675856590271
VAAL iteration: 2300 vae_loss: 1.771063208580017 dsc_loss: 1.3863654136657715
VAAL iteration: 2400 vae_loss: 1.6832259893417358 dsc_loss: 1.3869572877883911
VAAL iteration: 2500 vae_loss: 1.83278489112854 dsc_loss: 1.3862981796264648
VAAL iteration: 2600 vae_loss: 1.9215164184570312 dsc_loss: 1.3928587436676025
VAAL iteration: 2700 vae_loss: 1.7242761850357056 dsc_loss: 1.385778784751892
VAAL iteration: 2800 vae_loss: 1.8641188144683838 dsc_loss: 1.3833141326904297
VAAL iteration: 2900 vae_loss: 1.941729187965393 dsc_loss: 1.3892505168914795
VAAL iteration: 3000 vae_loss: 2.019404172897339 dsc_loss: 1.3903266191482544
VAAL iteration: 3100 vae_loss: 1.831791639328003 dsc_loss: 1.3852858543395996
VAAL iteration: 3200 vae_loss: 1.7956552505493164 dsc_loss: 1.3870917558670044
VAAL iteration: 3300 vae_loss: 1.9255884885787964 dsc_loss: 1.3910408020019531
VAAL iteration: 3400 vae_loss: 1.833483338356018 dsc_loss: 1.3831987380981445
VAAL iteration: 3500 vae_loss: 1.9189485311508179 dsc_loss: 1.3844653367996216
VAAL iteration: 3600 vae_loss: 2.028506278991699 dsc_loss: 1.3859891891479492
VAAL iteration: 3700 vae_loss: 1.7483566999435425 dsc_loss: 1.38685142993927
VAAL iteration: 3800 vae_loss: 1.869208574295044 dsc_loss: 1.3838653564453125
VAAL iteration: 3900 vae_loss: 2.157741069793701 dsc_loss: 1.387911081314087
VAAL iteration: 4000 vae_loss: 1.822422981262207 dsc_loss: 1.3871467113494873
VAAL iteration: 4100 vae_loss: 1.7560184001922607 dsc_loss: 1.386635661125183
VAAL iteration: 4200 vae_loss: 1.800239086151123 dsc_loss: 1.3862624168395996
VAAL iteration: 4300 vae_loss: 1.9256304502487183 dsc_loss: 1.3872557878494263
VAAL iteration: 4400 vae_loss: 1.9335676431655884 dsc_loss: 1.3864774703979492
VAAL iteration: 4500 vae_loss: 1.9441227912902832 dsc_loss: 1.386029839515686
VAAL iteration: 4600 vae_loss: 1.8630880117416382 dsc_loss: 1.385331153869629
VAAL iteration: 4700 vae_loss: 1.7324087619781494 dsc_loss: 1.3878979682922363
VAAL iteration: 4800 vae_loss: 1.7681639194488525 dsc_loss: 1.3828589916229248
VAAL iteration: 4900 vae_loss: 1.7751734256744385 dsc_loss: 1.3863911628723145
VAAL iteration: 5000 vae_loss: 1.9876898527145386 dsc_loss: 1.3879252672195435
VAAL iteration: 5100 vae_loss: 1.8534750938415527 dsc_loss: 1.38645339012146
VAAL iteration: 5200 vae_loss: 1.838261365890503 dsc_loss: 1.3861608505249023
VAAL iteration: 5300 vae_loss: 1.8036084175109863 dsc_loss: 1.3845819234848022
VAAL iteration: 5400 vae_loss: 1.8329263925552368 dsc_loss: 1.385967493057251
VAAL iteration: 5500 vae_loss: 1.8114945888519287 dsc_loss: 1.386838436126709
VAAL iteration: 5600 vae_loss: 1.8409960269927979 dsc_loss: 1.386461853981018
VAAL iteration: 5700 vae_loss: 1.8522851467132568 dsc_loss: 1.387143850326538
VAAL iteration: 5800 vae_loss: 1.7798686027526855 dsc_loss: 1.387772560119629
VAAL iteration: 5900 vae_loss: 1.8064851760864258 dsc_loss: 1.3840692043304443
VAAL iteration: 6000 vae_loss: 1.769463300704956 dsc_loss: 1.3891704082489014
VAAL iteration: 6100 vae_loss: 1.9220967292785645 dsc_loss: 1.3871543407440186
VAAL iteration: 6200 vae_loss: 1.8484742641448975 dsc_loss: 1.3895448446273804
VAAL iteration: 6300 vae_loss: 1.8485995531082153 dsc_loss: 1.3878228664398193
VAAL iteration: 6400 vae_loss: 1.7974591255187988 dsc_loss: 1.3886934518814087
VAAL iteration: 6500 vae_loss: 1.8800480365753174 dsc_loss: 1.3859918117523193
VAAL iteration: 6600 vae_loss: 2.0310158729553223 dsc_loss: 1.384808897972107
VAAL iteration: 6700 vae_loss: 1.989883303642273 dsc_loss: 1.3856329917907715
VAAL iteration: 6800 vae_loss: 1.9857805967330933 dsc_loss: 1.3866381645202637
VAAL iteration: 6900 vae_loss: 1.739319086074829 dsc_loss: 1.3882256746292114
VAAL iteration: 7000 vae_loss: 1.8355262279510498 dsc_loss: 1.38576340675354
VAAL iteration: 7100 vae_loss: 1.763393759727478 dsc_loss: 1.386535882949829
VAAL iteration: 7200 vae_loss: 1.8304685354232788 dsc_loss: 1.3859655857086182
VAAL iteration: 7300 vae_loss: 1.863854169845581 dsc_loss: 1.3852603435516357
VAAL iteration: 7400 vae_loss: 1.9682515859603882 dsc_loss: 1.3857513666152954
512 5720 19 6219
>> Train vae and task model
epoch 20, vae loss is 0.1363276094198227
epoch 40, vae loss is 0.11141622811555862
epoch 60, vae loss is 0.09933950006961823
epoch 80, vae loss is 0.09940455108880997
epoch 100, vae loss is 0.09725780040025711
epoch 0:  train loss is 8.322105050086975, train roc is  0.5056, train_prc:  0.4985
epoch 20:  train loss is 8.06264853477478, train roc is  0.5464, train_prc:  0.4233
epoch 40:  train loss is 7.987347424030304, train roc is  0.5520, train_prc:  0.4263
epoch 60:  train loss is 7.926367700099945, train roc is  0.5590, train_prc:  0.4315
epoch 80:  train loss is 7.879424571990967, train roc is  0.5606, train_prc:  0.4326
 >> Test Model
Cycle 2/5 || labeled data size 512, test roc =  0.6225, test prc =  0.2014
VAAL iteration: 0 vae_loss: 1.5095560550689697 dsc_loss: 1.398371934890747
VAAL iteration: 100 vae_loss: 1.5673198699951172 dsc_loss: 1.387204885482788
VAAL iteration: 200 vae_loss: 1.5407397747039795 dsc_loss: 1.3837183713912964
VAAL iteration: 300 vae_loss: 1.744927167892456 dsc_loss: 1.3854780197143555
VAAL iteration: 400 vae_loss: 1.7777900695800781 dsc_loss: 1.3839614391326904
VAAL iteration: 500 vae_loss: 1.7121485471725464 dsc_loss: 1.3821961879730225
VAAL iteration: 600 vae_loss: 1.7204985618591309 dsc_loss: 1.3900604248046875
VAAL iteration: 700 vae_loss: 2.1320881843566895 dsc_loss: 1.3891682624816895
VAAL iteration: 800 vae_loss: 1.890366792678833 dsc_loss: 1.385099172592163
VAAL iteration: 900 vae_loss: 1.7649165391921997 dsc_loss: 1.3883440494537354
VAAL iteration: 1000 vae_loss: 1.8123530149459839 dsc_loss: 1.3868135213851929
VAAL iteration: 1100 vae_loss: 1.8306318521499634 dsc_loss: 1.3832148313522339
VAAL iteration: 1200 vae_loss: 1.7693169116973877 dsc_loss: 1.387730598449707
VAAL iteration: 1300 vae_loss: 1.948466181755066 dsc_loss: 1.386344075202942
VAAL iteration: 1400 vae_loss: 1.986064076423645 dsc_loss: 1.385107159614563
VAAL iteration: 1500 vae_loss: 2.008911371231079 dsc_loss: 1.3856263160705566
VAAL iteration: 1600 vae_loss: 1.9068739414215088 dsc_loss: 1.3855159282684326
VAAL iteration: 1700 vae_loss: 1.9855749607086182 dsc_loss: 1.382504940032959
VAAL iteration: 1800 vae_loss: 1.9233959913253784 dsc_loss: 1.3842467069625854
VAAL iteration: 1900 vae_loss: 1.9130525588989258 dsc_loss: 1.3859684467315674
VAAL iteration: 2000 vae_loss: 1.8772140741348267 dsc_loss: 1.3854382038116455
VAAL iteration: 2100 vae_loss: 1.9152921438217163 dsc_loss: 1.3875195980072021
VAAL iteration: 2200 vae_loss: 1.914005994796753 dsc_loss: 1.3861308097839355
VAAL iteration: 2300 vae_loss: 2.038193702697754 dsc_loss: 1.386685848236084
VAAL iteration: 2400 vae_loss: 1.927622675895691 dsc_loss: 1.387231707572937
VAAL iteration: 2500 vae_loss: 1.9759974479675293 dsc_loss: 1.3862193822860718
VAAL iteration: 2600 vae_loss: 1.9287819862365723 dsc_loss: 1.3871245384216309
VAAL iteration: 2700 vae_loss: 1.9420256614685059 dsc_loss: 1.3859953880310059
VAAL iteration: 2800 vae_loss: 1.8678953647613525 dsc_loss: 1.3856055736541748
VAAL iteration: 2900 vae_loss: 1.8768258094787598 dsc_loss: 1.3856765031814575
VAAL iteration: 3000 vae_loss: 1.9138954877853394 dsc_loss: 1.3861844539642334
VAAL iteration: 3100 vae_loss: 1.9090824127197266 dsc_loss: 1.3866249322891235
VAAL iteration: 3200 vae_loss: 1.8807294368743896 dsc_loss: 1.3864681720733643
VAAL iteration: 3300 vae_loss: 1.9055464267730713 dsc_loss: 1.3862504959106445
VAAL iteration: 3400 vae_loss: 1.8684037923812866 dsc_loss: 1.3862735033035278
VAAL iteration: 3500 vae_loss: 2.0251624584198 dsc_loss: 1.3885087966918945
VAAL iteration: 3600 vae_loss: 1.858750343322754 dsc_loss: 1.386299967765808
VAAL iteration: 3700 vae_loss: 1.8555090427398682 dsc_loss: 1.3863712549209595
VAAL iteration: 3800 vae_loss: 1.820892572402954 dsc_loss: 1.3863041400909424
VAAL iteration: 3900 vae_loss: 1.858725666999817 dsc_loss: 1.3863153457641602
VAAL iteration: 4000 vae_loss: 1.8486076593399048 dsc_loss: 1.386484980583191
VAAL iteration: 4100 vae_loss: 1.8190960884094238 dsc_loss: 1.386309027671814
VAAL iteration: 4200 vae_loss: 1.8262275457382202 dsc_loss: 1.386335849761963
VAAL iteration: 4300 vae_loss: 1.8309510946273804 dsc_loss: 1.3863248825073242
VAAL iteration: 4400 vae_loss: 1.988344430923462 dsc_loss: 1.3929405212402344
VAAL iteration: 4500 vae_loss: 1.7928130626678467 dsc_loss: 1.3862953186035156
VAAL iteration: 4600 vae_loss: 1.7925939559936523 dsc_loss: 1.3862966299057007
VAAL iteration: 4700 vae_loss: 1.8083117008209229 dsc_loss: 1.3863049745559692
VAAL iteration: 4800 vae_loss: 1.8066731691360474 dsc_loss: 1.386293888092041
VAAL iteration: 4900 vae_loss: 1.7549893856048584 dsc_loss: 1.3873786926269531
VAAL iteration: 5000 vae_loss: 1.786421298980713 dsc_loss: 1.3865296840667725
VAAL iteration: 5100 vae_loss: 1.7795288562774658 dsc_loss: 1.386631727218628
VAAL iteration: 5200 vae_loss: 1.7742152214050293 dsc_loss: 1.3863146305084229
VAAL iteration: 5300 vae_loss: 1.8193461894989014 dsc_loss: 1.386315107345581
VAAL iteration: 5400 vae_loss: 1.7648725509643555 dsc_loss: 1.386275291442871
VAAL iteration: 5500 vae_loss: 1.773856282234192 dsc_loss: 1.3863319158554077
VAAL iteration: 5600 vae_loss: 1.741288185119629 dsc_loss: 1.3863086700439453
VAAL iteration: 5700 vae_loss: 1.7532137632369995 dsc_loss: 1.3864178657531738
VAAL iteration: 5800 vae_loss: 1.788456678390503 dsc_loss: 1.3863306045532227
VAAL iteration: 5900 vae_loss: 1.8591325283050537 dsc_loss: 1.3872324228286743
VAAL iteration: 6000 vae_loss: 1.7656419277191162 dsc_loss: 1.3863356113433838
VAAL iteration: 6100 vae_loss: 1.7162420749664307 dsc_loss: 1.3865504264831543
VAAL iteration: 6200 vae_loss: 1.7678871154785156 dsc_loss: 1.3862929344177246
VAAL iteration: 6300 vae_loss: 1.7737486362457275 dsc_loss: 1.3862932920455933
VAAL iteration: 6400 vae_loss: 1.7420626878738403 dsc_loss: 1.3862948417663574
VAAL iteration: 6500 vae_loss: 1.7424225807189941 dsc_loss: 1.3862929344177246
VAAL iteration: 6600 vae_loss: 1.7416367530822754 dsc_loss: 1.3863030672073364
VAAL iteration: 6700 vae_loss: 1.7317826747894287 dsc_loss: 1.38629150390625
VAAL iteration: 6800 vae_loss: 1.7708301544189453 dsc_loss: 1.3866593837738037
VAAL iteration: 6900 vae_loss: 1.7066171169281006 dsc_loss: 1.3865185976028442
VAAL iteration: 7000 vae_loss: 1.7101351022720337 dsc_loss: 1.3864308595657349
VAAL iteration: 7100 vae_loss: 1.7481179237365723 dsc_loss: 1.3863096237182617
VAAL iteration: 7200 vae_loss: 1.7400044202804565 dsc_loss: 1.3862948417663574
VAAL iteration: 7300 vae_loss: 1.7086002826690674 dsc_loss: 1.3863635063171387
VAAL iteration: 7400 vae_loss: 1.7193543910980225 dsc_loss: 1.386296033859253
768 5464 15 6229
>> Train vae and task model
epoch 20, vae loss is 0.15790414810180664
epoch 40, vae loss is 0.127407506108284
epoch 60, vae loss is 0.12423710525035858
epoch 80, vae loss is 0.12293025106191635
epoch 100, vae loss is 0.12149505317211151
epoch 0:  train loss is 8.29970669746399, train roc is  0.4955, train_prc:  0.2945
epoch 20:  train loss is 8.051209648450216, train roc is  0.5412, train_prc:  0.4492
epoch 40:  train loss is 7.955558220545451, train roc is  0.5393, train_prc:  0.4423
epoch 60:  train loss is 7.916936596234639, train roc is  0.5407, train_prc:  0.4415
epoch 80:  train loss is 7.869338830312093, train roc is  0.5425, train_prc:  0.4420
 >> Test Model
Cycle 3/5 || labeled data size 768, test roc =  0.6185, test prc =  0.1969
VAAL iteration: 0 vae_loss: 1.4561231136322021 dsc_loss: 1.4104292392730713
VAAL iteration: 100 vae_loss: 1.5448102951049805 dsc_loss: 1.38649320602417
VAAL iteration: 200 vae_loss: 1.7959916591644287 dsc_loss: 1.3865571022033691
VAAL iteration: 300 vae_loss: 1.6427223682403564 dsc_loss: 1.382250428199768
VAAL iteration: 400 vae_loss: 1.588510513305664 dsc_loss: 1.3875383138656616
VAAL iteration: 500 vae_loss: 1.589853286743164 dsc_loss: 1.3874911069869995
VAAL iteration: 600 vae_loss: 1.6565830707550049 dsc_loss: 1.386928677558899
VAAL iteration: 700 vae_loss: 1.6726161241531372 dsc_loss: 1.3850957155227661
VAAL iteration: 800 vae_loss: 1.5796282291412354 dsc_loss: 1.3878955841064453
VAAL iteration: 900 vae_loss: 1.6380057334899902 dsc_loss: 1.3876228332519531
VAAL iteration: 1000 vae_loss: 1.676261305809021 dsc_loss: 1.3856854438781738
VAAL iteration: 1100 vae_loss: 1.6250476837158203 dsc_loss: 1.3865277767181396
VAAL iteration: 1200 vae_loss: 1.6983410120010376 dsc_loss: 1.3869049549102783
VAAL iteration: 1300 vae_loss: 1.7075157165527344 dsc_loss: 1.3859999179840088
VAAL iteration: 1400 vae_loss: 1.799408197402954 dsc_loss: 1.3874576091766357
VAAL iteration: 1500 vae_loss: 1.78633451461792 dsc_loss: 1.3885678052902222
VAAL iteration: 1600 vae_loss: 1.687896490097046 dsc_loss: 1.3856929540634155
VAAL iteration: 1700 vae_loss: 1.6527886390686035 dsc_loss: 1.3865292072296143
VAAL iteration: 1800 vae_loss: 1.5930262804031372 dsc_loss: 1.386506199836731
VAAL iteration: 1900 vae_loss: 1.617140769958496 dsc_loss: 1.386486530303955
VAAL iteration: 2000 vae_loss: 1.6654808521270752 dsc_loss: 1.3866374492645264
VAAL iteration: 2100 vae_loss: 1.6437691450119019 dsc_loss: 1.3864424228668213
VAAL iteration: 2200 vae_loss: 1.7180547714233398 dsc_loss: 1.3855371475219727
VAAL iteration: 2300 vae_loss: 1.6612414121627808 dsc_loss: 1.3862990140914917
VAAL iteration: 2400 vae_loss: 1.7096989154815674 dsc_loss: 1.3865554332733154
VAAL iteration: 2500 vae_loss: 1.7349238395690918 dsc_loss: 1.3856728076934814
VAAL iteration: 2600 vae_loss: 1.7676769495010376 dsc_loss: 1.386825442314148
VAAL iteration: 2700 vae_loss: 1.7393912076950073 dsc_loss: 1.3867106437683105
VAAL iteration: 2800 vae_loss: 1.7170623540878296 dsc_loss: 1.386195421218872
VAAL iteration: 2900 vae_loss: 1.707804560661316 dsc_loss: 1.3862338066101074
VAAL iteration: 3000 vae_loss: 1.6953723430633545 dsc_loss: 1.3860232830047607
VAAL iteration: 3100 vae_loss: 1.729017734527588 dsc_loss: 1.3859331607818604
VAAL iteration: 3200 vae_loss: 1.7318928241729736 dsc_loss: 1.3866610527038574
VAAL iteration: 3300 vae_loss: 1.6913201808929443 dsc_loss: 1.3862217664718628
VAAL iteration: 3400 vae_loss: 1.6931674480438232 dsc_loss: 1.3860423564910889
VAAL iteration: 3500 vae_loss: 1.7201014757156372 dsc_loss: 1.385968804359436
VAAL iteration: 3600 vae_loss: 1.707838773727417 dsc_loss: 1.3862760066986084
VAAL iteration: 3700 vae_loss: 1.7279199361801147 dsc_loss: 1.386332631111145
VAAL iteration: 3800 vae_loss: 1.7611968517303467 dsc_loss: 1.386127233505249
VAAL iteration: 3900 vae_loss: 1.716376781463623 dsc_loss: 1.3862147331237793
VAAL iteration: 4000 vae_loss: 1.7061634063720703 dsc_loss: 1.3864045143127441
VAAL iteration: 4100 vae_loss: 1.7336690425872803 dsc_loss: 1.3865262269973755
VAAL iteration: 4200 vae_loss: 1.6981306076049805 dsc_loss: 1.3862320184707642
VAAL iteration: 4300 vae_loss: 1.816540002822876 dsc_loss: 1.3846622705459595
VAAL iteration: 4400 vae_loss: 1.6988685131072998 dsc_loss: 1.385599136352539
VAAL iteration: 4500 vae_loss: 1.7141797542572021 dsc_loss: 1.386310338973999
VAAL iteration: 4600 vae_loss: 1.7333331108093262 dsc_loss: 1.3873236179351807
VAAL iteration: 4700 vae_loss: 1.7816481590270996 dsc_loss: 1.3877884149551392
VAAL iteration: 4800 vae_loss: 1.701143503189087 dsc_loss: 1.3860008716583252
VAAL iteration: 4900 vae_loss: 1.7195322513580322 dsc_loss: 1.3849079608917236
VAAL iteration: 5000 vae_loss: 1.8360239267349243 dsc_loss: 1.3850343227386475
VAAL iteration: 5100 vae_loss: 1.6865131855010986 dsc_loss: 1.386739730834961
VAAL iteration: 5200 vae_loss: 1.7140365839004517 dsc_loss: 1.3867101669311523
VAAL iteration: 5300 vae_loss: 1.6896324157714844 dsc_loss: 1.3860353231430054
VAAL iteration: 5400 vae_loss: 1.7030812501907349 dsc_loss: 1.3863375186920166
VAAL iteration: 5500 vae_loss: 1.6333715915679932 dsc_loss: 1.3875389099121094
VAAL iteration: 5600 vae_loss: 1.681388020515442 dsc_loss: 1.3862460851669312
VAAL iteration: 5700 vae_loss: 1.670701026916504 dsc_loss: 1.386309027671814
VAAL iteration: 5800 vae_loss: 1.6777856349945068 dsc_loss: 1.3866229057312012
VAAL iteration: 5900 vae_loss: 1.6955468654632568 dsc_loss: 1.386144995689392
VAAL iteration: 6000 vae_loss: 1.7289438247680664 dsc_loss: 1.386298656463623
VAAL iteration: 6100 vae_loss: 1.7123488187789917 dsc_loss: 1.386366844177246
VAAL iteration: 6200 vae_loss: 1.675673007965088 dsc_loss: 1.3862957954406738
VAAL iteration: 6300 vae_loss: 1.646632194519043 dsc_loss: 1.3863987922668457
VAAL iteration: 6400 vae_loss: 1.651475429534912 dsc_loss: 1.3863060474395752
VAAL iteration: 6500 vae_loss: 1.6494204998016357 dsc_loss: 1.386307716369629
VAAL iteration: 6600 vae_loss: 1.6687536239624023 dsc_loss: 1.3862943649291992
VAAL iteration: 6700 vae_loss: 1.674584150314331 dsc_loss: 1.3862965106964111
VAAL iteration: 6800 vae_loss: 1.6638067960739136 dsc_loss: 1.3863242864608765
VAAL iteration: 6900 vae_loss: 1.6710882186889648 dsc_loss: 1.3863003253936768
VAAL iteration: 7000 vae_loss: 1.6794769763946533 dsc_loss: 1.38632071018219
VAAL iteration: 7100 vae_loss: 1.6491318941116333 dsc_loss: 1.3863074779510498
VAAL iteration: 7200 vae_loss: 1.6564524173736572 dsc_loss: 1.3862959146499634
VAAL iteration: 7300 vae_loss: 1.6701462268829346 dsc_loss: 1.386331558227539
VAAL iteration: 7400 vae_loss: 1.661238670349121 dsc_loss: 1.3862926959991455
1024 5208 4 6229
>> Train vae and task model
epoch 20, vae loss is 0.1776045560836792
epoch 40, vae loss is 0.1613166332244873
epoch 60, vae loss is 0.15770739316940308
epoch 80, vae loss is 0.15721125900745392
epoch 100, vae loss is 0.1553325355052948
epoch 0:  train loss is 8.31920063495636, train roc is  0.4982, train_prc:  0.4327
epoch 20:  train loss is 8.05962660908699, train roc is  0.5439, train_prc:  0.4127
epoch 40:  train loss is 8.001576751470566, train roc is  0.5501, train_prc:  0.4191
epoch 60:  train loss is 7.956327825784683, train roc is  0.5537, train_prc:  0.4232
epoch 80:  train loss is 7.936536371707916, train roc is  0.5538, train_prc:  0.4234
 >> Test Model
Cycle 4/5 || labeled data size 1024, test roc =  0.6097, test prc =  0.1835
VAAL iteration: 0 vae_loss: 1.4791510105133057 dsc_loss: 1.401519536972046
VAAL iteration: 100 vae_loss: 1.5400497913360596 dsc_loss: 1.386650562286377
VAAL iteration: 200 vae_loss: 1.465759515762329 dsc_loss: 1.3865087032318115
VAAL iteration: 300 vae_loss: 1.5584690570831299 dsc_loss: 1.3852163553237915
VAAL iteration: 400 vae_loss: 1.5656582117080688 dsc_loss: 1.3862888813018799
VAAL iteration: 500 vae_loss: 1.6286051273345947 dsc_loss: 1.3879108428955078
VAAL iteration: 600 vae_loss: 1.675438642501831 dsc_loss: 1.3867475986480713
VAAL iteration: 700 vae_loss: 1.7441158294677734 dsc_loss: 1.3864822387695312
VAAL iteration: 800 vae_loss: 1.6929802894592285 dsc_loss: 1.3860342502593994
VAAL iteration: 900 vae_loss: 1.684647798538208 dsc_loss: 1.3869540691375732
VAAL iteration: 1000 vae_loss: 1.5669479370117188 dsc_loss: 1.3910483121871948
VAAL iteration: 1100 vae_loss: 1.7383346557617188 dsc_loss: 1.3866803646087646
VAAL iteration: 1200 vae_loss: 1.657365322113037 dsc_loss: 1.3862578868865967
VAAL iteration: 1300 vae_loss: 1.6866753101348877 dsc_loss: 1.3864384889602661
VAAL iteration: 1400 vae_loss: 1.8145027160644531 dsc_loss: 1.3889482021331787
VAAL iteration: 1500 vae_loss: 1.6968343257904053 dsc_loss: 1.3862590789794922
VAAL iteration: 1600 vae_loss: 1.6788116693496704 dsc_loss: 1.3860316276550293
VAAL iteration: 1700 vae_loss: 1.721846580505371 dsc_loss: 1.3859307765960693
VAAL iteration: 1800 vae_loss: 1.7161558866500854 dsc_loss: 1.3859403133392334
VAAL iteration: 1900 vae_loss: 1.7287318706512451 dsc_loss: 1.3860327005386353
VAAL iteration: 2000 vae_loss: 1.7137951850891113 dsc_loss: 1.386238932609558
VAAL iteration: 2100 vae_loss: 1.7032697200775146 dsc_loss: 1.3865718841552734
VAAL iteration: 2200 vae_loss: 1.7175880670547485 dsc_loss: 1.3864564895629883
VAAL iteration: 2300 vae_loss: 1.7318257093429565 dsc_loss: 1.3861424922943115
VAAL iteration: 2400 vae_loss: 1.7215068340301514 dsc_loss: 1.385919451713562
VAAL iteration: 2500 vae_loss: 1.7924890518188477 dsc_loss: 1.386535882949829
VAAL iteration: 2600 vae_loss: 1.849506139755249 dsc_loss: 1.3879368305206299
VAAL iteration: 2700 vae_loss: 1.798751950263977 dsc_loss: 1.3865423202514648
VAAL iteration: 2800 vae_loss: 1.7606619596481323 dsc_loss: 1.3864271640777588
VAAL iteration: 2900 vae_loss: 1.7431814670562744 dsc_loss: 1.3862221240997314
VAAL iteration: 3000 vae_loss: 1.7038562297821045 dsc_loss: 1.3862589597702026
VAAL iteration: 3100 vae_loss: 1.7597588300704956 dsc_loss: 1.386325478553772
VAAL iteration: 3200 vae_loss: 1.7391331195831299 dsc_loss: 1.3863177299499512
VAAL iteration: 3300 vae_loss: 1.7159425020217896 dsc_loss: 1.3862665891647339
VAAL iteration: 3400 vae_loss: 1.763179898262024 dsc_loss: 1.3859729766845703
VAAL iteration: 3500 vae_loss: 1.73477303981781 dsc_loss: 1.3859282732009888
VAAL iteration: 3600 vae_loss: 1.7234300374984741 dsc_loss: 1.38645339012146
VAAL iteration: 3700 vae_loss: 1.762115240097046 dsc_loss: 1.3865423202514648
VAAL iteration: 3800 vae_loss: 1.6985852718353271 dsc_loss: 1.386465072631836
VAAL iteration: 3900 vae_loss: 1.7727570533752441 dsc_loss: 1.3862884044647217
VAAL iteration: 4000 vae_loss: 1.7525010108947754 dsc_loss: 1.3863224983215332
VAAL iteration: 4100 vae_loss: 1.7085838317871094 dsc_loss: 1.3863106966018677
VAAL iteration: 4200 vae_loss: 1.7150137424468994 dsc_loss: 1.3878825902938843
VAAL iteration: 4300 vae_loss: 1.8911175727844238 dsc_loss: 1.3887567520141602
VAAL iteration: 4400 vae_loss: 1.6812199354171753 dsc_loss: 1.3854670524597168
VAAL iteration: 4500 vae_loss: 1.7440484762191772 dsc_loss: 1.385584831237793
VAAL iteration: 4600 vae_loss: 1.7449374198913574 dsc_loss: 1.3854115009307861
VAAL iteration: 4700 vae_loss: 1.707852840423584 dsc_loss: 1.3861794471740723
VAAL iteration: 4800 vae_loss: 1.761326551437378 dsc_loss: 1.3854762315750122
VAAL iteration: 4900 vae_loss: 1.78554105758667 dsc_loss: 1.3841557502746582
VAAL iteration: 5000 vae_loss: 1.8558919429779053 dsc_loss: 1.3866373300552368
VAAL iteration: 5100 vae_loss: 1.6871222257614136 dsc_loss: 1.3874821662902832
VAAL iteration: 5200 vae_loss: 1.7392349243164062 dsc_loss: 1.3848943710327148
VAAL iteration: 5300 vae_loss: 1.7905381917953491 dsc_loss: 1.3851745128631592
VAAL iteration: 5400 vae_loss: 1.813623070716858 dsc_loss: 1.3863741159439087
VAAL iteration: 5500 vae_loss: 1.7361634969711304 dsc_loss: 1.3862359523773193
VAAL iteration: 5600 vae_loss: 1.7316946983337402 dsc_loss: 1.3862996101379395
VAAL iteration: 5700 vae_loss: 1.7203344106674194 dsc_loss: 1.3862714767456055
VAAL iteration: 5800 vae_loss: 1.7504377365112305 dsc_loss: 1.3862779140472412
VAAL iteration: 5900 vae_loss: 1.8089470863342285 dsc_loss: 1.3864719867706299
VAAL iteration: 6000 vae_loss: 1.7807724475860596 dsc_loss: 1.3858578205108643
VAAL iteration: 6100 vae_loss: 1.8214313983917236 dsc_loss: 1.386170506477356
VAAL iteration: 6200 vae_loss: 1.7641642093658447 dsc_loss: 1.3864362239837646
VAAL iteration: 6300 vae_loss: 1.7950513362884521 dsc_loss: 1.3863694667816162
VAAL iteration: 6400 vae_loss: 1.7823253870010376 dsc_loss: 1.3861868381500244
VAAL iteration: 6500 vae_loss: 1.765000820159912 dsc_loss: 1.385878562927246
VAAL iteration: 6600 vae_loss: 1.7628041505813599 dsc_loss: 1.3863720893859863
VAAL iteration: 6700 vae_loss: 1.7720527648925781 dsc_loss: 1.38649320602417
VAAL iteration: 6800 vae_loss: 1.7871558666229248 dsc_loss: 1.3863450288772583
VAAL iteration: 6900 vae_loss: 1.7917040586471558 dsc_loss: 1.3860942125320435
VAAL iteration: 7000 vae_loss: 1.7775949239730835 dsc_loss: 1.3864351511001587
VAAL iteration: 7100 vae_loss: 1.8446733951568604 dsc_loss: 1.3864960670471191
VAAL iteration: 7200 vae_loss: 1.8320424556732178 dsc_loss: 1.3864355087280273
VAAL iteration: 7300 vae_loss: 1.7944360971450806 dsc_loss: 1.3859546184539795
VAAL iteration: 7400 vae_loss: 1.8107154369354248 dsc_loss: 1.3865267038345337
1280 4952 4 6229
>> Train vae and task model
epoch 20, vae loss is 0.19377993047237396
epoch 40, vae loss is 0.1836848258972168
epoch 60, vae loss is 0.1804550588130951
epoch 80, vae loss is 0.17896324396133423
epoch 100, vae loss is 0.1775231808423996
epoch 0:  train loss is 8.300247526168823, train roc is  0.5127, train_prc:  0.4306
epoch 20:  train loss is 7.928703832626343, train roc is  0.5528, train_prc:  0.4638
epoch 40:  train loss is 7.845448422431946, train roc is  0.5547, train_prc:  0.4642
epoch 60:  train loss is 7.815781736373902, train roc is  0.5575, train_prc:  0.4652
epoch 80:  train loss is 7.767885231971741, train roc is  0.5572, train_prc:  0.4630
 >> Test Model
Cycle 5/5 || labeled data size 1280, test roc =  0.6290, test prc =  0.2206
Finished.
